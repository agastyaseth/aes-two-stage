{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ne22WAOPdxRU"
      },
      "source": [
        "# Experiment 1: Training with sentence-wise embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_OA59ArCd9lc"
      },
      "source": [
        "We explore training all the deep models for AES two stage flow by taking sentence-wise embeddings and then averaging the word embeddings for each sentence to get the embedding of the essay. This would yeild a tensor of dimension (N x max_sentences x 768) where N is the number of essays, and the max_sentences is found to be 85"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3dGIG9BE7Pg"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OnRXlI-2kXli",
        "outputId": "bd221964-60b3-4cf9-b3af-f8e0cc18e901"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "  from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jU2RzOqpka9t",
        "outputId": "8c149e53-2c0b-45f3-a1c9-db3d5fef87e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.64.0)\n",
            "Collecting boto3\n",
            "  Downloading boto3-1.21.46-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 7.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (2.23.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (2019.12.20)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 61.1 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 68.6 MB/s \n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n",
            "  Downloading jmespath-1.0.0-py3-none-any.whl (23 kB)\n",
            "Collecting botocore<1.25.0,>=1.24.46\n",
            "  Downloading botocore-1.24.46-py3-none-any.whl (8.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.7 MB 82.6 MB/s \n",
            "\u001b[?25hCollecting s3transfer<0.6.0,>=0.5.0\n",
            "  Downloading s3transfer-0.5.2-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 10.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.25.0,>=1.24.46->boto3) (2.8.2)\n",
            "Collecting urllib3<1.27,>=1.25.4\n",
            "  Downloading urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 78.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.25.0,>=1.24.46->boto3) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests) (3.0.4)\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 91.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses) (7.1.2)\n",
            "Installing collected packages: urllib3, jmespath, botocore, s3transfer, sentencepiece, sacremoses, boto3\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed boto3-1.21.46 botocore-1.24.46 jmespath-1.0.0 s3transfer-0.5.2 sacremoses-0.0.49 sentencepiece-0.1.96 urllib3-1.25.11\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "urllib3"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'AES_DL'...\n",
            "remote: Enumerating objects: 59, done.\u001b[K\n",
            "remote: Counting objects: 100% (59/59), done.\u001b[K\n",
            "remote: Compressing objects: 100% (44/44), done.\u001b[K\n",
            "remote: Total 59 (delta 25), reused 28 (delta 8), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (59/59), done.\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 8.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 96.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.49)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 63.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.5.1-py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 7.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.25.11)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.5.1 pyyaml-6.0 tokenizers-0.12.1 transformers-4.18.0\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.7/dist-packages (0.90)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from xgboost) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from xgboost) (1.4.1)\n",
            "Collecting language-tool-python\n",
            "  Downloading language_tool_python-2.7.1-py3-none-any.whl (34 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from language-tool-python) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from language-tool-python) (4.64.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->language-tool-python) (1.25.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->language-tool-python) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->language-tool-python) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->language-tool-python) (2.10)\n",
            "Installing collected packages: language-tool-python\n",
            "Successfully installed language-tool-python-2.7.1\n"
          ]
        }
      ],
      "source": [
        "# import important libraries and download data\n",
        "import os\n",
        "import math\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import random\n",
        "import multiprocessing\n",
        "import tensorflow as tf\n",
        "%matplotlib notebook\n",
        "import numpy as np\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE\n",
        "from torch.autograd import Variable\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "import xgboost as xgb\n",
        "from tqdm import tqdm\n",
        "import string\n",
        "! pip install tqdm boto3 requests regex sentencepiece sacremoses\n",
        "! git clone https://github.com/Gaurav-Pande/AES_DL.git && mv AES_DL/data .\n",
        "! pip install transformers\n",
        "! pip install xgboost\n",
        "! pip install language-tool-python "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jehlg6loEps4"
      },
      "source": [
        "## RUN Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JFl1IlIcBl2B"
      },
      "outputs": [],
      "source": [
        "# Load respective embeddings from file\n",
        "load_bert_sem=True\n",
        "load_bert_coh= True\n",
        "load_bert_prel=False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6EjI47zsEmS0"
      },
      "outputs": [],
      "source": [
        "# Flags to load respective models from file, no training of LSTM models\n",
        "load_trained_model_sem  = True\n",
        "load_trained_model_coh = True\n",
        "load_trained_model_prel = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cly0WkAkFTvy"
      },
      "outputs": [],
      "source": [
        "# Path for all files\n",
        "#model_path = '/content/drive/MyDrive/Colab Notebooks/AES/full_embeddings'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MOQN_EaGFvOz"
      },
      "outputs": [],
      "source": [
        "# Embedding Type\n",
        "#embedding = 'full_emb'\n",
        "embedding = \"sen_avg\"\n",
        "#embedding = \"para_avg\"\n",
        "\n",
        "# Max Words (for full embedding)\n",
        "max_words_for_full_emb = 200\n",
        "max_words_for_full_emb_sem = 300\n",
        "\n",
        "# Max # Sentences (for sentence average embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzqETgwsFBbN"
      },
      "source": [
        "## Function Definitions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64c3YRADslqw",
        "outputId": "97734317-7fa4-4174-bb21-9266d8b619a6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading LanguageTool 5.6: 100%|██████████| 220M/220M [00:03<00:00, 63.0MB/s]\n",
            "Unzipping /tmp/tmpx5ihe5hq.zip to /root/.cache/language_tool_python.\n",
            "Downloaded https://www.languagetool.org/download/LanguageTool-5.6.zip to /root/.cache/language_tool_python.\n"
          ]
        }
      ],
      "source": [
        "import language_tool_python\n",
        "tool = language_tool_python.LanguageTool('en-US')\n",
        "def check_sp_n_grammar (text):\n",
        "  matches = tool.check(text)\n",
        "  num_sp_err = 0\n",
        "  num_gram_err = 0\n",
        "  num_other_err = 0\n",
        "  # print (\"Spell n Grammar checker: Number of errors detected: \",len(matches))\n",
        "  for i in range(len(matches)):\n",
        "    if (matches[i].ruleIssueType == \"misspelling\"):\n",
        "      num_sp_err = num_sp_err +1\n",
        "    elif (matches[i].ruleIssueType == \"grammar\"):\n",
        "      num_gram_err = num_gram_err +1\n",
        "    else:\n",
        "      num_other_err = num_other_err +1\n",
        "  #if (matches[i].ruleId == '')\n",
        "  return (matches, num_sp_err, num_gram_err, num_other_err)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WIoqpWKfkncn"
      },
      "outputs": [],
      "source": [
        "# Augment dataframe with handrafted features - num of spelling errors, gramm errors, other errors, word-count and also add the 3 scores\n",
        "def augment_handcrafted_features (df, prelEval=False):\n",
        "  from transformers import BertModel, BertConfig, BertTokenizer\n",
        "  sp_errors = len(df)*[0]\n",
        "  gr_errors = len(df)*[0]\n",
        "  oth_errors = len(df)*[0]\n",
        "  semantic_score = len(df)*[0.0]\n",
        "  coherence_score = len(df)*[0.0]\n",
        "  prel_score = len(df)*[0.0]\n",
        "  tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "  config = BertConfig.from_pretrained('bert-base-uncased', output_hidden_states=True)\n",
        "  model = BertModel.from_pretrained('bert-base-uncased', config=config)\n",
        "  i = 0\n",
        "  for index, row in df.iterrows():\n",
        "    input_tensor = prepare_input_data_sen_avg(model=model, tokenizer=tokenizer, text=row.essay).detach().numpy()\n",
        "    #coherence_score = lstm_model_coh.predict(input_tensor)[0][0]\n",
        "    #semantic_score = lstm_model_sem.predict(input_tensor)[0][0]\n",
        "    #df['semantic_score'][index] = semantic_score\n",
        "    #df['coherence_score'][index] = coherence_score\n",
        "    semantic_score[i] = lstm_model_sem.predict(input_tensor)[0][0]\n",
        "    coherence_score[i] = lstm_model_coh.predict(input_tensor)[0][0]\n",
        "    if (prelEval ==True):\n",
        "      del input_tensor\n",
        "      input_tensor = prepare_input_data_sen_avg(model=model, tokenizer=tokenizer, text=row.prompt+row.essay).detach().numpy()\n",
        "      #prel_score = lstm_model_prel.predict(input_tensor)[0][0]\n",
        "      #df['prel_score'][index] = prel_score\n",
        "      prel_score[i] = lstm_model_prel.predict(input_tensor)[0][0]\n",
        "    del input_tensor\n",
        "\n",
        "    _,sp, gr, oth = check_sp_n_grammar(row.essay)\n",
        "    sp_errors[i] = sp\n",
        "    gr_errors[i] = gr\n",
        "    oth_errors[i] = oth\n",
        "\n",
        "    if (i%100==0):\n",
        "      print('Iter: ',i)\n",
        "      print ('Combined Essay: ', row.essay + row.prompt)\n",
        "      print ('Prel Score: ', prel_score[i])\n",
        "      print ('Norm Score: ', row.normalized_score)\n",
        "    i += 1\n",
        "\n",
        "\n",
        "  df['spell_err'] = sp_errors\n",
        "  df['gram_err'] = gr_errors\n",
        "  df['oth_err'] = oth_errors\n",
        "  df['semantic_score'] = semantic_score\n",
        "  df['coherence_score'] = coherence_score\n",
        "  df['prel_score'] = prel_score\n",
        "  return (df)\n",
        "  #for essay in df['essay']:\n",
        "  #  _,sp, gr, oth = check_sp_n_grammar(essay)\n",
        "  #  sp_errors[i] = sp\n",
        "  #  gr_errors[i] = gr\n",
        "  #  oth_errors[i] = oth\n",
        "  #  if (i%100==0):\n",
        "  #    print('Iter: ',i)\n",
        "  #  i += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rli1eAINkwQN"
      },
      "outputs": [],
      "source": [
        "# Prepare Input data (1 essay) for prediction\n",
        "def prepare_input_data(text, max_len=200):\n",
        "  tokenized_text = tokenizer.encode(text, add_special_tokens=True ,max_length=200)\n",
        "  # print (\"Tokenized text: \", tokenized_text)\n",
        "  ## processing the tokenized train values for the test set\n",
        "  padded_text = np.array( [tokenized_text + [0]*(max_len-len(tokenized_text))])\n",
        "  # print (\"Padded text: \", padded_text)\n",
        "  attention_mask_test = np.where(padded_text != 0, 1, 0)\n",
        "  input_ids = torch.tensor(padded_text)\n",
        "  attention_mask = torch.tensor(attention_mask_test)\n",
        "  #last_hidden_state = torch.zeros(1,200,768)\n",
        "  outputs = model(input_ids)\n",
        "  return(outputs[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qjK22LauRg2G"
      },
      "outputs": [],
      "source": [
        "def prepare_input_data_sen_avg(model, tokenizer, text, max_len=200):\n",
        "\tlhs = torch.empty(1,max_sentences,768, dtype=torch.float)\n",
        "\temb_for_padding = tokenizer.encode_plus(\"\", add_special_tokens=True, truncation=True, padding=\"max_length\", return_tensors=\"pt\", max_length=10)\n",
        "\ttt = torch.tensor(emb_for_padding['input_ids'])\n",
        "\toutput = model(tt)\n",
        "\tlhs_for_padding = output.hidden_states[12] + output.hidden_states[11] + output.hidden_states[10] + output.hidden_states[9]\n",
        "\tlhs_for_padding_np = np.array(lhs_for_padding.detach().numpy())\n",
        "\tlhs_for_padding_mean = np.mean(lhs_for_padding_np,axis=1)\n",
        "\tlhs_avg_for_padding = torch.tensor(lhs_for_padding_mean[0])\n",
        "\tsentences = re.split('\\. |\\? |! ', text)\n",
        "\tsen_length = len(sentences)\n",
        "\tlhs_sentence_avg = np.zeros((max_sentences,768), dtype=float)\n",
        "\tfor i,s in enumerate(sentences):\n",
        "\t\tif (i>=max_sentences):\n",
        "\t\t\tbreak\n",
        "\t\ttokenize_sentence = tokenizer.encode(sentences[i],add_special_tokens=True, max_length=512, truncation=True)\n",
        "\t\ttt = torch.tensor(tokenize_sentence)\n",
        "\t\ttts = tt.reshape(1,len(tt))\n",
        "\t\toutput = model(tts)\n",
        "\t\tlhs_sentence = output.hidden_states[12] + output.hidden_states[11] + output.hidden_states[10] + output.hidden_states[9]\n",
        "\t\tlhs_sentence_np = np.array(lhs_sentence.detach().numpy())\n",
        "\t\tlhs_sentence_np_mean = np.mean(lhs_sentence_np,axis=1)\n",
        "\t\tlhs_sentence_avg[i] = lhs_sentence_np_mean[0]\n",
        "\t\t\n",
        "\tlhs[0] = torch.tensor(lhs_sentence_avg)\n",
        "        \n",
        "\tif (sen_length < max_sentences):\n",
        "\t\tfor i in range (sen_length, max_sentences):\n",
        "\t\t\tlhs[0][i]= lhs_avg_for_padding\n",
        "\t\t\n",
        "\t#print (\"SIze of lhs_for_padding: \", lhs_for_padding.shape)\n",
        "\t#print (\"SIze of lhs_avg_for_padding: \", lhs_avg_for_padding.shape)\n",
        "\t#print (\"SIze of lhs being returned: \", lhs.shape)\n",
        "\treturn (lhs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BPV3XXZ4kzsC"
      },
      "outputs": [],
      "source": [
        "# Normalizing the domain1_score\n",
        "def normalize_value(score, min_value, max_value):\n",
        "  result =  tf.compat.v1.div(float(tf.subtract(score, min_value)), float(tf.subtract(max_value, min_value)))\n",
        "  return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H5agOxE1k641"
      },
      "outputs": [],
      "source": [
        "# taking care of NEC\n",
        "def clean_nec(essay):\n",
        "    essay = re.sub(r\"@[A-Za-z0-9]+\", ' ', essay)\n",
        "    essay = re.sub(r\"https?://[A-Za-z0-9./]+\", ' ', essay)\n",
        "    #essay = re.sub(r\"[^a-zA-Z.!?']\", ' ', essay)\n",
        "    essay = re.sub(r\" +\", ' ', essay)\n",
        "    return essay"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FcHpWqudl9b9"
      },
      "outputs": [],
      "source": [
        "# augmenting for coherence model\n",
        "def coherence_augment(essay):\n",
        "  x = re.split('\\. |\\? |! ', essay)\n",
        "  random.shuffle(x)\n",
        "  return '. '.join(x)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fgy71fJRZg_E"
      },
      "outputs": [],
      "source": [
        "alphabets= \"([A-Za-z])\"\n",
        "prefixes = \"(Mr|St|Mrs|Ms|Dr)[.]\"\n",
        "suffixes = \"(Inc|Ltd|Jr|Sr|Co)\"\n",
        "starters = \"(Mr|Mrs|Ms|Dr|He\\s|She\\s|It\\s|They\\s|Their\\s|Our\\s|We\\s|But\\s|However\\s|That\\s|This\\s|Wherever)\"\n",
        "acronyms = \"([A-Z][.][A-Z][.](?:[A-Z][.])?)\"\n",
        "websites = \"[.](com|net|org|io|gov)\"\n",
        "\n",
        "def split_into_sentences(text):\n",
        "    text = \" \" + text + \"  \"\n",
        "    text = text.replace(\"\\n\",\" \")\n",
        "    text = re.sub(prefixes,\"\\\\1<prd>\",text)\n",
        "    text = re.sub(websites,\"<prd>\\\\1\",text)\n",
        "    if \"Ph.D\" in text: text = text.replace(\"Ph.D.\",\"Ph<prd>D<prd>\")\n",
        "    text = re.sub(\"\\s\" + alphabets + \"[.] \",\" \\\\1<prd> \",text)\n",
        "    text = re.sub(acronyms+\" \"+starters,\"\\\\1<stop> \\\\2\",text)\n",
        "    text = re.sub(alphabets + \"[.]\" + alphabets + \"[.]\" + alphabets + \"[.]\",\"\\\\1<prd>\\\\2<prd>\\\\3<prd>\",text)\n",
        "    text = re.sub(alphabets + \"[.]\" + alphabets + \"[.]\",\"\\\\1<prd>\\\\2<prd>\",text)\n",
        "    text = re.sub(\" \"+suffixes+\"[.] \"+starters,\" \\\\1<stop> \\\\2\",text)\n",
        "    text = re.sub(\" \"+suffixes+\"[.]\",\" \\\\1<prd>\",text)\n",
        "    text = re.sub(\" \" + alphabets + \"[.]\",\" \\\\1<prd>\",text)\n",
        "    if \"”\" in text: text = text.replace(\".”\",\"”.\")\n",
        "    if \"\\\"\" in text: text = text.replace(\".\\\"\",\"\\\".\")\n",
        "    if \"!\" in text: text = text.replace(\"!\\\"\",\"\\\"!\")\n",
        "    if \"?\" in text: text = text.replace(\"?\\\"\",\"\\\"?\")\n",
        "    text = text.replace(\".\",\".<stop>\")\n",
        "    text = text.replace(\"?\",\"?<stop>\")\n",
        "    text = text.replace(\"!\",\"!<stop>\")\n",
        "    text = text.replace(\"<prd>\",\".\")\n",
        "    sentences = text.split(\"<stop>\")\n",
        "    sentences = sentences[:-1]\n",
        "    sentences = [s.strip() for s in sentences]\n",
        "    return sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltfFB-9RlCQC",
        "outputId": "b2894dcf-3f26-471f-b094-6e870136ab07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-e676a082-66d4-43e9-90f4-7efe7fc06d2c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>essay_id</th>\n",
              "      <th>essay_set</th>\n",
              "      <th>essay</th>\n",
              "      <th>domain1_score</th>\n",
              "      <th>normalized_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear local newspaper, I think effects computer...</td>\n",
              "      <td>8</td>\n",
              "      <td>0.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
              "      <td>9</td>\n",
              "      <td>0.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
              "      <td>7</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
              "      <td>10</td>\n",
              "      <td>0.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
              "      <td>8</td>\n",
              "      <td>0.6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e676a082-66d4-43e9-90f4-7efe7fc06d2c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e676a082-66d4-43e9-90f4-7efe7fc06d2c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e676a082-66d4-43e9-90f4-7efe7fc06d2c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   essay_id  essay_set                                              essay  \\\n",
              "0         1          1  Dear local newspaper, I think effects computer...   \n",
              "1         2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
              "2         3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
              "3         4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
              "4         5          1  Dear @LOCATION1, I know having computers has a...   \n",
              "\n",
              "   domain1_score  normalized_score  \n",
              "0              8               0.6  \n",
              "1              9               0.7  \n",
              "2              7               0.5  \n",
              "3             10               0.8  \n",
              "4              8               0.6  "
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Loading the dataset\n",
        "dataset_path = \"./data/training_set_rel3.tsv\"\n",
        "data = pd.read_csv(dataset_path, sep=\"\\t\", encoding=\"ISO-8859-1\")\n",
        "min_scores = [2, 1, 0, 0, 0, 0, 0, 0]\n",
        "max_scores = [12, 6, 3, 3, 4, 4, 30, 60]\n",
        "data.dropna(axis=1, inplace=True)\n",
        "data.drop(columns=[\"rater1_domain1\", \"rater2_domain1\"], inplace=True)\n",
        "data['normalized_score'] = data.apply(lambda x: float(normalize_value(x['domain1_score'], min_scores[x['essay_set']-1], max_scores[x['essay_set']-1])), axis=1)\n",
        "data.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "NVtV92qnlG5B"
      },
      "outputs": [],
      "source": [
        "data['essay'] = data['essay'].apply(lambda x: clean_nec(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Up7aChVclLZW",
        "outputId": "6e3c61ac-68d1-4780-cb4b-e34a5865af28"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"Some people think it is a good idea and same do not. My opinion is that, I think that people spend a lot of time for good reasons. Here are three reasons why, . grownups working, . students learning how to type, and . communicating with others. My first reason is that parents do a lot of work on computer. For example, they do taxes, paperwork, airline tickets, and the bank. And those are usually all done on the computer so it would be easier if people don't drive. My second reason is students need to learn how to type so they can email or even write on paper. It helps them build learning ability and also, so they can know how to sing the 's. Computers are suppose to be fun for people of any age. My last reason is, communicating with others is a great skill to have so you can talk in person. Computers help because if you mess up of what your trying to say then you could just erase what your trying to say. And in person, you can't. Also you can make plans with one of your friend on something if they live really far or something like that. In my opinion. I think people should be able to go on the computers to do work, playgames, no sites, and many more other things to go on, only if you have a computer at home.\""
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.iloc[68]['essay']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZErPCWWlPAW",
        "outputId": "c4514771-a747-43ee-fc85-79a5c3808aec"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-3cf9209a-eddb-4299-8268-fb4d8ca9b3bd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>essay_id</th>\n",
              "      <th>essay_set</th>\n",
              "      <th>essay</th>\n",
              "      <th>domain1_score</th>\n",
              "      <th>normalized_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear local newspaper, I think effects computer...</td>\n",
              "      <td>8</td>\n",
              "      <td>0.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear , I believe that using computers will ben...</td>\n",
              "      <td>9</td>\n",
              "      <td>0.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear, More and more people use computers, but ...</td>\n",
              "      <td>7</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear Local Newspaper, I have found that many e...</td>\n",
              "      <td>10</td>\n",
              "      <td>0.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear , I know having computers has a positive ...</td>\n",
              "      <td>8</td>\n",
              "      <td>0.6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3cf9209a-eddb-4299-8268-fb4d8ca9b3bd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3cf9209a-eddb-4299-8268-fb4d8ca9b3bd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3cf9209a-eddb-4299-8268-fb4d8ca9b3bd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   essay_id  essay_set                                              essay  \\\n",
              "0         1          1  Dear local newspaper, I think effects computer...   \n",
              "1         2          1  Dear , I believe that using computers will ben...   \n",
              "2         3          1  Dear, More and more people use computers, but ...   \n",
              "3         4          1  Dear Local Newspaper, I have found that many e...   \n",
              "4         5          1  Dear , I know having computers has a positive ...   \n",
              "\n",
              "   domain1_score  normalized_score  \n",
              "0              8               0.6  \n",
              "1              9               0.7  \n",
              "2              7               0.5  \n",
              "3             10               0.8  \n",
              "4              8               0.6  "
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "vzkFhm7SlTxP"
      },
      "outputs": [],
      "source": [
        "# LSTM Model\n",
        "from keras.layers import Embedding, Input, LSTM, Dense, Dropout, Lambda, Flatten, Bidirectional, Conv2D, Conv1D, MaxPooling1D, GlobalMaxPooling1D\n",
        "from keras.models import Sequential,Model, load_model, model_from_config\n",
        "import keras.backend as K\n",
        "max_sentences = 128\n",
        "\n",
        "def get_model(Hidden_dim1=400, Hidden_dim2=128, return_sequences = True, dropout_dense=0.5, dropout_lstm=0.4, recurrent_dropout=0.4, \n",
        "              sen_size=max_sentences, input_size=768, activation='sigmoid', opt_engine='rmsprop', loss_fn='mean_squared_error'):\n",
        "    \"\"\"Define the model.\"\"\"\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(Hidden_dim1, dropout=dropout_lstm, recurrent_dropout=recurrent_dropout, input_shape=(sen_size,input_size), return_sequences=return_sequences))\n",
        "    model.add(LSTM(Hidden_dim2, recurrent_dropout=recurrent_dropout))\n",
        "    model.add(Dropout(dropout_dense))\n",
        "    model.add(Dense(1, activation=activation))\n",
        "\n",
        "    model.compile(loss=loss_fn, optimizer=opt_engine, metrics=['mae'])\n",
        "    model.summary()\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "mwD7dtDjCDNd"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Embedding, Input, LSTM, Dense, Dropout, Lambda, Flatten, Bidirectional, Conv2D, Conv1D, MaxPooling1D, GlobalMaxPooling1D\n",
        "from keras.models import Sequential,Model, load_model, model_from_config\n",
        "import keras.backend as K\n",
        "max_sentences = 128\n",
        "\n",
        "def get_model_CNN(output_dims=10380):\n",
        "    \"\"\"Define the model.\"\"\"\n",
        "    #inputs = Input(shape=(768,1))\n",
        "    #x = Conv1D(64, 3, strides=1, padding='same', activation='relu')(inputs)\n",
        "    ##Cuts the size of the output in half, maxing over every 2 inputs\n",
        "    #x = MaxPooling1D(pool_size=2)(x)\n",
        "    #x = Conv1D(128, 3, strides=1, padding='same', activation='relu')(x)\n",
        "    #x = GlobalMaxPooling1D()(x) \n",
        "    #outputs = Dense(output_dims, activation='relu')(x)\n",
        "    #model = Model(inputs=inputs, outputs=outputs, name='CNN')\n",
        "    #model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mae','mse'])\n",
        "    #model.summary()\n",
        "    model.add (Conv2D())\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6D4F3RKidMEs"
      },
      "outputs": [],
      "source": [
        "tpd_train = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/AES/tpd_train.csv')\n",
        "tpd_xgb = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/AES/tpd_xgb.csv')\n",
        "tpd_test = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/AES/tpd_test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "acGHZJYs4Dah"
      },
      "outputs": [],
      "source": [
        "average_essay_lens = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/AES/average_essay_set_lengths.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_ZBSTme4R8S",
        "outputId": "61b62001-1228-4c51-a954-6bf1dd5d5b7a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-906063ef-550e-44a8-85b4-aa1b7fe7d700\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>essay_set</th>\n",
              "      <th>essay_len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>369</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>91</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>150</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>571</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-906063ef-550e-44a8-85b4-aa1b7fe7d700')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-906063ef-550e-44a8-85b4-aa1b7fe7d700 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-906063ef-550e-44a8-85b4-aa1b7fe7d700');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   essay_set  essay_len\n",
              "0          1        350\n",
              "1          2        369\n",
              "2          3        104\n",
              "3          4         91\n",
              "4          5        118\n",
              "5          6        150\n",
              "6          7        156\n",
              "7          8        571"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "average_essay_lens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "sdTARVUhfbIl",
        "outputId": "24aea6ca-02d3-40a0-9972-ec2146c113fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train: 6488, xgb: 3892, test: 2596\n"
          ]
        }
      ],
      "source": [
        "print(\"train: %d, xgb: %d, test: %d\"%(len(tpd_train), len(tpd_xgb), len(tpd_test)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "deueEdHjSQqs"
      },
      "outputs": [],
      "source": [
        "def prepare_embeddings (df, model_type='semantic', train_or_test='test', load_from_file=True, \n",
        "                        file_path='/content/drive/MyDrive/Colab Notebooks/AES/experiment_XX' ,\n",
        "                        max_sentences=128):\n",
        "  # Arguments Description:\n",
        "  # ----------------------\n",
        "  # \n",
        "  #   df:             Dataframe containing the essays and scores \n",
        "  #\n",
        "  #   model_type:     Supports 3 model types: 'semantic', 'coherence' and 'p_rel' (Prompt Relevance)\n",
        "  #\n",
        "  #   train_or_test:  Whether there are \"training\" vectors (essays) or \"test\" vectors\n",
        "  #\n",
        "  #   load_from_file: Boolean flag whether to load the embeddings from previously stored file or generate \n",
        "  #                   & save afresh\n",
        "  #\n",
        "  #   file_path:      Base directory where models and embeddings will be saved\n",
        "  #\n",
        "  #   max_sentences:  Relevant for sentence average (sen_avg) embedding type: maximum no of sentences \n",
        "  #                   permissable in an essay\n",
        "  #\n",
        "  from transformers import BertModel, BertConfig, BertTokenizer\n",
        "\n",
        "  print (\"Preparing Embeddings...\")\n",
        "  print (\"Model Type: \", model_type)\n",
        "  print (\"Train or Test: \", train_or_test)\n",
        "  if (not df.empty):\n",
        "    print (\"Dataframe provided, Size: \", df.shape)\n",
        "\n",
        "  if (model_type =='semantic'):\n",
        "    if (train_or_test=='train'):\n",
        "      lhs_path = file_path + '/lhs_train.pt'\n",
        "      y_path = file_path + '/y_train.pt'\n",
        "    else:\n",
        "      if (train_or_test == 'test'):\n",
        "        lhs_path = file_path + '/lhs_test.pt'\n",
        "        y_path = file_path + '/y_test.pt'\n",
        "      else:\n",
        "        print (\"Invalid choice for train_or_test. Returning NONE\")\n",
        "        return\n",
        "  else:\n",
        "    if (model_type =='coherence'):\n",
        "      if (train_or_test=='train'):\n",
        "        lhs_path = file_path + '/lhs_coherence_train.pt'\n",
        "        y_path = file_path + '/y_train_coh.pt'\n",
        "      else:\n",
        "        if (train_or_test == 'test'):\n",
        "          lhs_path = file_path + '/lhs_coherence_test.pt'\n",
        "          y_path = file_path + '/y_test_coh.pt'\n",
        "        else:\n",
        "          print (\"Invalid choice for train_or_test. Returning NONE\")\n",
        "          return\n",
        "    else:\n",
        "      if (model_type =='prel'):\n",
        "        if (train_or_test=='train'):\n",
        "          lhs_path = file_path + '/lhs_prel_train.pt'\n",
        "          y_path = file_path + '/y_train_prel.pt'\n",
        "        else:\n",
        "          if (train_or_test == 'test'):\n",
        "            lhs_path = file_path + '/lhs_prel_test.pt'\n",
        "            y_path = file_path + '/y_test_prel.pt'\n",
        "          else:\n",
        "            print (\"Invalid choice for train_or_test. Returning NONE\")\n",
        "            return\n",
        "      else:\n",
        "        print (\"Please choose a valid model - one of SEMANTIC, COHERENCE or PREL\")\n",
        "        return\n",
        "\n",
        "  if (load_from_file == True):\n",
        "    print (\"Loading existing embeddings from file...\")\n",
        "    print (\"LHS File chosen: \", lhs_path)\n",
        "    print (\"Y File chosen: \", y_path)\n",
        "    lhs = torch.load(lhs_path)\n",
        "    y_gold = torch.load(y_path)\n",
        "    print (\"Loaded, Size of LHS embeddings: \", lhs.shape)\n",
        "    print (\"Loaded, Size of y Gold: \", y_gold.shape)\n",
        "  else:\n",
        "    print (\"Generating embeddings from scratch & extracting the Y_Gold from dataframe...\\n\")\n",
        "    \n",
        "    if (df.empty):\n",
        "      print (\"Null dataframe, please provide a valid dataframe\")\n",
        "      return\n",
        "\n",
        "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "    config = BertConfig.from_pretrained('bert-base-uncased', output_hidden_states=True)\n",
        "    model = BertModel.from_pretrained('bert-base-uncased', config=config)\n",
        "\n",
        "    essays = df['essay']\n",
        "    y_gold = df['normalized_score']\n",
        "    sentences = []\n",
        "    tokenize_sentences = []\n",
        "  \n",
        "    cuda = torch.device('cuda')\n",
        "\n",
        "    # Embeddings for training vectors\n",
        "    lhs = torch.empty((len(essays),max_sentences,768), dtype=torch.float)\n",
        "    emb_for_padding = tokenizer.encode_plus(\"\", add_special_tokens=True, truncation=True, padding=\"max_length\", return_tensors=\"pt\", max_length=10)\n",
        "    tt = torch.tensor(emb_for_padding['input_ids'])\n",
        "    output = model(tt)\n",
        "    #lhs_for_padding = output.hidden_states[11]\n",
        "    lhs_for_padding = output.hidden_states[12] + output.hidden_states[11] + output.hidden_states[10] + output.hidden_states[9]\n",
        "    lhs_for_padding_np = np.array(lhs_for_padding.detach().numpy())\n",
        "    lhs_for_padding_mean = np.mean(lhs_for_padding_np,axis=1)\n",
        "    lhs_avg_for_padding = torch.tensor(lhs_for_padding_mean[0])\n",
        "    \n",
        "    for j,essay in enumerate(essays):\n",
        "      if (j%200 ==0):\n",
        "        print (\"Iteration: \", j)\n",
        "\n",
        "      sentences = re.split('\\. |\\? |! ', essay)\n",
        "      sen_length = len(sentences)\n",
        "      lhs_sentence_avg = np.zeros((max_sentences,768), dtype=float)\n",
        "\n",
        "      #for i in range(min(85,len(sentences))):\n",
        "      for i,s in enumerate(sentences):\n",
        "        if (i>=max_sentences):\n",
        "          break\n",
        "        tokenize_sentence = tokenizer.encode(sentences[i],add_special_tokens=True, max_length=512, truncation=True)\n",
        "        tt = torch.tensor(tokenize_sentence)\n",
        "        tts = tt.reshape(1,len(tt))\n",
        "        output = model(tts)\n",
        "        # getting the 2nd last layer\n",
        "        #lhs_sentence = output.hidden_states[11]\n",
        "        lhs_sentence = output.hidden_states[12] + output.hidden_states[11] + output.hidden_states[10] + output.hidden_states[9]\n",
        "        lhs_sentence_np = np.array(lhs_sentence.detach().numpy())\n",
        "        lhs_sentence_np_mean = np.mean(lhs_sentence_np,axis=1)\n",
        "        lhs_sentence_avg[i] = lhs_sentence_np_mean[0]\n",
        "  \n",
        "      lhs[j] = torch.tensor(lhs_sentence_avg)\n",
        "\n",
        "      if (sen_length < max_sentences):\n",
        "        for i in range (sen_length, max_sentences):\n",
        "          lhs[j][i]= lhs_avg_for_padding\n",
        "  \n",
        "    torch.save(lhs, lhs_path)\n",
        "    torch.save(y_gold, y_path)\n",
        "\n",
        "    print (\"Saved LHS & Y_gold...\") \n",
        "    \n",
        "  print (\"Returning lhs: Shape: \", lhs.shape)\n",
        "  print (\"Returning y_gold: Shape: \", y_gold.shape)\n",
        "  return lhs, y_gold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "QLFqa5NrDogv"
      },
      "outputs": [],
      "source": [
        "def prepare_embeddings_updated (df, model_type='semantic', train_or_test='test', load_from_file=True, \n",
        "                        file_path='/content/drive/MyDrive/Colab Notebooks/AES/experiment_XX' ,\n",
        "                        embedding_type='sen_avg',max_sentences=128, max_words=512, hstate='last4sum', gold_field=\"normalized_score\" ):\n",
        "  # Arguments Description:\n",
        "  # ----------------------\n",
        "  # \n",
        "  #   model_type:     Supports 3 model types: 'semantic', 'coherence' and 'p_rel' (Prompt Relevance)\n",
        "  #\n",
        "  #   train_or_test:  Whether there are \"training\" vectors (essays) or \"test\" vectors\n",
        "  #\n",
        "  #   load_from_file: Boolean flag whether to load the embeddings from previously stored file or generate \n",
        "  #                   & save afresh\n",
        "  #\n",
        "  #   file_path:      Base directory where models and embeddings will be saved\n",
        "  #\n",
        "  #   embedding_type: Supports 3 types of embedding types: \n",
        "  #                     - 'sen_avg':  Averages embeddings for every sentence, embedding vector size per \n",
        "  #                                   essay: (max_sentences * 768)\n",
        "  #                     - 'para_avg\": Averages embeddings first for every sentence & then averages these \n",
        "  #                                   for the full essay, embedding vector size per essay: (1x768)\n",
        "  #                     - 'full_emb\": Creates embedding for entire sentence - embedding vector size per\n",
        "  #                                   essay: (max_words * 768)\n",
        "  #\n",
        "  #   max_sentences:  Relevant for sentence average (sen_avg) embedding type: maximum no of sentences \n",
        "  #                   permissable in an essay\n",
        "  #\n",
        "  #   max_words:      Relevant for the full embedding (full_emb) embedding type: maximum no of words\n",
        "  #                   permissable in an essay\n",
        "  #\n",
        "  #   hstate:         How embedding is computed using BERT's hidden states:\n",
        "  #                     - 'last4sum': Embedding computed by summing last 4 hidden state sof instantited BERT model\n",
        "  #                     - 'second_last':  Embedding computed by picking the 2nd last hidden state of instantiaed BERT model\n",
        "  #\n",
        "  from transformers import BertModel, BertConfig, BertTokenizer\n",
        "\n",
        "  print (\"Preparing Embeddings...\")\n",
        "  print (\"Model Type: \", model_type)\n",
        "  print (\"Embedding Type: \", embedding_type)\n",
        "  print (\"hState: \", hstate)\n",
        "  print (\"Save File Directory: \", file_path)\n",
        "  if (not df.empty):\n",
        "    print (\"Dataframe provided, Size: \", df.shape)\n",
        "\n",
        "  if (model_type =='semantic'):\n",
        "    if (train_or_test=='train'):\n",
        "      lhs_path = file_path + '/lhs_train.pt'\n",
        "      y_path = file_path + '/y_train.pt'\n",
        "    else:\n",
        "      if (train_or_test == 'test'):\n",
        "        lhs_path = file_path + '/lhs_test.pt'\n",
        "        y_path = file_path + '/y_test.pt'\n",
        "      else:\n",
        "        print (\"Invalid choice for train_or_test. Returning NONE\")\n",
        "        return\n",
        "  else:\n",
        "    if (model_type =='coherence'):\n",
        "      if (train_or_test=='train'):\n",
        "        lhs_path = file_path + '/lhs_coherence_train.pt'\n",
        "        y_path = file_path + '/y_train_coh.pt'\n",
        "      else:\n",
        "        if (train_or_test == 'test'):\n",
        "          lhs_path = file_path + '/lhs_coherence_test.pt'\n",
        "          y_path = file_path + '/y_test_coh.pt'\n",
        "        else:\n",
        "          print (\"Invalid choice for train_or_test. Returning NONE\")\n",
        "          return\n",
        "    else:\n",
        "      if (model_type =='p_rel'):\n",
        "        if (train_or_test=='train'):\n",
        "          lhs_path = file_path + '/lhs_prel_train.pt'\n",
        "          y_path = file_path + '/y_train_prel.pt'\n",
        "        else:\n",
        "          if (train_or_test == 'test'):\n",
        "            lhs_path = file_path + '/lhs_prel_test.pt'\n",
        "            y_path = file_path + '/y_test_prel.pt'\n",
        "          else:\n",
        "            print (\"Invalid choice for train_or_test. Returning NONE\")\n",
        "            return\n",
        "      else:\n",
        "        print (\"Please choose a valid model - one of SEMANTIC, COHERENCE or PREL\")\n",
        "        return\n",
        "\n",
        "  if (load_from_file == True):\n",
        "    print (\"Loading existing embeddings from file...\")\n",
        "    print (\"LHS File chosen: \", lhs_path)\n",
        "    print (\"Y File chosen: \", y_path)\n",
        "    lhs = torch.load(lhs_path)\n",
        "    y_gold = torch.load(y_path)\n",
        "    print (\"Loaded, Size of LHS embeddings: \", lhs.shape)\n",
        "    print (\"Loaded, Size of y Gold: \", y_gold.shape)\n",
        "  else:\n",
        "    print (\"Generating embeddings from scratch & extracting the Y_Gold from dataframe...\\n\")\n",
        "    \n",
        "    if (df.empty):\n",
        "      print (\"Null dataframe, please provide a valid dataframe\")\n",
        "      return\n",
        "\n",
        "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "    config = BertConfig.from_pretrained('bert-base-uncased', output_hidden_states=True)\n",
        "    model = BertModel.from_pretrained('bert-base-uncased', config=config)\n",
        "\n",
        "    if (model_type=='p_rel'):\n",
        "        essays = df['combined_essay']\n",
        "    else:\n",
        "        essays = df['essay']\n",
        "    y_gold = df[gold_field]\n",
        "    sentences = []\n",
        "    tokenize_sentences = []\n",
        "    \n",
        "    cuda = torch.device('cuda')\n",
        "\n",
        "    if (embedding_type == 'sen_avg'):\n",
        "      print (\"Using Sentence Average Embedding...\")\n",
        "      # Embeddings for the dataframe provided\n",
        "      lhs = torch.empty((len(essays),max_sentences,768), dtype=torch.float)\n",
        "      emb_for_padding = tokenizer.encode_plus(\"\", add_special_tokens=True, truncation=True, padding=\"max_length\", return_tensors=\"pt\", max_length=10)\n",
        "      tt = torch.tensor(emb_for_padding['input_ids'])\n",
        "      output = model(tt)\n",
        "      if (hstate=='second_last'):\n",
        "        # getting the 2nd last layer\n",
        "        lhs_for_padding = output.hidden_states[11]\n",
        "      else:\n",
        "        if (hstate=='last4sum'):\n",
        "          lhs_for_padding = output.hidden_states[12] + output.hidden_states[11] + output.hidden_states[10] + output.hidden_states[9]\n",
        "        else:\n",
        "          print (\"Invalid value provided for hstate\")\n",
        "          return\n",
        "      #lhs_for_padding = model(tt)[2][-2]\n",
        "      lhs_for_padding_np = np.array(lhs_for_padding.detach().numpy())\n",
        "      lhs_for_padding_mean = np.mean(lhs_for_padding_np,axis=1)\n",
        "      lhs_avg_for_padding = torch.tensor(lhs_for_padding_mean[0])\n",
        "    \n",
        "      for j,essay in enumerate(essays):\n",
        "        if (j%200 ==0):\n",
        "          print (\"Iteration: \", j)\n",
        "\n",
        "        sentences = re.split('\\. |\\? |! ', essay)\n",
        "        sen_length = len(sentences)\n",
        "        lhs_sentence_avg = np.zeros((max_sentences,768), dtype=float)\n",
        "\n",
        "        #for i in range(min(85,len(sentences))):\n",
        "        for i,s in enumerate(sentences):\n",
        "          if (i>=max_sentences):\n",
        "            break\n",
        "          tokenize_sentence = tokenizer.encode(sentences[i],add_special_tokens=True, max_length=512, truncation=True)\n",
        "          tt = torch.tensor(tokenize_sentence)\n",
        "          tts = tt.reshape(1,len(tt))\n",
        "          output = model(tts)\n",
        "          if (hstate=='second_last'):\n",
        "            # getting the 2nd last layer\n",
        "            lhs_sentence = output.hidden_states[11]\n",
        "          else:\n",
        "            if (hstate=='last4sum'):\n",
        "              lhs_sentence = output.hidden_states[12] + output.hidden_states[11] + output.hidden_states[10] + output.hidden_states[9]\n",
        "            else:\n",
        "              print (\"Invalid value provided for hstate\")\n",
        "              return\n",
        "          #lhs_sentence = model(tts).hidden_states[11]\n",
        "          lhs_sentence_np = np.array(lhs_sentence.detach().numpy())\n",
        "          lhs_sentence_np_mean = np.mean(lhs_sentence_np,axis=1)\n",
        "          lhs_sentence_avg[i] = lhs_sentence_np_mean[0]\n",
        "  \n",
        "        lhs[j] = torch.tensor(lhs_sentence_avg)\n",
        "\n",
        "        if (sen_length < max_sentences):\n",
        "          for i in range (sen_length, max_sentences):\n",
        "            lhs[j][i]= lhs_avg_for_padding\n",
        "    else:\n",
        "      if (embedding_type =='para_avg'):\n",
        "        print (\"Using Paragraph Average Embedding...\")\n",
        "        lhs = torch.empty((len(essays),1,768), dtype=torch.float)\n",
        "        #lhs = torch.empty((1,768), dtype=torch.float)\n",
        "        #for j in range(len(prompt_data)):\n",
        "        for j,essay in enumerate(essays):\n",
        "          if (j%200 ==0):\n",
        "            print (\"Iteration: \", j)\n",
        "          sentences = split_into_sentences(essay)\n",
        "          sen_length = len(sentences)\n",
        "  \n",
        "          lhs_sentence_avg = np.zeros((1,768), dtype=float)\n",
        "          lhs_avg_sen = np.empty((0,768), dtype=float)\n",
        "\n",
        "          for i in range(min(max_sentences,len(sentences))):\n",
        "            tokenize_sentence = tokenizer.encode(sentences[i],add_special_tokens=True, max_length=512, truncation=True)\n",
        "            tt = torch.tensor(tokenize_sentence)\n",
        "            tts = tt.reshape(1,len(tt))\n",
        "            output = model(tts)\n",
        "            if (hstate=='second_last'):\n",
        "              # getting the 2nd last layer\n",
        "              lhs_sentence = output.hidden_states[11]\n",
        "            else:\n",
        "              if (hstate=='last4sum'):\n",
        "                lhs_sentence = output.hidden_states[12] + output.hidden_states[11] + output.hidden_states[10] + output.hidden_states[9]\n",
        "              else:\n",
        "                print (\"Invalid value provided for hstate\")\n",
        "                return\n",
        "            lhs_sentence_np = np.array(lhs_sentence.detach().numpy())\n",
        "            lhs_sentence_np_mean = np.mean(lhs_sentence_np,axis=1)\n",
        "            lhs_avg_sen = np.append(lhs_avg_sen,lhs_sentence_np_mean, axis=0)\n",
        "\n",
        "          lhs_sentence_avg = np.mean(lhs_avg_sen, axis=0, keepdims=True)\n",
        "          lhs[j] = torch.tensor(lhs_sentence_avg)\n",
        "      else:\n",
        "        if (embedding_type =='full_emb'):\n",
        "          print (\"Embedding Type: Full Embedding ...\")\n",
        "          #lhs = torch.zeros((len(essays),max_words,768), dtype=torch.float)\n",
        "          lhs_np = np.zeros((len(essays), max_words, 768), dtype=float)\n",
        "          for j,essay in enumerate(essays):\n",
        "            if (j%200 ==0):\n",
        "              print (\"Iteration: \", j)\n",
        "            tokenized_essay = tokenizer.encode_plus(essay, add_special_tokens=True, truncation=True, \n",
        "                                                    padding=\"max_length\", max_length=max_words, \n",
        "                                                    return_tensors=\"pt\")\n",
        "          \n",
        "            output = model(**tokenized_essay)\n",
        "            #print (\"HS data type: \", type(output.hidden_states[11]))\n",
        "            if (hstate=='second_last'):\n",
        "              # getting the 2nd last layer\n",
        "              lhs_np[j] = output.hidden_states[11].detach().numpy()\n",
        "            else:\n",
        "              if (hstate=='last4sum'):\n",
        "                lhs_np[j] = (output.hidden_states[12] + output.hidden_states[11] + output.hidden_states[10] + output.hidden_states[9]).detach().numpy()#.reshape(max_words,768)\n",
        "              else:\n",
        "                print (\"Invalid value provided for hstate\")\n",
        "                return\n",
        "            del output\n",
        "\n",
        "          lhs = torch.tensor(lhs_np)\n",
        "          del (lhs_np)\n",
        "          #torch.save(y_gold, y_path)\n",
        "          #torch.save(lhs_np, lhs_path)\n",
        "          #print (\"Full EMb: Saved LHS & Y_gold...\") \n",
        "          #print (\"Full Emb: Returning lhs: Shape: \", lhs.shape)\n",
        "          #print (\"Full Emb: Returning y_gold: Shape: \", y_gold.shape)\n",
        "          #return (torch.tensor(lhs_np), y_gold)\n",
        "\n",
        "    torch.save(lhs, lhs_path)\n",
        "    torch.save(y_gold, y_path)\n",
        "\n",
        "    print (\"Saved LHS & Y_gold...\") \n",
        "    \n",
        "  print (\"Returning lhs: Shape: \", lhs.shape)\n",
        "  print (\"Returning y_gold: Shape: \", y_gold.shape)\n",
        "  return lhs, y_gold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "p7Ikp5jO_Bry"
      },
      "outputs": [],
      "source": [
        "def evaluate_model (model, lhs_test, y_test):\n",
        "  y_pred = model.predict(lhs_test.numpy())\n",
        "  tt1 = np.around(10*y_pred)\n",
        "  tt2 = tt1.reshape(tt1.shape[0],)\n",
        "  pred_values = tt2.astype(int)\n",
        "  tt3 = np.array(10* y_test)\n",
        "  gold_values = tt3.astype(int)\n",
        "  # evaluate the model\n",
        "  result = cohen_kappa_score(gold_values,pred_values,weights='quadratic')\n",
        "  print(\"Kappa Score: {}\".format(result))\n",
        "  yy_p = y_pred.reshape(y_pred.shape[0],)\n",
        "  yy_t = np.array(y_test)\n",
        "  MSE = np.square(np.subtract(yy_t, yy_p)).mean()\n",
        "  RMSE = math.sqrt(MSE)\n",
        "  print (\"MSE: \", MSE)\n",
        "  print (\"RMSE: \", RMSE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9IgDlfaFK2_"
      },
      "source": [
        "## Initializing classes and paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "nazZLnLPXgSg"
      },
      "outputs": [],
      "source": [
        "# Initialize the RUN configuration\n",
        "\n",
        "run_semantic = True\n",
        "run_coherence = True\n",
        "run_prelevance = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ML2bW5q5YFvE"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import torch\n",
        "import transformers as ppb\n",
        "import warnings\n",
        "\n",
        "# PArent Directory on Google Drive where all moels and other data is stored\n",
        "#model_path = '/content/drive/MyDrive/Colab Notebooks/AES/experiment_1'\n",
        "model_path = '/content/drive/MyDrive/Colab Notebooks/AES/experiment_XX'\n",
        "sem_model_save_path = model_path + '/lstm_model.pt'\n",
        "coh_model_save_path = model_path + '/coh-lstm_model-latest.pt'\n",
        "prel_model_save_path = model_path + '/prel-lstm_model-latest.pt'\n",
        "\n",
        "data_with_errors_path = model_path + '/data_w_errors.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jcEUX7UtOIuY"
      },
      "outputs": [],
      "source": [
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5WTR9wYPlaRM"
      },
      "outputs": [],
      "source": [
        "regressor = xgb.XGBRegressor(\n",
        "    n_estimators=200,\n",
        "    reg_lambda=1,\n",
        "    gamma=0,\n",
        "    eta = 0.1,\n",
        "    max_depth=6,\n",
        "    objective='reg:squarederror'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxZIz1NBxAlJ"
      },
      "source": [
        "## CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QH_431bOxYr2"
      },
      "outputs": [],
      "source": [
        "def get_model_CNN(Hidden_dim1=400, Hidden_dim2=128, return_sequences = True, dropout=0.5, recurrent_dropout=0.4, input_size=768,output_dims=10380, activation='relu', bidirectional = False):\n",
        "    \"\"\"Define the model.\"\"\"\n",
        "    inputs = Input(shape=(768,1))\n",
        "    x = Conv1D(64, 3, strides=1, padding='same', activation='relu')(inputs)\n",
        "    #Cuts the size of the output in half, maxing over every 2 inputs\n",
        "    x = MaxPooling1D(pool_size=2)(x)\n",
        "    x = Conv1D(128, 3, strides=1, padding='same', activation='relu')(x)\n",
        "    x = GlobalMaxPooling1D()(x) \n",
        "    outputs = Dense(output_dims, activation='relu')(x)\n",
        "    model = Model(inputs=inputs, outputs=outputs, name='CNN')\n",
        "    model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mae','mse'])\n",
        "    model.summary()\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "id": "Y5CAHVv4z5Od",
        "outputId": "e086a76a-0ce4-49bd-f1de-291cb05a6e74"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-44-2209a21e98e1>\"\u001b[0;36m, line \u001b[0;32m68\u001b[0m\n\u001b[0;31m    input.size() = (batch_size, num_seq, embedding_length)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m can't assign to function call\n"
          ]
        }
      ],
      "source": [
        "class CNN(nn.Module):\n",
        "\tdef __init__(self, batch_size, output_size, in_channels, out_channels, kernel_heights, stride, padding, keep_probab, vocab_size, embedding_length, weights):\n",
        "\t\tsuper(CNN, self).__init__()\n",
        "\t\t\n",
        "\t\t\"\"\"\n",
        "\t\tArguments\n",
        "\t\t---------\n",
        "\t\tbatch_size : Size of each batch which is same as the batch_size of the data returned by the TorchText BucketIterator\n",
        "\t\toutput_size : 2 = (pos, neg)\n",
        "\t\tin_channels : Number of input channels. Here it is 1 as the input data has dimension = (batch_size, num_seq, embedding_length)\n",
        "\t\tout_channels : Number of output channels after convolution operation performed on the input matrix\n",
        "\t\tkernel_heights : A list consisting of 3 different kernel_heights. Convolution will be performed 3 times and finally results from each kernel_height will be concatenated.\n",
        "\t\tkeep_probab : Probability of retaining an activation node during dropout operation\n",
        "\t\tvocab_size : Size of the vocabulary containing unique words\n",
        "\t\tembedding_length : Embedding dimension of GloVe word embeddings\n",
        "\t\tweights : Pre-trained GloVe word_embeddings which we will use to create our word_embedding look-up table\n",
        "\t\t--------\n",
        "\t\t\n",
        "\t\t\"\"\"\n",
        "\t\tself.batch_size = batch_size\n",
        "\t\tself.output_size = output_size\n",
        "\t\tself.in_channels = in_channels\n",
        "\t\tself.out_channels = out_channels\n",
        "\t\tself.kernel_heights = kernel_heights\n",
        "\t\tself.stride = stride\n",
        "\t\tself.padding = padding\n",
        "\t\tself.vocab_size = vocab_size\n",
        "\t\tself.embedding_length = embedding_dim[0]\n",
        "\t\t\n",
        "\t\t# self.word_embeddings = nn.Embedding(vocab_size, embedding_length)\n",
        "\t\t# self.word_embeddings.weight = nn.Parameter(weights, requires_grad=False)\n",
        "\n",
        "\t\tself.conv1 = nn.Conv2d(in_channels, out_channels, (kernel_heights[0], embedding_length), stride, padding)\n",
        "\t\tself.conv2 = nn.Conv2d(in_channels, out_channels, (kernel_heights[1], embedding_length), stride, padding)\n",
        "\t\tself.conv3 = nn.Conv2d(in_channels, out_channels, (kernel_heights[2], embedding_length), stride, padding)\n",
        "\t\tself.dropout = nn.Dropout(keep_probab)\n",
        "\t\tself.label = nn.Linear(len(kernel_heights)*out_channels, output_size)\n",
        "\t\n",
        "\tdef conv_block(self, input, conv_layer):\n",
        "\t\tconv_out = conv_layer(input)# conv_out.size() = (batch_size, out_channels, dim, 1)\n",
        "\t\tactivation = F.relu(conv_out.squeeze(3))# activation.size() = (batch_size, out_channels, dim1)\n",
        "\t\tmax_out = F.max_pool1d(activation, activation.size()[2]).squeeze(2)# maxpool_out.size() = (batch_size, out_channels)\n",
        "\t\t\n",
        "\t\treturn max_out\n",
        "\t\n",
        "\tdef forward(self, input_sentences, batch_size=None):\n",
        "\t\t\n",
        "\t\t\"\"\"\n",
        "\t\tThe idea of the Convolutional Neural Netwok for Text Classification is very simple. We perform convolution operation on the embedding matrix \n",
        "\t\twhose shape for each batch is (num_seq, embedding_length) with kernel of varying height but constant width which is same as the embedding_length.\n",
        "\t\tWe will be using ReLU activation after the convolution operation and then for each kernel height, we will use max_pool operation on each tensor \n",
        "\t\tand will filter all the maximum activation for every channel and then we will concatenate the resulting tensors. This output is then fully connected\n",
        "\t\tto the output layers consisting two units which basically gives us the logits for both positive and negative classes.\n",
        "\t\t\n",
        "\t\tParameters\n",
        "\t\t----------\n",
        "\t\tinput_sentences: input_sentences of shape = (batch_size, num_sequences)\n",
        "\t\tbatch_size : default = None. Used only for prediction on a single sentence after training (batch_size = 1)\n",
        "\t\t\n",
        "\t\tReturns\n",
        "\t\t-------\n",
        "\t\tOutput of the linear layer containing logits for pos & neg class.\n",
        "\t\tlogits.size() = (batch_size, output_size)\n",
        "\t\t\n",
        "\t\t\"\"\"\n",
        "\t\t\n",
        "\t\tinput = input_sentences\n",
        "\t\t# input.size() = (batch_size, num_seq, embedding_length)\n",
        "\t\t# print(\"Input size is: \", input.size())\n",
        "\t\tinput = input.unsqueeze(1)\n",
        "\t\tinput.size() = (batch_size, 1, num_seq, embedding_length)\n",
        "\t\tmax_out1 = self.conv_block(input, self.conv1)\n",
        "\t\tmax_out2 = self.conv_block(input, self.conv2)\n",
        "\t\tmax_out3 = self.conv_block(input, self.conv3)\n",
        "\t\t\n",
        "\t\tall_out = torch.cat((max_out1, max_out2, max_out3), 1)\n",
        "\t\t# all_out.size() = (batch_size, num_kernels*out_channels)\n",
        "\t\tfc_in = self.dropout(all_out)\n",
        "\t\t# fc_in.size()) = (batch_size, num_kernels*out_channels)\n",
        "\t\tlogits = self.label(fc_in)\n",
        "\t\t\n",
        "\t\treturn logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yiVGxmExxc05"
      },
      "outputs": [],
      "source": [
        "class CNN(nn.Module):   \n",
        "    def __init__(self, batch_size, output_size, in_channels, out_channels, kernel_heights, stride, padding, keep_probab, embedding_dim):\n",
        "        super(CNN, self).__init__()\n",
        "  \n",
        "        self.batch_size = batch_size\n",
        "        self.output_size = output_size\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.kernel_heights = kernel_heights\n",
        "        self.stride = stride\n",
        "        self.padding = padding\n",
        "            # self.vocab_size = vocab_size\n",
        "        self.embedding_length = embedding_dim[1]\n",
        "        self.num_sentences = embedding_dim[0]\n",
        "        # self.sentence_embeddings = essay_embedding\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, (kernel_heights[0], embedding_dim[1]), stride, padding)\n",
        "        self.conv2 = nn.Conv2d(in_channels, out_channels, (kernel_heights[1], embedding_dim[1]), stride, padding)\n",
        "        self.conv3 = nn.Conv2d(in_channels, out_channels, (kernel_heights[2], embedding_dim[1]), stride, padding)\n",
        "        self.dropout = nn.Dropout(keep_probab)\n",
        "        self.label = nn.Linear(len(kernel_heights)*out_channels, output_size)\n",
        "\t\n",
        "    def conv_block(self, input, conv_layer):\n",
        "        conv_out = conv_layer(input)# conv_out.size() = (batch_size, out_channels, dim, 1)\n",
        "        activation = F.relu(conv_out.squeeze(3))# activation.size() = (batch_size, out_channels, dim1)\n",
        "        print (\"Activation Shape:\", activation.shape)\n",
        "        max_out = F.max_pool1d(activation, activation.size()[2]).squeeze(2)# maxpool_out.size() = (batch_size, out_channels)\n",
        "\n",
        "        return max_out\n",
        "\t\n",
        "    def forward(self, input_sentences, batch_size=None):    \n",
        "\t\t\n",
        "        \"\"\"\n",
        "        The idea of the Convolutional Neural Netwok for Text Classification is very simple. We perform convolution operation on the embedding matrix \n",
        "        whose shape for each batch is (num_seq, embedding_length) with kernel of varying height but constant width which is same as the embedding_length.\n",
        "        We will be using ReLU activation after the convolution operation and then for each kernel height, we will use max_pool operation on each tensor \n",
        "        and will filter all the maximum activation for every channel and then we will concatenate the resulting tensors. This output is then fully connected\n",
        "        to the output layers consisting two units which basically gives us the logits for both positive and negative classes.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        input_sentences: input_sentences of shape = (batch_size, num_sequences)\n",
        "        batch_size : default = None. Used only for prediction on a single sentence after training (batch_size = 1)\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        Output of the linear layer containing logits for pos & neg class.\n",
        "        logits.size() = (batch_size, output_size)\n",
        "\n",
        "        \"\"\"\n",
        "\t\t\n",
        "        input = input_sentences\n",
        "        # input.size = (self.batch_size, num_seq, self.embedding_length)\n",
        "        input = input.unsqueeze(1)\n",
        "        # input.size = (self.batch_size, 1, num_seq, self.embedding_length)\n",
        "        max_out1 = self.conv_block(input, self.conv1)\n",
        "        print(max_out1.shape)\n",
        "        max_out2 = self.conv_block(input, self.conv2)\n",
        "        max_out3 = self.conv_block(input, self.conv3)\n",
        "\n",
        "        all_out = torch.cat((max_out1, max_out2, max_out3), 1)\n",
        "        # all_out.size() = (batch_size, num_kernels*out_channels)\n",
        "        fc_in = self.dropout(all_out)\n",
        "        # fc_in.size()) = (batch_size, num_kernels*out_channels)\n",
        "        logits = self.label(fc_in)\n",
        "\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "krSSj_g_q35C"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "st87AaaAQZn8"
      },
      "outputs": [],
      "source": [
        "def clip_gradient(model, clip_value):\n",
        "    params = list(filter(lambda p: p.grad is not None, model.parameters()))\n",
        "    for p in params:\n",
        "        p.grad.data.clamp_(-clip_value, clip_value)\n",
        "    \n",
        "def train_model(model, lhs_train, y_train, epoch):\n",
        "    total_epoch_loss = 0\n",
        "    total_epoch_acc = 0\n",
        "    model.cuda()\n",
        "    optim = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()))\n",
        "    steps = 0\n",
        "    model.train()\n",
        "    for i in range(0,len(lhs_train),32):\n",
        "        text = lhs_train[i:i+32]\n",
        "        target = y_train[i:i+32]\n",
        "        # print(\"text shape: \", text.shape)\n",
        "        # print(\"target shape: \", target.shape)\n",
        "        target = torch.autograd.Variable(target).long()\n",
        "        if torch.cuda.is_available():\n",
        "            text = text.cuda()\n",
        "            target = target.cuda()\n",
        "        if (text.size()[0] is not 32):# One of the batch returned by BucketIterator has length different than 32.\n",
        "            continue\n",
        "        optim.zero_grad()\n",
        "        prediction = model(text)\n",
        "        loss = nn.CrossEntropyLoss(prediction, target)\n",
        "        num_corrects = (torch.max(prediction, 1)[1].view(target.size()).data == target.data).float().sum()\n",
        "        acc = 100.0 * num_corrects/len(batch)\n",
        "        loss.backward()\n",
        "        clip_gradient(model, 1e-1)\n",
        "        optim.step()\n",
        "        steps += 1\n",
        "        \n",
        "        if steps % 100 == 0:\n",
        "            print (f'Epoch: {epoch+1}, Idx: {idx+1}, Training Loss: {loss.item():.4f}, Training Accuracy: {acc.item(): .2f}%')\n",
        "        \n",
        "        total_epoch_loss += loss.item()\n",
        "        total_epoch_acc += acc.item()\n",
        "        \n",
        "    return total_epoch_loss/len(train_iter), total_epoch_acc/len(train_iter)\n",
        "\n",
        "def eval_model(model, val_iter):\n",
        "    total_epoch_loss = 0\n",
        "    total_epoch_acc = 0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for idx, batch in enumerate(val_iter):\n",
        "            text = batch.text[0]\n",
        "            if (text.size()[0] is not 32):\n",
        "                continue\n",
        "            target = batch.label\n",
        "            target = torch.autograd.Variable(target).long()\n",
        "            if torch.cuda.is_available():\n",
        "                text = text.cuda()\n",
        "                target = target.cuda()\n",
        "            prediction = model(text)\n",
        "            loss = loss_fn(prediction, target)\n",
        "            num_corrects = (torch.max(prediction, 1)[1].view(target.size()).data == target.data).sum()\n",
        "            acc = 100.0 * num_corrects/len(batch)\n",
        "            total_epoch_loss += loss.item()\n",
        "            total_epoch_acc += acc.item()\n",
        "\n",
        "    return total_epoch_loss/len(val_iter), total_epoch_acc/len(val_iter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0ZD6wm7HIpy",
        "outputId": "fda0d832-9761-4b50-8e53-2621f03382ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([6488, 11])\n"
          ]
        }
      ],
      "source": [
        "#from keras.utils import np_utils\n",
        "#from numpy import np_utils\n",
        "y_train_labels = y_train.apply(lambda x: int(10*x))\n",
        "y_train_tensor = torch.tensor(y_train_labels.values)\n",
        "one_hot_y = F.one_hot(y_train_tensor, 11)\n",
        "if torch.cuda.is_available():\n",
        "    one_hot_y = one_hot_y.cuda()\n",
        "print (one_hot_y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3n1b3PxJfrY",
        "outputId": "755596cc-6c9f-496f-e2d6-812da42bcbc9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "6     1870\n",
              "5      909\n",
              "7      809\n",
              "3      719\n",
              "10     667\n",
              "4      613\n",
              "2      363\n",
              "8      310\n",
              "0      224\n",
              "9        2\n",
              "1        2\n",
              "Name: normalized_score, dtype: int64"
            ]
          },
          "execution_count": 124,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train_labels.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJ-hDeY-O98T",
        "outputId": "989aae1f-cca1-4723-99aa-9485b838744d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([6488])"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train_tensor.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        },
        "id": "Z9V0ERxyFkC0",
        "outputId": "2e644758-5c79-4435-d08c-effbe4529ff2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:652: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-c48728c103e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlhs_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;31m# val_loss, val_acc = eval_model(model, valid_iter)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-49-ff52a82f1e73>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, lhs_train, y_train, epoch)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mnum_corrects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100.0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_corrects\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   1114\u001b[0m     def __init__(self, weight: Optional[Tensor] = None, size_average=None, ignore_index: int = -100,\n\u001b[1;32m   1115\u001b[0m                  reduce=None, reduction: str = 'mean') -> None:\n\u001b[0;32m-> 1116\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1117\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_WeightedLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_Loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'mean'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_WeightedLoss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'weight'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_Loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py\u001b[0m in \u001b[0;36mlegacy_get_string\u001b[0;34m(size_average, reduce, emit_warning)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mreduce\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'mean'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Boolean value of Tensor with more than one value is ambiguous"
          ]
        }
      ],
      "source": [
        "# loss_fn = F.categorical_crossentropy\n",
        "\n",
        "for epoch in range(10):\n",
        "    train_loss, train_acc = train_model(model, lhs_train, y_train_tensor, epoch)\n",
        "    # val_loss, val_acc = eval_model(model, valid_iter)\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02}, Train Loss: {train_loss:.3f}, Train Acc: {train_acc:.2f}%')\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LOkUCU99X6c0"
      },
      "outputs": [],
      "source": [
        "total_epoch_loss = 0\n",
        "total_epoch_acc = 0\n",
        "model.cuda()\n",
        "optim = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dR9Hj4LtW5sd"
      },
      "outputs": [],
      "source": [
        "text = lhs_train[:32]\n",
        "#target = one_hot_y[:32]\n",
        "target = y_train_tensor[:32]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1xaPI93Zgdt",
        "outputId": "79ff0d7c-2871-4f2d-dd8d-af8288fb0359"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([32, 128, 768])\n",
            "torch.Size([32])\n"
          ]
        }
      ],
      "source": [
        "print (text.shape)\n",
        "print (target.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OqxqxnCuXYcL"
      },
      "outputs": [],
      "source": [
        "target = torch.autograd.Variable(target).long()\n",
        "if torch.cuda.is_available():\n",
        "    text = text.cuda()\n",
        "    target = target.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZvBNUNtXqGU",
        "outputId": "9ea6132e-c720-4fd3-febf-0641be7d090f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Activation Shape: torch.Size([32, 32, 128])\n",
            "torch.Size([32, 32])\n",
            "Activation Shape: torch.Size([32, 32, 127])\n",
            "Activation Shape: torch.Size([32, 32, 126])\n",
            "Size of prediction: torch.Size([32, 11])\n",
            "tensor([-1.1847, -0.3497, -0.2948, -1.7616,  0.8465, -1.2724,  1.5663, -0.0714,\n",
            "         1.1757, -1.3443, -2.0278], device='cuda:0', grad_fn=<SelectBackward>)\n",
            "tensor(2, device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "optim.zero_grad()\n",
        "prediction = model(text)\n",
        "print (\"Size of prediction:\", prediction.shape)\n",
        "print (prediction[5])\n",
        "print (target[5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tctw1zK_uOjD",
        "outputId": "319561ca-150c-4c26-f236-b9931915b21c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([20])\n",
            "tensor([1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0])\n"
          ]
        }
      ],
      "source": [
        "Train ={}\n",
        "Train[\"Label\"] = torch.empty(20, dtype=torch.long).random_(2)\n",
        "print (Train[\"Label\"].shape)\n",
        "print (Train[\"Label\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "J1sTARfNcgoa",
        "outputId": "c7d79978-2680-4417-9388-e5eb6e933cbe"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-138-efcf64c18f47>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnum_corrects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100.0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_corrects\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mclip_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e-1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'batch' is not defined"
          ]
        }
      ],
      "source": [
        "loss = nn.CrossEntropyLoss()\n",
        "loss(prediction, target)\n",
        "num_corrects = (torch.max(prediction, 1)[1].view(target.size()).data == target.data).float().sum()\n",
        "acc = 100.0 * num_corrects/len(batch)\n",
        "loss.backward()\n",
        "clip_gradient(model, 1e-1)\n",
        "optim.step()\n",
        "steps += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCicVVh7m4zP"
      },
      "source": [
        "## CNN BERT 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dZmKJ2YMaZzH"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "output_size = 11\n",
        "in_channels = 1\n",
        "out_channels = 32\n",
        "kernel_heights = [1,2,3]\n",
        "stride = 1\n",
        "padding = 0\n",
        "keep_probab = 0.5\n",
        "embedding_dims = (128,768)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pmtfzNp3nhV-"
      },
      "outputs": [],
      "source": [
        "model = CNN(batch_size, output_size, in_channels, out_channels, kernel_heights, stride, padding, keep_probab, embedding_dims)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCFfSVorwUpy",
        "outputId": "dceacc2d-d9a6-4a3b-fbf1-2fa60bf6cf4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Preparing Embeddings...\n",
            "Model Type:  semantic\n",
            "Embedding Type:  sen_avg\n",
            "hState:  last4sum\n",
            "Save File Directory:  /content/drive/MyDrive/Colab Notebooks/AES/experiment_XX\n",
            "Dataframe provided, Size:  (6488, 6)\n",
            "Loading existing embeddings from file...\n",
            "LHS File chosen:  /content/drive/MyDrive/Colab Notebooks/AES/experiment_XX/lhs_train.pt\n",
            "Y File chosen:  /content/drive/MyDrive/Colab Notebooks/AES/experiment_XX/y_train.pt\n",
            "Loaded, Size of LHS embeddings:  torch.Size([6488, 128, 768])\n",
            "Loaded, Size of y Gold:  (6488,)\n",
            "Returning lhs: Shape:  torch.Size([6488, 128, 768])\n",
            "Returning y_gold: Shape:  (6488,)\n"
          ]
        }
      ],
      "source": [
        "lhs_train, y_train = prepare_embeddings_updated (tpd_train, model_type='semantic', train_or_test='train', load_from_file=load_bert_sem, embedding_type=embedding, max_words=max_words_for_full_emb_sem, file_path=model_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOZYLJMq5rc8"
      },
      "source": [
        "##CNN BERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sieJJHAX6i2M"
      },
      "outputs": [],
      "source": [
        "use_gpu = True\n",
        "seed = 42\n",
        "max_length = 64\n",
        "batch_size = 16\n",
        "lr = 2e-5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-wdhcuV29fhG"
      },
      "outputs": [],
      "source": [
        "from transformers import BertModel, BertConfig, BertTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "Sg8UQLNy9UMP",
        "outputId": "99fe6c9d-56e6-4040-cc88-dbd4cbf9845f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e0c5059d8b1b4e6fa80b19416974d560",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "65d607cbdb474024aecfcd8137eec006",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "447ef8d4bf7046ab9360f6f54f0c5e9e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c82d9fff7da44c8ea665222025473f81",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b361649a109248dca3a7e450e6903d35",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "config = BertConfig.from_pretrained('bert-base-uncased', output_hidden_states=True)\n",
        "model = BertModel.from_pretrained('bert-base-uncased', config=config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UviBDkjj37ZN",
        "outputId": "68466fe2-6169-4328-d0f3-63f1005e080e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tt shape: torch.Size([512])\n",
            "tts shape: torch.Size([1, 512])\n",
            "Stacked size: torch.Size([1, 4, 512, 768])\n",
            "Squeezed size: torch.Size([1, 4, 512, 768])\n",
            "Size of conv output:  torch.Size([32, 512, 1])\n",
            "Size of relu output (after squeeze):  torch.Size([1, 32, 511])\n"
          ]
        }
      ],
      "source": [
        "ts = tokenizer.encode('Hello, how are you doing today?',add_special_tokens=True, max_length=512, padding=\"max_length\", truncation=True)\n",
        "tt = torch.tensor(ts)\n",
        "tts = tt.reshape(1,len(tt))\n",
        "print (\"tt shape:\", tt.shape)\n",
        "print (\"tts shape:\", tts.shape)\n",
        "output = model(tts)\n",
        "ooo1 = output.hidden_states[12] + output.hidden_states[11] + output.hidden_states[10] + output.hidden_states[9]\n",
        "ooo2 = output[2][-4:]\n",
        "# print (\"Size ADDED:\", ooo1.shape)\n",
        "# print (\"Size CONCAT 0:\", ooo2[0].shape)\n",
        "# print (\"Size CONCAT 1:\", ooo2[1].shape)\n",
        "# print (\"Size CONCAT 2:\", ooo2[2].shape)\n",
        "# print (\"Size CONCAT 3:\", ooo2[3].shape)\n",
        "x = torch.stack(ooo2, dim=1)\n",
        "print (\"Stacked size:\", x.shape)\n",
        "xx = x.squeeze(3)\n",
        "print (\"Squeezed size:\", xx.shape)\n",
        "num_filters = 32\n",
        "embed_size = 768\n",
        "filter_sizes = [1,2,3,4,5]\n",
        "#conv = nn.Conv2d(4, num_filters, (1, embed_size))\n",
        "conv = nn.ModuleList([nn.Conv2d(4, num_filters, (K, embed_size)) for K in filter_sizes])\n",
        "cnx = conv[0](xx)\n",
        "print(\"Size of conv output: \", cnx[0].shape)\n",
        "relx = [F.relu(cnx(x)).squeeze(3) for cnx in conv] \n",
        "print(\"Size of relu output (after squeeze): \", relx[1].shape)\n",
        "#mpoolx = [F.max_pool1d(relx[0], relx[0].size(2)).squeeze(2)]\n",
        "# mpoolx = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in relx] \n",
        "# out = torch.cat(mpoolx, 1)\n",
        "# print (\"Con Size:\", cnx.shape)\n",
        "# print (\"post rel Size:\", relx[0].size())\n",
        "# print (\"post rel Size 2:\", relx[0].size(2))\n",
        "# print (\"Post maxpool size:\", mpoolx[0].size())\n",
        "# print (\"Out:\", out.size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGmeEY105kfU",
        "outputId": "3518e6b4-4912-48b2-e8c0-1b72d2df5cac"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.4199, 0.4277, 0.6975, 0.8807, 1.0234, 0.5523, 0.0000, 0.4113, 0.7582,\n",
              "         0.4670, 0.6480, 1.2027, 0.7079, 0.8579, 0.7264, 0.2271, 0.6367, 0.3200,\n",
              "         0.3867, 1.1314, 0.4128, 0.4859, 0.5273, 0.6375, 1.1721, 0.8330, 1.1401,\n",
              "         0.7078, 0.3995, 0.7792, 1.1293, 1.0822]], grad_fn=<SqueezeBackward1>)"
            ]
          },
          "execution_count": 21,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mpoolx[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9swbj5DCr0i",
        "outputId": "0a3ba584-b93c-4ae0-a9d7-82a4f702f848"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(None, 1, 128, 1, 32)\n",
            "(None, 1, 127, 1, 32)\n",
            "(None, 1, 126, 1, 32)\n",
            "(None, 1, 125, 1, 32)\n",
            "(None, 1, 124, 1, 32)\n",
            "Con length: 5\n",
            "Size CONCAT: 0 (None, 1, 128, 1, 32)\n",
            "Squeeze:  (1, 128, 1, 32)\n",
            "Size CONCAT: 1 (None, 1, 127, 1, 32)\n",
            "Squeeze:  (1, 127, 1, 32)\n",
            "Size CONCAT: 2 (None, 1, 126, 1, 32)\n",
            "Squeeze:  (1, 126, 1, 32)\n",
            "Size CONCAT: 3 (None, 1, 125, 1, 32)\n",
            "Squeeze:  (1, 125, 1, 32)\n",
            "Size CONCAT: 4 (None, 1, 124, 1, 32)\n",
            "Squeeze:  (1, 124, 1, 32)\n"
          ]
        }
      ],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.layers import Embedding, Input, LSTM, Dense, Dropout, Lambda, Flatten, Bidirectional, Conv2D, Conv1D, MaxPooling1D, GlobalMaxPooling1D, Concatenate\n",
        "from keras.models import Sequential,Model, load_model, model_from_config\n",
        "import keras.backend as K\n",
        "\n",
        "num_filters = 32\n",
        "embed_size = 768\n",
        "filter_sizes = [1,2,3,4,5]\n",
        "input_shape = [1,128,768,4]\n",
        "#conv_input = Input(shape=input_shape[1:])\n",
        "conv_input = Input(shape=input_shape)\n",
        "conv_op = []\n",
        "mp_op = []\n",
        "#conv_op = layers.Conv2D(num_filters, (2,768), input_shape=input_shape[1:], activation=\"relu\")(encoder_input)\n",
        "for K in filter_sizes:\n",
        "  print((Conv2D(num_filters, (K, embed_size), input_shape=input_shape,activation=\"relu\")(conv_input)).shape)\n",
        "  conv_op.append(Conv2D(num_filters, (K, embed_size), input_shape=input_shape,activation=\"relu\")(conv_input))\n",
        "print (\"Con length:\", len(conv_op))\n",
        "\n",
        "#pooling each parallel conv layer\n",
        "for i in range(0, len(conv_op)):\n",
        "  print (\"Size CONCAT:\", i, conv_op[i].shape)\n",
        "  print (\"Squeeze: \", tf.squeeze(conv_op[i],axis=0).shape)\n",
        "  #mp_op.append(layers.MaxPool1D(conv_op[i].size(2)))(conv_op[i])\n",
        "  mp_op.append(MaxPooling1D(128)(tf.squeeze(conv_op[i])))\n",
        "\n",
        "#print(\"MP OP shape\",mp_op[0].shape)\n",
        "#out = Concatenate(axis=1)(mp_op)\n",
        "#print(\"Output shape: \", out.shape)\n",
        "\n",
        "\n",
        "#print (\"Size:\", conv_op.shape)\n",
        "#x = layers.Conv2D(32, 3, activation=\"relu\")(x)\n",
        "#x = layers.MaxPooling2D(3)(x)\n",
        "#x = layers.Conv2D(32, 3, activation=\"relu\")(x)\n",
        "#x = layers.Conv2D(16, 3, activation=\"relu\")(x)\n",
        "#encoder_output = layers.GlobalMaxPooling2D()(x)\n",
        "\n",
        "#encoder = keras.Model(encoder_input, encoder_output, name=\"encoder\")\n",
        "#encoder.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ub-vUHb8oP1P"
      },
      "outputs": [],
      "source": [
        "inputs = Input(shape=(768,1))\n",
        "x = Conv1D(64, 3, strides=1, padding='same', activation='relu')(inputs)\n",
        "#Cuts the size of the output in half, maxing over every 2 inputs\n",
        "x = MaxPooling1D(pool_size=2)(x)\n",
        "x = Conv1D(128, 3, strides=1, padding='same', activation='relu')(x)\n",
        "x = GlobalMaxPooling1D()(x) \n",
        "outputs = Dense(output_dims, activation='relu')(x)\n",
        "model = Model(inputs=inputs, outputs=outputs, name='CNN')\n",
        "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mae','mse'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "sHn2k7HjY5Zc",
        "outputId": "14492f1e-369f-4b54-9dcf-fa6c15d022d7"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-80a2f9f967e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mCNNBert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbert_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCNNBert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mfilter_sizes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
          ]
        }
      ],
      "source": [
        "class CNNBert(nn.Module):\n",
        "    \n",
        "    def __init__(self, embed_size, bert_model):\n",
        "        super(CNNBert, self).__init__()\n",
        "        filter_sizes = [1,2,3,4,5]\n",
        "        num_filters = 32\n",
        "        self.convs1 = nn.ModuleList([nn.Conv2d(4, num_filters, (K, embed_size)) for K in filter_sizes])\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.fc1 = nn.Linear(len(filter_sizes)*num_filters, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.bert_model = bert_model\n",
        "\n",
        "    def forward(self, x, input_masks, token_type_ids):\n",
        "        x = self.bert_model(x, attention_mask=input_masks, token_type_ids=token_type_ids)[2][-4:]\n",
        "        x = torch.stack(x, dim=1)\n",
        "        x = [F.relu(conv(x)).squeeze(3) for conv in self.convs1] \n",
        "        x = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in x]  \n",
        "        x = torch.cat(x, 1)\n",
        "        x = self.dropout(x)  \n",
        "        logit = self.fc1(x)\n",
        "        return self.sigmoid(logit)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vkInkigh78qX"
      },
      "outputs": [],
      "source": [
        "def prepare_set(text, max_length=128):\n",
        "    \"\"\"returns input_ids, attention_mask, token_type_ids for set of data ready in BERT format\"\"\"\n",
        "    global tokenizer\n",
        "\n",
        "    text = [ split_into_sentences(t) for t in text ]\n",
        "    t = tokenizer.batch_encode_plus(text,\n",
        "                        pad_to_max_length=True,\n",
        "                        add_special_tokens=True,\n",
        "                        max_length=max_length,\n",
        "                        return_tensors='pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PrHUQFMQ6Prj"
      },
      "outputs": [],
      "source": [
        "def train_bert_cnn(x_train, x_dev, y_train, y_dev, n_epochs=10, model_path=\"temp.pt\", batch_size=batch_size):\n",
        "    bert_model = model\n",
        "    \n",
        "    print([len(x) for x in (y_train, y_dev)])\n",
        "    y_train, y_dev = ( torch.FloatTensor(t) for t in (y_train, y_dev) )\n",
        "\n",
        "    train_inputs, train_masks, train_type_ids = prepare_set(x_train, max_length=max_length)\n",
        "    train_data = TensorDataset(train_inputs, train_masks, train_type_ids, y_train)\n",
        "    train_sampler = RandomSampler(train_data)\n",
        "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "    # Create the DataLoader for our dev set.\n",
        "    dev_inputs, dev_masks, dev_type_ids = prepare_set(x_dev, max_length=max_length)\n",
        "    dev_data = TensorDataset(dev_inputs, dev_masks, dev_type_ids, y_dev)\n",
        "    dev_sampler = SequentialSampler(dev_data)\n",
        "    dev_dataloader = DataLoader(dev_data, sampler=dev_sampler, batch_size=batch_size)\n",
        "\n",
        "    model = CNNBert(768, bert_model)\n",
        "    if len(device_ids) > 1 and device.type == \"cuda\":\n",
        "        model = nn.DataParallel(model, device_ids=device_ids)\n",
        "    model.to(device)\n",
        "\n",
        "    optimizer = AdamW(model.parameters(), lr=lr, weight_decay=0.9)\n",
        "    loss_fn = nn.BCELoss()\n",
        "    train_losses, val_losses = [], []\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed) \n",
        "    if device.type == \"cuda\":\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "    total_steps = len(train_dataloader) * n_epochs\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                        num_warmup_steps = 0,\n",
        "                                        num_training_steps = total_steps)\n",
        "\n",
        "    model.zero_grad()\n",
        "    best_score = 0\n",
        "    best_loss = 1e6\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "\n",
        "        start_time = time.time()\n",
        "        train_loss = 0 \n",
        "        model.train(True)\n",
        "\n",
        "        for batch in train_dataloader:\n",
        "            b_input_ids, b_input_mask, b_token_type_ids, b_labels  = tuple(t.to(device) for t in batch)\n",
        "            y_pred = model(b_input_ids, b_input_mask, b_token_type_ids)\n",
        "            loss = loss_fn(y_pred, b_labels.unsqueeze(1))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "            scheduler.step()\n",
        "            model.zero_grad()\n",
        "\n",
        "        train_losses.append(train_loss)\n",
        "        elapsed = time.time() - start_time\n",
        "        model.eval()\n",
        "        val_preds = []\n",
        "\n",
        "        with torch.no_grad(): \n",
        "            val_loss = 0\n",
        "            for batch in dev_dataloader:\n",
        "                b_input_ids, b_input_mask, b_token_type_ids, b_labels  = tuple(t.to(device) for t in batch)\n",
        "                y_pred = model(b_input_ids, b_input_mask, b_token_type_ids)\n",
        "                loss = loss_fn(y_pred, b_labels.unsqueeze(1))\n",
        "                val_loss += loss.item()\n",
        "                y_pred = y_pred.cpu().numpy().flatten()\n",
        "                val_preds += [ int(p >= 0.5) for p in y_pred ] \n",
        "                model.zero_grad()\n",
        "\n",
        "        val_score = f1_score(y_dev.cpu().numpy().tolist(), val_preds)\n",
        "        val_losses.append(val_loss)    \n",
        "        print(\"Epoch %d Train loss: %.4f. Validation F1-Macro: %.4f  Validation loss: %.4f. Elapsed time: %.2fs.\"% (epoch + 1, train_losses[-1], val_score, val_losses[-1], elapsed))\n",
        "\n",
        "        if val_score > best_score:\n",
        "            torch.save(model.state_dict(), \"temp.pt\")\n",
        "            print(classification_report(y_dev.cpu().numpy().tolist(), val_preds, digits=4))\n",
        "            best_score = val_score\n",
        "\n",
        "    model.load_state_dict(torch.load(\"temp.pt\"))\n",
        "    model.to(device)\n",
        "    model.predict = predict.__get__(model)\n",
        "    model.eval()\n",
        "    os.remove(\"temp.pt\")\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "Ve7U7wHb8sOq",
        "outputId": "f102d622-34a1-4017-dad5-21c364426c91"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>essay_id</th>\n",
              "      <th>essay_set</th>\n",
              "      <th>essay</th>\n",
              "      <th>domain1_score</th>\n",
              "      <th>normalized_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6351</td>\n",
              "      <td>9908</td>\n",
              "      <td>4</td>\n",
              "      <td>The author concludes the story w/this paragrap...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6315</td>\n",
              "      <td>9872</td>\n",
              "      <td>4</td>\n",
              "      <td>I believe that the author concludes the story ...</td>\n",
              "      <td>2</td>\n",
              "      <td>0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>304</td>\n",
              "      <td>305</td>\n",
              "      <td>1</td>\n",
              "      <td>Computers, a very much talked about subject. D...</td>\n",
              "      <td>10</td>\n",
              "      <td>0.800000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8023</td>\n",
              "      <td>12771</td>\n",
              "      <td>5</td>\n",
              "      <td>I think in my opion is that the author was ver...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4442</td>\n",
              "      <td>6839</td>\n",
              "      <td>3</td>\n",
              "      <td>The setting that affect the cyclist is the con...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.333333</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  essay_id  ...  domain1_score normalized_score\n",
              "0        6351      9908  ...              1         0.333333\n",
              "1        6315      9872  ...              2         0.666667\n",
              "2         304       305  ...             10         0.800000\n",
              "3        8023     12771  ...              1         0.250000\n",
              "4        4442      6839  ...              1         0.333333\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "execution_count": 46,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tpd_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EGPpeZ2z9wTC"
      },
      "outputs": [],
      "source": [
        "train_bert_cnn(tpd_train.essay, tpd_test, y_train, y_dev, n_epochs=10, model_path=\"temp.pt\", batch_size=batch_size):"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWX6MTxUEZXf"
      },
      "source": [
        "## Training Flow - Obsolete Now"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMHVw2ED7rRt"
      },
      "source": [
        "### Prompt relevance score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbyWp6yPjxMy"
      },
      "source": [
        "#### Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ANZtyq398Akz"
      },
      "outputs": [],
      "source": [
        "#prompts = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/AES/prompts-aes-kaggle-dataset.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Gx7DoaPGKcv"
      },
      "outputs": [],
      "source": [
        "#prompts.columns = ['essay_set','prompt']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R3HhtTk6GusI"
      },
      "outputs": [],
      "source": [
        "#prompts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BTB1WE7qbTHP"
      },
      "outputs": [],
      "source": [
        "#prompt_data_test = tpd_test.merge(prompts,on='essay_set')\n",
        "#prompt_data_train = tpd_train.merge(prompts,on='essay_set')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0-sWskFBKo4d"
      },
      "outputs": [],
      "source": [
        "#prompt_data_train['combined_essay'] = prompt_data_train['prompt'] + prompt_data_train['essay']\n",
        "#prompt_data_test['combined_essay'] = prompt_data_test['prompt'] + prompt_data_test['essay']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yIXfXgq3X_Yb"
      },
      "outputs": [],
      "source": [
        "#prompt_data_train = prompt_data_train.drop(columns=['Unnamed: 0'])\n",
        "#prompt_data_test = prompt_data_test.drop(columns=['Unnamed: 0'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "diIkitYuaESG"
      },
      "outputs": [],
      "source": [
        "#prompt_data_test.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HyBjHAlaPXQg"
      },
      "source": [
        "#### Saving training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qJshxnAD8kyN"
      },
      "outputs": [],
      "source": [
        "#prompt_data_train.to_csv('/content/drive/MyDrive/Colab Notebooks/AES/prompt_train_tpd.csv')\n",
        "#prompt_data_test.to_csv('/content/drive/MyDrive/Colab Notebooks/AES/prompt_test_tpd.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGIfSAjojeYs"
      },
      "source": [
        "#### Load training set\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gCfL_pbQjdKv"
      },
      "outputs": [],
      "source": [
        "#prompt_data_train = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/AES/prompt_train_tpd.csv')\n",
        "#prompt_data_test = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/AES/prompt_test_tpd.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "88Q9EPHgPbZx"
      },
      "outputs": [],
      "source": [
        "#X_train = prompt_data_train\n",
        "#y_train = prompt_data_train['normalized_score']\n",
        "#X_test = prompt_data_test\n",
        "#y_test = prompt_data_test['normalized_score']\n",
        "# X_train.to_csv('/content/drive/MyDrive/Colab Notebooks/AES/X_train_prel.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2GbvgaziPtRH"
      },
      "outputs": [],
      "source": [
        "#tmp_aug = X_train.sample(frac=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MRy-UhBoQ_05"
      },
      "outputs": [],
      "source": [
        "#tmp_aug.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AR22e_zJVeVV"
      },
      "outputs": [],
      "source": [
        "#def return_shuffle_prompt(p, prompts):\n",
        "#  essay_id = prompts.index[prompts['prompt'] == p].tolist()[0] + 1\n",
        "#  essay_ids = list(range(1,9))\n",
        "#  essay_ids.remove(essay_id)\n",
        "#  ran_id = random.choice(essay_ids)\n",
        "#  return prompts.iloc[ran_id -1].prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qTeU2qnqRFrq"
      },
      "outputs": [],
      "source": [
        "#tmp_aug['prompt'] = tmp_aug['prompt'].apply(lambda x: return_shuffle_prompt(x,prompts))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yDkTWJ1PaTuG"
      },
      "outputs": [],
      "source": [
        "#tmp_aug['combined_essay'] = tmp_aug['prompt'] + tmp_aug['essay']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xem0TLnPJIHH"
      },
      "outputs": [],
      "source": [
        "#tmp_aug.loc[tmp_aug.essay_id==9792]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gPsvNYzRkKJS"
      },
      "outputs": [],
      "source": [
        "#X_train = X_train.append(tmp_aug)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bciFFKsXkTl_"
      },
      "outputs": [],
      "source": [
        "#X_train.to_csv('/content/drive/MyDrive/Colab Notebooks/AES/X_train_prel_augmented_tpd.csv')\n",
        "#X_test.to_csv('/content/drive/MyDrive/Colab Notebooks/AES/X_test_prel_tpd.csv')\n",
        "#y_train.to_csv('/content/drive/MyDrive/Colab Notebooks/AES/y_train_prel_tpd.csv')\n",
        "#y_test.to_csv('/content/drive/MyDrive/Colab Notebooks/AES/y_test_prel_tpd.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LsK8s2grxMDs"
      },
      "source": [
        "#### Evaluating embedding for training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "27SiqFrhOVjk"
      },
      "outputs": [],
      "source": [
        "#from transformers import BertModel, BertConfig, BertTokenizer\n",
        "#\n",
        "#max_sentences = 100\n",
        "## Either load precomputed or compute the BERT embeddings & dataset for semantic scoring \n",
        "#if (use_existing_bert_prel == True):\n",
        "#  print (\"Experiment 1: Prompt-relavance Model: Using Saved vectors & embeddings...\")\n",
        "#  if (load_trained_model_prel == False):\n",
        "#    lhs_train_prel = torch.load(lhs_prelevance_train_path)\n",
        "#    y_train = torch.load(y_train_file_path_prel)\n",
        "#    print(\"Prompt-relevance Model: Shape of loaded TRAIN embeddings:\",lhs_train_prel.shape)\n",
        "#  else:\n",
        "#    print (\"Since LOAD LSTM Model is TRUE, not loading the saved training BERT embedding TENSOR\")\n",
        "#  \n",
        "#  y_test = torch.load(y_test_file_path_prel)\n",
        "#  lhs_test_prel = torch.load(lhs_prelevance_test_path)\n",
        "#  \n",
        "#  print(\"Prompt-relevance Model: Shape of loaded y_train:\",y_train.shape)\n",
        "#  print(\"Prompt-relevance Model: Shape of loaded y_test:\",y_test.shape)\n",
        "#  print(\"Prompt-relevance Model: Shape of loaded TEST embeddings:\",lhs_test_prel.shape)\n",
        "#else:\n",
        "#  print (\"Experiment 1: Prompt-relevance Model: New Train & Test vector split & creating corresponding BERT embeddings...\")\n",
        "#  tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "#  config = BertConfig.from_pretrained('bert-base-uncased', output_hidden_states=True)\n",
        "#  model = BertModel.from_pretrained('bert-base-uncased', config=config)\n",
        "#\n",
        "#  train_essays = X_train['combined_essay']\n",
        "#  test_essays = X_test['combined_essay']\n",
        "#  sentences = []\n",
        "#  tokenize_sentences = []\n",
        "#  train_bert_embeddings = []\n",
        "#  \n",
        "#  torch.save(y_train, y_train_file_path_prel)\n",
        "#  torch.save(y_test, y_test_file_path_prel)\n",
        "#\n",
        "#  cuda = torch.device('cuda')\n",
        "#\n",
        "#  # Embeddings for training vectors\n",
        "#  lhs_train_prel = torch.empty((len(train_essays),max_sentences,768), dtype=torch.float)\n",
        "#  emb_for_padding = tokenizer.encode_plus(\"\", add_special_tokens=True, truncation=True, padding=\"max_length\", return_tensors=\"pt\", max_length=10)\n",
        "#  tt = torch.tensor(emb_for_padding['input_ids'])\n",
        "#  lhs_for_padding = model(tt)[2][-2]\n",
        "#  lhs_for_padding_np = np.array(lhs_for_padding.detach().numpy())\n",
        "#  lhs_for_padding_mean = np.mean(lhs_for_padding_np,axis=1)\n",
        "#  lhs_avg_for_padding = torch.tensor(lhs_for_padding_mean[0])\n",
        "#\n",
        "#for j,essay in enumerate(tqdm(train_essays)):\n",
        "#  sentences = split_into_sentences(essay)\n",
        "#  sen_length = len(sentences)\n",
        "#  \n",
        "#  lhs_sentence_avg = np.zeros((max_sentences,768), dtype=float)\n",
        "#  \n",
        "#  for i in range(min(max_sentences,len(sentences))):\n",
        "#    tokenize_sentence = tokenizer.encode(sentences[i],add_special_tokens=True, max_length=512, truncation=True)\n",
        "#    tt = torch.tensor(tokenize_sentence)\n",
        "#    tts = tt.reshape(1,len(tt))\n",
        "#    # getting the 2nd last layer\n",
        "#    lhs_sentence = model(tts).hidden_states[11]\n",
        "#    lhs_sentence_np = np.array(lhs_sentence.detach().numpy())\n",
        "#    lhs_sentence_np_mean = np.mean(lhs_sentence_np,axis=1)\n",
        "#    lhs_sentence_avg[i] = lhs_sentence_np_mean[0]\n",
        "#  \n",
        "#  lhs_train_prel[j] = torch.tensor(lhs_sentence_avg)\n",
        "#\n",
        "#  if (sen_length < max_sentences):\n",
        "#   for i in range (sen_length, max_sentences):\n",
        "#     lhs_train_prel[j][i]= lhs_avg_for_padding\n",
        "#  \n",
        "#torch.save(lhs_train_prel, lhs_prelevance_train_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01uke1tAw-qm"
      },
      "source": [
        "#### Creating embedding for the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mVjsgA2Vuh2n"
      },
      "outputs": [],
      "source": [
        "#from transformers import BertModel, BertConfig, BertTokenizer\n",
        "#tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "#config = BertConfig.from_pretrained('bert-base-uncased', output_hidden_states=True)\n",
        "#model = BertModel.from_pretrained('bert-base-uncased', config=config)\n",
        "#\n",
        "#max_sentences = 100\n",
        "#X = prompt_data\n",
        "#y = prompt_data['normalized_score']\n",
        "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "#fold_count =1\n",
        "#train_essays = X_train['combined_essay']\n",
        "#test_essays = X_test['combined_essay']\n",
        "#sentences = []\n",
        "#tokenize_sentences = []\n",
        "#\n",
        "#lhs_test_prel = torch.empty((len(test_essays),max_sentences,768), dtype=torch.float)\n",
        "#emb_for_padding = tokenizer.encode_plus(\"\", add_special_tokens=True, truncation=True, padding=\"max_length\", return_tensors=\"pt\", max_length=10)\n",
        "#tt = torch.tensor(emb_for_padding['input_ids'])\n",
        "#output = model(tt)\n",
        "#lhs_for_padding = output.hidden_states[12] + output.hidden_states[11] + output.hidden_states[10] + output.hidden_states[9]\n",
        "#lhs_for_padding_np = np.array(lhs_for_padding.detach().numpy())\n",
        "#lhs_for_padding_mean = np.mean(lhs_for_padding_np,axis=1)\n",
        "#\n",
        "#for j,essay in enumerate(tqdm(test_essays)):\n",
        "#  sentences = split_into_sentences(essay)\n",
        "#  sen_length = len(sentences)\n",
        "#  \n",
        "#  lhs_sentence_avg = np.zeros((max_sentences,768), dtype=float)\n",
        "#  \n",
        "#  for i in range(min(max_sentences,len(sentences))):\n",
        "#    tokenize_sentence = tokenizer.encode(sentences[i],add_special_tokens=True, max_length=512, truncation=True)\n",
        "#    tt = torch.tensor(tokenize_sentence)\n",
        "#    tts = tt.reshape(1,len(tt))\n",
        "#    # getting the 2nd last layer\n",
        "#    output = model(tts)\n",
        "#    lhs_sentence = output.hidden_states[12] + output.hidden_states[11] + output.hidden_states[10] + output.hidden_states[9]\n",
        "#    lhs_sentence_np = np.array(lhs_sentence.detach().numpy())\n",
        "#    lhs_sentence_np_mean = np.mean(lhs_sentence_np,axis=1)\n",
        "#    lhs_sentence_avg[i] = lhs_sentence_np_mean[0]\n",
        "#  \n",
        "#  lhs_test_prel[j] = torch.tensor(lhs_sentence_avg)\n",
        "#\n",
        "#  if (sen_length < max_sentences):\n",
        "#   for i in range (sen_length, max_sentences):\n",
        "#     lhs_test_prel[j][i]= lhs_avg_for_padding\n",
        "#  \n",
        "#torch.save(lhs_test_prel, lhs_prelevance_test_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXlU7OSNQxBk"
      },
      "source": [
        "#### Training/loading the promp-relevance LSTM model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zi0bmwGdQxBw"
      },
      "outputs": [],
      "source": [
        "## to load LHS for training and evalutation purposes\n",
        "\n",
        "#lhs_train_prel = torch.load(lhs_prelevance_train_path)\n",
        "#y_train = torch.load(y_train_file_path_prel)\n",
        "#print(\"Prompt-relevance Model: Shape of loaded TRAIN embeddings:\",lhs_train_prel.shape)\n",
        "#y_test = torch.load(y_test_file_path_prel)\n",
        "#lhs_test_prel = torch.load(lhs_prelevance_test_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "teaikXdwQxBx"
      },
      "outputs": [],
      "source": [
        "#max_sentences = 100\n",
        "#load_trained_model_prel = False\n",
        "#if (load_trained_model_prel == True):\n",
        "#    lstm_model_prel = load_model(prel_model_save_path)\n",
        "#else:\n",
        "#  lstm_model_prel = get_model(sen_size=max_sentences)\n",
        "#  lstm_model_prel.fit(lhs_train_prel.numpy(), y_train, batch_size=128, epochs=60)\n",
        "#  lstm_model_prel.save(prel_model_save_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2Kvfea7wueZ"
      },
      "source": [
        "#### Evaluating the prompt-relevance model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wc9855yRvKbz"
      },
      "outputs": [],
      "source": [
        "#y_pred = lstm_model_prel.predict(lhs_test_prel.numpy())\n",
        "#tt1 = np.around(10*y_pred)\n",
        "#tt2 = tt1.reshape(tt1.shape[0],)\n",
        "#pred_values = tt2.astype(int)\n",
        "#tt3 = np.array(10* y_test)\n",
        "#gold_values = tt3.astype(int)\n",
        "## evaluate the model\n",
        "#result = cohen_kappa_score(gold_values,pred_values,weights='quadratic')\n",
        "#print(\"Kappa Score: {}\".format(result))\n",
        "#yy_p = y_pred.reshape(y_pred.shape[0],)\n",
        "#yy_t = np.array(y_test)\n",
        "#MSE = np.square(np.subtract(yy_t, yy_p)).mean()\n",
        "#RMSE = math.sqrt(MSE)\n",
        "#print (\"Prompt-relevance Model: MSE: \", MSE)\n",
        "#print (\"Prompt-relevance Model: RMSE: \", RMSE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNaqSH-4Okf0"
      },
      "source": [
        "### Prompt relevance model - w/ augmented dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1oGJtNWbOixX"
      },
      "outputs": [],
      "source": [
        "#from transformers import BertModel, BertConfig, BertTokenizer\n",
        "#tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "#config = BertConfig.from_pretrained('bert-base-uncased', output_hidden_states=True)\n",
        "#model = BertModel.from_pretrained('bert-base-uncased', config=config)\n",
        "#\n",
        "#max_sentences = 100\n",
        "#sentences = []\n",
        "#tokenize_sentences = []\n",
        "#\n",
        "#aug_essays = tmp_aug['combined_essay']\n",
        "#lhs_aug_prel = torch.empty((len(tmp_aug),max_sentences,768), dtype=torch.float)\n",
        "#emb_for_padding = tokenizer.encode_plus(\"\", add_special_tokens=True, truncation=True, padding=\"max_length\", return_tensors=\"pt\", max_length=10)\n",
        "#tt = torch.tensor(emb_for_padding['input_ids'])\n",
        "#output = model(tt)\n",
        "#lhs_for_padding = output.hidden_states[12] + output.hidden_states[11] + output.hidden_states[10] + output.hidden_states[9]\n",
        "#lhs_for_padding_np = np.array(lhs_for_padding.detach().numpy())\n",
        "#lhs_for_padding_mean = np.mean(lhs_for_padding_np,axis=1)\n",
        "#lhs_avg_for_padding = torch.tensor(lhs_for_padding_mean[0])\n",
        "#\n",
        "#for j,essay in enumerate(tqdm(aug_essays)):\n",
        "#  sentences = split_into_sentences(essay)\n",
        "#  sen_length = len(sentences)\n",
        "#  \n",
        "#  lhs_sentence_avg = np.zeros((max_sentences,768), dtype=float)\n",
        "#  \n",
        "#  for i in range(min(max_sentences,len(sentences))):\n",
        "#    tokenize_sentence = tokenizer.encode(sentences[i],add_special_tokens=True, max_length=512, truncation=True)\n",
        "#    tt = torch.tensor(tokenize_sentence)\n",
        "#    tts = tt.reshape(1,len(tt))\n",
        "#    # getting the 2nd last layer\n",
        "#    output = model(tts)\n",
        "#    lhs_sentence = output.hidden_states[12] + output.hidden_states[11] + output.hidden_states[10] + output.hidden_states[9]\n",
        "#    lhs_sentence_np = np.array(lhs_sentence.detach().numpy())\n",
        "#    lhs_sentence_np_mean = np.mean(lhs_sentence_np,axis=1)\n",
        "#    lhs_sentence_avg[i] = lhs_sentence_np_mean[0]\n",
        "#  \n",
        "#  lhs_aug_prel[j] = torch.tensor(lhs_sentence_avg)\n",
        "#\n",
        "#  if (sen_length < max_sentences):\n",
        "#   for i in range (sen_length, max_sentences):\n",
        "#     lhs_aug_prel[j][i]= lhs_avg_for_padding\n",
        "#  \n",
        "#torch.save(lhs_aug_prel, '/content/drive/MyDrive/Colab Notebooks/AES/prel_aug_lhs.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABwq0bdVhLZK"
      },
      "source": [
        "#### Training/loading the promp-relevance LSTM model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DIAb3SBlhLZd"
      },
      "outputs": [],
      "source": [
        "## to load LHS for training and evalutation purposes\n",
        "#lhs_train_prel = torch.load(lhs_prelevance_train_path)\n",
        "#lhs_aug_prel = torch.load('/content/drive/MyDrive/Colab Notebooks/AES/prel_aug_lhs.pt')\n",
        "#lhs_train_prel_aug = torch.cat((lhs_train_prel,lhs_aug_prel),0)\n",
        "#y_train = torch.load(y_train_file_path_prel)\n",
        "#print(\"Prompt-relevance Model: Shape of loaded TRAIN embeddings:\",lhs_train_prel_aug.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1a6kPS1TNyQb"
      },
      "outputs": [],
      "source": [
        "#y_train_org = torch.load(y_train_file_path_prel)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KvZxL__kNvV-"
      },
      "outputs": [],
      "source": [
        "#lhs_aug_prel.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NHWWK6QtN-U9"
      },
      "outputs": [],
      "source": [
        "#print (lhs_train_prel_aug[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sb6iu7IV0cGJ"
      },
      "outputs": [],
      "source": [
        "#y_test = torch.load(y_test_file_path_prel)\n",
        "#lhs_test_prel = torch.load(lhs_prelevance_test_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9t1y0_OfOc9c"
      },
      "outputs": [],
      "source": [
        "#print (y_test[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AxgtrjrKjk9d"
      },
      "outputs": [],
      "source": [
        "#y_app = 1038*[0.0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "huEYsasUkEv-"
      },
      "outputs": [],
      "source": [
        "#y_train = y_train.append(pd.Series(y_app),ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MyX6x_BOPBKa"
      },
      "outputs": [],
      "source": [
        "#y_train.iloc[10000:10500]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KupXtBfMO_zI"
      },
      "outputs": [],
      "source": [
        "#type(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sONjhvxbhLZe"
      },
      "outputs": [],
      "source": [
        "#max_sentences = 100\n",
        "#load_trained_model_prel = False\n",
        "#if (load_trained_model_prel == True):\n",
        "#    lstm_model_prel = load_model('/content/drive/MyDrive/Colab Notebooks/AES/prel_model_with_adverserial_examples.pkl')\n",
        "#else:\n",
        "#  lstm_model_prel = get_model(sen_size=max_sentences)\n",
        "#  lstm_model_prel.fit(lhs_train_prel_aug.numpy(), y_train, batch_size=128, epochs=60)\n",
        "#  #lstm_model_prel.fit(lhs_train_prel.numpy(), y_train_org, batch_size=128, epochs=60)\n",
        "#  lstm_model_prel.save('/content/drive/MyDrive/Colab Notebooks/AES/prel_model_with_adverserial_examples.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHHZUUzTlpzf"
      },
      "source": [
        "#### Evaluating the prompt-relevance model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hDzstCpnlpzg"
      },
      "outputs": [],
      "source": [
        "#y_pred = lstm_model_prel.predict(lhs_test_prel.numpy())\n",
        "#tt1 = np.around(10*y_pred)\n",
        "#tt2 = tt1.reshape(tt1.shape[0],)\n",
        "#pred_values = tt2.astype(int)\n",
        "#print (\"pred values\", pred_values)\n",
        "#tt3 = np.array(10* y_test)\n",
        "#gold_values = tt3.astype(int)\n",
        "#print (\"gold values\", gold_values)\n",
        "## evaluate the model\n",
        "#result = cohen_kappa_score(gold_values,pred_values,weights='quadratic')\n",
        "#print(\"Kappa Score: {}\".format(result))\n",
        "#yy_p = y_pred.reshape(y_pred.shape[0],)\n",
        "#yy_t = np.array(y_test)\n",
        "#MSE = np.square(np.subtract(yy_t, yy_p)).mean()\n",
        "#RMSE = math.sqrt(MSE)\n",
        "#print (\"Prompt-relevance Model: MSE: \", MSE)\n",
        "#print (\"Prompt-relevance Model: RMSE: \", RMSE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eSM8_f6FbgQT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4D_SaMRbP-W"
      },
      "source": [
        "## Clean Spelling Errors (CSE): Semantic Score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rk5THMqffdDv"
      },
      "source": [
        "\n",
        "### Cleaning TPD dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rBuWuv4-f5cF"
      },
      "outputs": [],
      "source": [
        "# remove annoying characters\n",
        "def unicodetoascii(text):\n",
        "\n",
        "    TEXT = (text.\n",
        "    \t\treplace('\\\\xe2\\\\x80\\\\x99', \"'\").\n",
        "            replace('\\\\xc3\\\\xa9', 'e').\n",
        "            replace('\\\\xe2\\\\x80\\\\x90', '-').\n",
        "            replace('\\\\xe2\\\\x80\\\\x91', '-').\n",
        "            replace('\\\\xe2\\\\x80\\\\x92', '-').\n",
        "            replace('\\\\xe2\\\\x80\\\\x93', '-').\n",
        "            replace('\\\\xe2\\\\x80\\\\x94', '-').\n",
        "            replace('\\\\xe2\\\\x80\\\\x94', '-').\n",
        "            replace('\\\\xe2\\\\x80\\\\x98', \"'\").\n",
        "            replace('\\x92',\"'\").\n",
        "            replace('\\\\xe2\\\\x80\\\\x9b', \"'\").\n",
        "            replace('\\\\xe2\\\\x80\\\\x9c', '\"').\n",
        "            replace('\\\\xe2\\\\x80\\\\x9c', '\"').\n",
        "            replace('\\\\xe2\\\\x80\\\\x9d', '\"').\n",
        "            replace('\\\\xe2\\\\x80\\\\x9e', '\"').\n",
        "            replace('\\\\xe2\\\\x80\\\\x9f', '\"').\n",
        "            replace('\\\\xe2\\\\x80\\\\xa6', '...').\n",
        "            replace('\\\\xe2\\\\x80\\\\xb2', \"'\").\n",
        "            replace('\\\\xe2\\\\x80\\\\xb3', \"'\").\n",
        "            replace('\\\\xe2\\\\x80\\\\xb4', \"'\").\n",
        "            replace('\\\\xe2\\\\x80\\\\xb5', \"'\").\n",
        "            replace('\\\\xe2\\\\x80\\\\xb6', \"'\").\n",
        "            replace('\\\\xe2\\\\x80\\\\xb7', \"'\").\n",
        "            replace('\\\\xe2\\\\x81\\\\xba', \"+\").\n",
        "            replace('\\\\xe2\\\\x81\\\\xbb', \"-\").\n",
        "            replace('\\\\xe2\\\\x81\\\\xbc', \"=\").\n",
        "            replace('\\\\xe2\\\\x81\\\\xbd', \"(\").\n",
        "            replace('\\\\xe2\\\\x81\\\\xbe', \")\")\n",
        "\n",
        "                 )\n",
        "    return TEXT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iIA4VOT3pimn"
      },
      "outputs": [],
      "source": [
        "import language_tool_python\n",
        "tool = language_tool_python.LanguageTool('en-US')\n",
        "def fix_spellings(text):\n",
        "    # print(\"Text before: \" ,text)\n",
        "    text = unicodetoascii(text)\n",
        "    matches = tool.check(text)\n",
        "    error_offsets = [[text[x.offset:x.offset+x.errorLength],x.offset,x.replacements[0]] \n",
        "                     for x in matches if (x.ruleIssueType=='misspelling' and len(x.replacements)>0)]\n",
        "    error_offsets = sorted(error_offsets, key=lambda x: x[1])\n",
        "    # print(\"Error offsets before: \", error_offsets)\n",
        "    for i in range(len(error_offsets)):\n",
        "        for j in range(i+1,len(error_offsets)):\n",
        "            if len(error_offsets[i][2]) >= len(error_offsets[i][0]):\n",
        "                error_offsets[j][1] += len(error_offsets[i][2]) - len(error_offsets[i][0])\n",
        "            else:\n",
        "                error_offsets[j][1] -= abs(len(error_offsets[i][2]) - len(error_offsets[i][0]))\n",
        "        text = text.replace(error_offsets[i][0], error_offsets[i][2])\n",
        "    # print(\"Error offsets after: \", error_offsets)\n",
        "    # print(\"Text after: \" ,text)\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "pFoVMLGHOxcX",
        "outputId": "10c6e221-b7ef-4a78-8533-647bf740ec7b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'I think in my option is that the author was very comfortable with his words and his way of being human. His parents was originally from Cuba, was in to there culture nice to other in there surrounding. For an example say It was in this simple house that my parents welcomed other refugees to celebrate their arrival to the country and where I celebrated His first birthday.'"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fix_spellings(tpd_train['essay'][3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYr20EUnX159",
        "outputId": "d0fbd618-4cac-41d4-cab8-c47c0b549c2e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/6488 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "100%|██████████| 6488/6488 [27:24<00:00,  3.94it/s]\n"
          ]
        }
      ],
      "source": [
        "for i in tqdm(range(len(tpd_train))):\n",
        "    tpd_train.iloc[i]['essay'] = fix_spellings(tpd_train.iloc[i]['essay'])\n",
        "tpd_train.to_csv(\"/content/drive/MyDrive/Colab Notebooks/AES/tpd_train_w_fixed_spellings.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xthLk_IJYXMu",
        "outputId": "48623f16-91f4-4533-ad18-b9841be41b2f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/2596 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "100%|██████████| 2596/2596 [16:56<00:00,  2.56it/s]\n"
          ]
        }
      ],
      "source": [
        "for i in tqdm(range(len(tpd_test))):\n",
        "    tpd_test.iloc[i]['essay'] = fix_spellings(tpd_test.iloc[i]['essay'])\n",
        "tpd_test.to_csv(\"/content/drive/MyDrive/Colab Notebooks/AES/tpd_test_w_fixed_spellings.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k1UXqCycb_T9"
      },
      "outputs": [],
      "source": [
        "tpd_train = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/AES/tpd_train_w_fixed_spellings.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qv1ruMCUQRDY"
      },
      "outputs": [],
      "source": [
        "tpd_test = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/AES/tpd_test_w_fixed_spellings.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "id": "ACOyBm8mQY5v",
        "outputId": "362dbca6-3793-4bb9-c8be-82b6eeb43d50"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-b26f9482-c420-4338-ab5d-942b849b813c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>essay_id</th>\n",
              "      <th>essay_set</th>\n",
              "      <th>essay</th>\n",
              "      <th>domain1_score</th>\n",
              "      <th>normalized_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>6351</td>\n",
              "      <td>9908</td>\n",
              "      <td>4</td>\n",
              "      <td>The author concludes the story w/this paragrap...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>6315</td>\n",
              "      <td>9872</td>\n",
              "      <td>4</td>\n",
              "      <td>I believe that the author concludes the story ...</td>\n",
              "      <td>2</td>\n",
              "      <td>0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>304</td>\n",
              "      <td>305</td>\n",
              "      <td>1</td>\n",
              "      <td>Computers, a very much talked about subject. D...</td>\n",
              "      <td>10</td>\n",
              "      <td>0.800000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>8023</td>\n",
              "      <td>12771</td>\n",
              "      <td>5</td>\n",
              "      <td>I think in my opion is that the author was ver...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4442</td>\n",
              "      <td>6839</td>\n",
              "      <td>3</td>\n",
              "      <td>The setting that affect the cyclist is the con...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.333333</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b26f9482-c420-4338-ab5d-942b849b813c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b26f9482-c420-4338-ab5d-942b849b813c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b26f9482-c420-4338-ab5d-942b849b813c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Unnamed: 0  Unnamed: 0.1  ...  domain1_score  normalized_score\n",
              "0           0          6351  ...              1          0.333333\n",
              "1           1          6315  ...              2          0.666667\n",
              "2           2           304  ...             10          0.800000\n",
              "3           3          8023  ...              1          0.250000\n",
              "4           4          4442  ...              1          0.333333\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tpd_train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4sKbPO_ZrQz"
      },
      "source": [
        "### Get Embeddings: CSE Semantic Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JknNW9sXiJc6"
      },
      "outputs": [],
      "source": [
        "prepare_embeddings_updated(tpd_train, model_type='semantic', train_or_test='train', \n",
        "                           load_from_file=False,file_path='/content/drive/MyDrive/Colab Notebooks/AES/clean_spelling_errors')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ela8_2wVkuh-"
      },
      "outputs": [],
      "source": [
        "prepare_embeddings_updated(tpd_test, model_type='semantic', train_or_test='test', \n",
        "                           load_from_file=False,file_path='/content/drive/MyDrive/Colab Notebooks/AES/clean_spelling_errors_test')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSxbBsBuX8GY"
      },
      "source": [
        "###Training LSTM model for Semantic Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ixM_uMCSZ4rn"
      },
      "outputs": [],
      "source": [
        "#load embeddings\n",
        "lhs_train = torch.load('/content/drive/MyDrive/Colab Notebooks/AES/clean_spelling_errors/lhs_train.pt')\n",
        "y_train = torch.load(\"/content/drive/MyDrive/Colab Notebooks/AES/clean_spelling_errors/y_train.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4YvQaKBW0ncu"
      },
      "outputs": [],
      "source": [
        "#load test embeddings\n",
        "lhs_test = torch.load(\"/content/drive/MyDrive/Colab Notebooks/AES/clean_spelling_errors_test/lhs_test.pt\")\n",
        "y_test = torch.load(\"/content/drive/MyDrive/Colab Notebooks/AES/clean_spelling_errors_test/y_test.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XPMNrQvHY0hK"
      },
      "outputs": [],
      "source": [
        "clean_semantic_model_save_path = \"/content/drive/MyDrive/Colab Notebooks/AES/clean_semantic.pt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cDhYCAhY0hK",
        "outputId": "9414341e-9a04-4219-c0bc-e6f2ec3301ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 128, 1028)         7389264   \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 512)               3155968   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 513       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 10,545,745\n",
            "Trainable params: 10,545,745\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "102/102 [==============================] - 74s 670ms/step - loss: 0.1090 - mae: 0.2593\n",
            "Epoch 2/100\n",
            "102/102 [==============================] - 69s 672ms/step - loss: 0.0507 - mae: 0.1775\n",
            "Epoch 3/100\n",
            "102/102 [==============================] - 69s 673ms/step - loss: 0.0360 - mae: 0.1484\n",
            "Epoch 4/100\n",
            "102/102 [==============================] - 68s 670ms/step - loss: 0.0298 - mae: 0.1333\n",
            "Epoch 5/100\n",
            "102/102 [==============================] - 68s 669ms/step - loss: 0.0266 - mae: 0.1257\n",
            "Epoch 6/100\n",
            "102/102 [==============================] - 68s 671ms/step - loss: 0.0243 - mae: 0.1210\n",
            "Epoch 7/100\n",
            "102/102 [==============================] - 68s 671ms/step - loss: 0.0231 - mae: 0.1183\n",
            "Epoch 8/100\n",
            "102/102 [==============================] - 68s 671ms/step - loss: 0.0225 - mae: 0.1171\n",
            "Epoch 9/100\n",
            "102/102 [==============================] - 68s 671ms/step - loss: 0.0213 - mae: 0.1137\n",
            "Epoch 10/100\n",
            "102/102 [==============================] - 68s 668ms/step - loss: 0.0203 - mae: 0.1121\n",
            "Epoch 11/100\n",
            "102/102 [==============================] - 68s 671ms/step - loss: 0.0200 - mae: 0.1099\n",
            "Epoch 12/100\n",
            "102/102 [==============================] - 69s 672ms/step - loss: 0.0189 - mae: 0.1078\n",
            "Epoch 13/100\n",
            "102/102 [==============================] - 69s 672ms/step - loss: 0.0184 - mae: 0.1057\n",
            "Epoch 14/100\n",
            "102/102 [==============================] - 69s 675ms/step - loss: 0.0178 - mae: 0.1045\n",
            "Epoch 15/100\n",
            "102/102 [==============================] - 69s 672ms/step - loss: 0.0176 - mae: 0.1036\n",
            "Epoch 16/100\n",
            "102/102 [==============================] - 68s 668ms/step - loss: 0.0175 - mae: 0.1035\n",
            "Epoch 17/100\n",
            "102/102 [==============================] - 69s 673ms/step - loss: 0.0168 - mae: 0.1023\n",
            "Epoch 18/100\n",
            "102/102 [==============================] - 69s 676ms/step - loss: 0.0167 - mae: 0.1007\n",
            "Epoch 19/100\n",
            "102/102 [==============================] - 68s 671ms/step - loss: 0.0158 - mae: 0.0985\n",
            "Epoch 20/100\n",
            "102/102 [==============================] - 69s 673ms/step - loss: 0.0153 - mae: 0.0970\n",
            "Epoch 21/100\n",
            "102/102 [==============================] - 69s 676ms/step - loss: 0.0147 - mae: 0.0952\n",
            "Epoch 22/100\n",
            "102/102 [==============================] - 69s 673ms/step - loss: 0.0151 - mae: 0.0960\n",
            "Epoch 23/100\n",
            "102/102 [==============================] - 68s 671ms/step - loss: 0.0147 - mae: 0.0950\n",
            "Epoch 24/100\n",
            "102/102 [==============================] - 68s 671ms/step - loss: 0.0147 - mae: 0.0955\n",
            "Epoch 25/100\n",
            "102/102 [==============================] - 68s 671ms/step - loss: 0.0139 - mae: 0.0924\n",
            "Epoch 26/100\n",
            "102/102 [==============================] - 68s 671ms/step - loss: 0.0133 - mae: 0.0905\n",
            "Epoch 27/100\n",
            "102/102 [==============================] - 69s 672ms/step - loss: 0.0134 - mae: 0.0905\n",
            "Epoch 28/100\n",
            "102/102 [==============================] - 68s 671ms/step - loss: 0.0132 - mae: 0.0903\n",
            "Epoch 29/100\n",
            "102/102 [==============================] - 68s 671ms/step - loss: 0.0126 - mae: 0.0876\n",
            "Epoch 30/100\n",
            "102/102 [==============================] - 68s 671ms/step - loss: 0.0126 - mae: 0.0875\n",
            "Epoch 31/100\n",
            "102/102 [==============================] - 68s 668ms/step - loss: 0.0120 - mae: 0.0856\n",
            "Epoch 32/100\n",
            "102/102 [==============================] - 68s 669ms/step - loss: 0.0117 - mae: 0.0838\n",
            "Epoch 33/100\n",
            "102/102 [==============================] - 68s 670ms/step - loss: 0.0124 - mae: 0.0865\n",
            "Epoch 34/100\n",
            "102/102 [==============================] - 68s 669ms/step - loss: 0.0112 - mae: 0.0825\n",
            "Epoch 35/100\n",
            "102/102 [==============================] - 68s 670ms/step - loss: 0.0110 - mae: 0.0815\n",
            "Epoch 36/100\n",
            "102/102 [==============================] - 68s 669ms/step - loss: 0.0109 - mae: 0.0808\n",
            "Epoch 37/100\n",
            "102/102 [==============================] - 68s 664ms/step - loss: 0.0105 - mae: 0.0799\n",
            "Epoch 38/100\n",
            "102/102 [==============================] - 67s 658ms/step - loss: 0.0103 - mae: 0.0789\n",
            "Epoch 39/100\n",
            "102/102 [==============================] - 67s 655ms/step - loss: 0.0102 - mae: 0.0788\n",
            "Epoch 40/100\n",
            "102/102 [==============================] - 67s 656ms/step - loss: 0.0100 - mae: 0.0766\n",
            "Epoch 41/100\n",
            "102/102 [==============================] - 67s 654ms/step - loss: 0.0099 - mae: 0.0762\n",
            "Epoch 42/100\n",
            "102/102 [==============================] - 67s 655ms/step - loss: 0.0093 - mae: 0.0743\n",
            "Epoch 43/100\n",
            "102/102 [==============================] - 67s 658ms/step - loss: 0.0090 - mae: 0.0724\n",
            "Epoch 44/100\n",
            "102/102 [==============================] - 67s 658ms/step - loss: 0.0096 - mae: 0.0744\n",
            "Epoch 45/100\n",
            "102/102 [==============================] - 67s 656ms/step - loss: 0.0089 - mae: 0.0720\n",
            "Epoch 46/100\n",
            "102/102 [==============================] - 67s 656ms/step - loss: 0.0089 - mae: 0.0719\n",
            "Epoch 47/100\n",
            "102/102 [==============================] - 67s 659ms/step - loss: 0.0085 - mae: 0.0696\n",
            "Epoch 48/100\n",
            "102/102 [==============================] - 67s 656ms/step - loss: 0.0085 - mae: 0.0701\n",
            "Epoch 49/100\n",
            "102/102 [==============================] - 67s 655ms/step - loss: 0.0084 - mae: 0.0694\n",
            "Epoch 50/100\n",
            "102/102 [==============================] - 67s 657ms/step - loss: 0.0081 - mae: 0.0679\n",
            "Epoch 51/100\n",
            "102/102 [==============================] - 67s 656ms/step - loss: 0.0077 - mae: 0.0663\n",
            "Epoch 52/100\n",
            "102/102 [==============================] - 67s 658ms/step - loss: 0.0078 - mae: 0.0668\n",
            "Epoch 53/100\n",
            "102/102 [==============================] - 67s 657ms/step - loss: 0.0074 - mae: 0.0643\n",
            "Epoch 54/100\n",
            "102/102 [==============================] - 67s 655ms/step - loss: 0.0077 - mae: 0.0657\n",
            "Epoch 55/100\n",
            "102/102 [==============================] - 67s 658ms/step - loss: 0.0073 - mae: 0.0638\n",
            "Epoch 56/100\n",
            "102/102 [==============================] - 67s 656ms/step - loss: 0.0072 - mae: 0.0639\n",
            "Epoch 57/100\n",
            "102/102 [==============================] - 67s 655ms/step - loss: 0.0070 - mae: 0.0624\n",
            "Epoch 58/100\n",
            "102/102 [==============================] - 67s 659ms/step - loss: 0.0070 - mae: 0.0625\n",
            "Epoch 59/100\n",
            "102/102 [==============================] - 67s 656ms/step - loss: 0.0065 - mae: 0.0594\n",
            "Epoch 60/100\n",
            "102/102 [==============================] - 67s 654ms/step - loss: 0.0063 - mae: 0.0584\n",
            "Epoch 61/100\n",
            "102/102 [==============================] - 67s 660ms/step - loss: 0.0066 - mae: 0.0607\n",
            "Epoch 62/100\n",
            "102/102 [==============================] - 67s 657ms/step - loss: 0.0064 - mae: 0.0592\n",
            "Epoch 63/100\n",
            "102/102 [==============================] - 67s 657ms/step - loss: 0.0065 - mae: 0.0600\n",
            "Epoch 64/100\n",
            "102/102 [==============================] - 67s 660ms/step - loss: 0.0063 - mae: 0.0585\n",
            "Epoch 65/100\n",
            "102/102 [==============================] - 67s 662ms/step - loss: 0.0064 - mae: 0.0588\n",
            "Epoch 66/100\n",
            "102/102 [==============================] - 67s 658ms/step - loss: 0.0061 - mae: 0.0573\n",
            "Epoch 67/100\n",
            "102/102 [==============================] - 67s 661ms/step - loss: 0.0064 - mae: 0.0591\n",
            "Epoch 68/100\n",
            "102/102 [==============================] - 67s 657ms/step - loss: 0.0059 - mae: 0.0560\n",
            "Epoch 69/100\n",
            "102/102 [==============================] - 67s 658ms/step - loss: 0.0062 - mae: 0.0577\n",
            "Epoch 70/100\n",
            "102/102 [==============================] - 68s 664ms/step - loss: 0.0056 - mae: 0.0547\n",
            "Epoch 71/100\n",
            "102/102 [==============================] - 67s 658ms/step - loss: 0.0059 - mae: 0.0563\n",
            "Epoch 72/100\n",
            "102/102 [==============================] - 67s 659ms/step - loss: 0.0057 - mae: 0.0553\n",
            "Epoch 73/100\n",
            "102/102 [==============================] - 67s 660ms/step - loss: 0.0056 - mae: 0.0548\n",
            "Epoch 74/100\n",
            "102/102 [==============================] - 67s 661ms/step - loss: 0.0054 - mae: 0.0543\n",
            "Epoch 75/100\n",
            "102/102 [==============================] - 67s 659ms/step - loss: 0.0056 - mae: 0.0551\n",
            "Epoch 76/100\n",
            "102/102 [==============================] - 67s 659ms/step - loss: 0.0053 - mae: 0.0537\n",
            "Epoch 77/100\n",
            "102/102 [==============================] - 67s 657ms/step - loss: 0.0052 - mae: 0.0525\n",
            "Epoch 78/100\n",
            "102/102 [==============================] - 67s 658ms/step - loss: 0.0054 - mae: 0.0537\n",
            "Epoch 79/100\n",
            "102/102 [==============================] - 67s 657ms/step - loss: 0.0057 - mae: 0.0554\n",
            "Epoch 80/100\n",
            "102/102 [==============================] - 67s 658ms/step - loss: 0.0056 - mae: 0.0543\n",
            "Epoch 81/100\n",
            "102/102 [==============================] - 67s 657ms/step - loss: 0.0060 - mae: 0.0568\n",
            "Epoch 82/100\n",
            "102/102 [==============================] - 67s 659ms/step - loss: 0.0093 - mae: 0.0653\n",
            "Epoch 83/100\n",
            "102/102 [==============================] - 67s 656ms/step - loss: 0.0100 - mae: 0.0771\n",
            "Epoch 84/100\n",
            "102/102 [==============================] - 67s 659ms/step - loss: 0.0060 - mae: 0.0584\n",
            "Epoch 85/100\n",
            "102/102 [==============================] - 67s 660ms/step - loss: 0.0058 - mae: 0.0565\n",
            "Epoch 86/100\n",
            "102/102 [==============================] - 67s 657ms/step - loss: 0.0055 - mae: 0.0543\n",
            "Epoch 87/100\n",
            "102/102 [==============================] - 67s 656ms/step - loss: 0.0052 - mae: 0.0535\n",
            "Epoch 88/100\n",
            "102/102 [==============================] - 67s 659ms/step - loss: 0.0052 - mae: 0.0525\n",
            "Epoch 89/100\n",
            "102/102 [==============================] - 68s 663ms/step - loss: 0.0049 - mae: 0.0515\n",
            "Epoch 90/100\n",
            "102/102 [==============================] - 67s 656ms/step - loss: 0.0051 - mae: 0.0520\n",
            "Epoch 91/100\n",
            "102/102 [==============================] - 67s 661ms/step - loss: 0.0049 - mae: 0.0511\n",
            "Epoch 92/100\n",
            "102/102 [==============================] - 67s 661ms/step - loss: 0.0050 - mae: 0.0508\n",
            "Epoch 93/100\n",
            "102/102 [==============================] - 67s 658ms/step - loss: 0.0048 - mae: 0.0501\n",
            "Epoch 94/100\n",
            "102/102 [==============================] - 68s 663ms/step - loss: 0.0046 - mae: 0.0489\n",
            "Epoch 95/100\n",
            "102/102 [==============================] - 67s 661ms/step - loss: 0.0046 - mae: 0.0494\n",
            "Epoch 96/100\n",
            "102/102 [==============================] - 67s 661ms/step - loss: 0.0049 - mae: 0.0501\n",
            "Epoch 97/100\n",
            "102/102 [==============================] - 67s 660ms/step - loss: 0.0045 - mae: 0.0478\n",
            "Epoch 98/100\n",
            "102/102 [==============================] - 67s 661ms/step - loss: 0.0048 - mae: 0.0494\n",
            "Epoch 99/100\n",
            "102/102 [==============================] - 68s 662ms/step - loss: 0.0046 - mae: 0.0484\n",
            "Epoch 100/100\n",
            "102/102 [==============================] - 67s 661ms/step - loss: 0.0043 - mae: 0.0471\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab Notebooks/AES/clean_semantic.pt/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Assets written to: /content/drive/MyDrive/Colab Notebooks/AES/clean_semantic.pt/assets\n",
            "<keras.layers.recurrent.LSTMCell object at 0x7faab00f7c10> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "<keras.layers.recurrent.LSTMCell object at 0x7faa87e9b910> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        }
      ],
      "source": [
        "load_trained_model_clean_semantic = False\n",
        "if (load_trained_model_clean_semantic == True):\n",
        "    lstm_model_coh_nsp = load_model(clean_semantic_model_save_path)\n",
        "else:\n",
        "  if (embedding == 'full_emb'):\n",
        "    lstm_model_clean_semantic = get_model(Hidden_dim1=1028, Hidden_dim2=512, return_sequences = True, dropout_dense=0.5, dropout_lstm=0.4, \n",
        "                             recurrent_dropout=0.4, sen_size=max_words_for_full_emb_sem, input_size=768, activation='sigmoid', \n",
        "                             opt_engine='adam', loss_fn='mse')\n",
        "  else:\n",
        "    lstm_model_clean_semantic = get_model(Hidden_dim1=1028, Hidden_dim2=512, return_sequences = True, dropout_dense=0.5, dropout_lstm=0.4, \n",
        "                             recurrent_dropout=0.4, sen_size=max_sentences, input_size=768, activation='sigmoid', \n",
        "                             opt_engine='adam', loss_fn='mse')\n",
        "  lstm_model_clean_semantic.fit(lhs_train.numpy(), y_train, batch_size=64, epochs=100)\n",
        "  lstm_model_clean_semantic.save(clean_semantic_model_save_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmJmjkXe0Fy4"
      },
      "source": [
        "### Evaluating the semantic model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WhlWVVyn0Fy5",
        "outputId": "82b48cf1-5212-48f5-dbb0-ffb7d443c028"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Kappa Score: 0.7640924160128812\n",
            "MSE:  0.022570307359501808\n",
            "RMSE:  0.15023417507179188\n"
          ]
        }
      ],
      "source": [
        "evaluate_model (lstm_model_clean_semantic, lhs_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ul8rCs00cety"
      },
      "source": [
        "## Case 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BN4VJrrfcvcm"
      },
      "source": [
        "**Semantic Score:** LSTM\n",
        "\n",
        "**Coherence Score:** LSTM + NSP Goldens\n",
        "\n",
        "**Promp-relevance Score:** LSTM + Cosine Similarity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZU3HUdweSKg"
      },
      "source": [
        "### Semantic Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3KcCi_rdeWV"
      },
      "source": [
        "#### Load Semantic Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wyfSjxEHddPe"
      },
      "outputs": [],
      "source": [
        "load_trained_model_sem = True\n",
        "if (load_trained_model_sem == True):\n",
        "    lstm_model_sem = load_model(sem_model_save_path)\n",
        "else:\n",
        "  if (embedding == 'full_emb'):\n",
        "    lstm_model_sem = get_model(Hidden_dim1=1028, Hidden_dim2=512, return_sequences = True, dropout_dense=0.5, dropout_lstm=0.4, \n",
        "                             recurrent_dropout=0.4, sen_size=max_words_for_full_emb_sem, input_size=768, activation='sigmoid', \n",
        "                             opt_engine='adam', loss_fn='mse')\n",
        "  else:\n",
        "    lstm_model_sem = get_model(Hidden_dim1=1028, Hidden_dim2=512, return_sequences = True, dropout_dense=0.5, dropout_lstm=0.4, \n",
        "                             recurrent_dropout=0.4, sen_size=max_sentences, input_size=768, activation='sigmoid', \n",
        "                             opt_engine='adam', loss_fn='mse')\n",
        "  lstm_model_sem.fit(lhs_train.numpy(), y_train, batch_size=64, epochs=100)\n",
        "  lstm_model_sem.save(sem_model_save_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5klVNw-eOeN"
      },
      "source": [
        "#### Evaluating the semantic model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMcF4eO-eOeO",
        "outputId": "6e439c18-0701-434a-870f-e826fcd6928c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Kappa Score: 0.746204577711272\n",
            "MSE:  0.02282681984321185\n",
            "RMSE:  0.15108547197931324\n"
          ]
        }
      ],
      "source": [
        "evaluate_model (lstm_model_sem, lhs_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZQ4Y6QFemWq"
      },
      "source": [
        "### Coherence Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFKIBtOD5CpI"
      },
      "source": [
        "#### Creating augmented dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JmKKPhnL5CpL",
        "outputId": "42a7b6a5-bca2-4d52-b1e1-ee694accd359"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original Train Data Shape (6488, 6)\n",
            "Original Test Data Shape (2596, 6)\n",
            "Augmented Train Data Shape (8629, 4)\n",
            "Augmented Test Data Shape (3453, 4)\n"
          ]
        }
      ],
      "source": [
        "print (\"Original Train Data Shape\", tpd_train.shape)\n",
        "print (\"Original Test Data Shape\", tpd_test.shape)\n",
        "\n",
        "samp_tpd_train = tpd_train.sample(frac=0.33)\n",
        "samp_tpd_train['essay'] = samp_tpd_train['essay'].apply(lambda x: coherence_augment(x))\n",
        "samp_tpd_train['normalized_score'] = 0\n",
        "aug_data_train = tpd_train.append(samp_tpd_train)\n",
        "aug_data_train = aug_data_train.reset_index()\n",
        "aug_data_train = aug_data_train.drop(columns=['Unnamed: 0','domain1_score','index'])\n",
        "print (\"Augmented Train Data Shape\", aug_data_train.shape)\n",
        "\n",
        "samp_tpd_test = tpd_test.sample(frac=0.33)\n",
        "samp_tpd_test['essay'] = samp_tpd_test['essay'].apply(lambda x: coherence_augment(x))\n",
        "samp_tpd_test['normalized_score'] = 0\n",
        "aug_data_test = tpd_test.append(samp_tpd_test)\n",
        "aug_data_test = aug_data_test.reset_index()\n",
        "aug_data_test = aug_data_test.drop(columns=['Unnamed: 0','domain1_score','index'])\n",
        "print (\"Augmented Test Data Shape\", aug_data_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "g5KqSkccHKJo",
        "outputId": "e662410d-fb5f-4c1e-d0de-afdb42b31c74"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-5c0a1106-07d3-4482-8e9d-1b9cc7741732\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>essay_id</th>\n",
              "      <th>essay_set</th>\n",
              "      <th>essay</th>\n",
              "      <th>normalized_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9064</td>\n",
              "      <td>4</td>\n",
              "      <td>The reason why at the end of the story she end...</td>\n",
              "      <td>0.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8884</td>\n",
              "      <td>4</td>\n",
              "      <td>They probably ended it like that to build susp...</td>\n",
              "      <td>0.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6929</td>\n",
              "      <td>3</td>\n",
              "      <td>The setting in the essay Rough Road ahead; Do...</td>\n",
              "      <td>0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>15816</td>\n",
              "      <td>6</td>\n",
              "      <td>Based on the excerpt, The Mooring Mast, the ob...</td>\n",
              "      <td>0.750000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>368</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear , Computers have helped us in many ways. ...</td>\n",
              "      <td>0.700000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3448</th>\n",
              "      <td>6239</td>\n",
              "      <td>3</td>\n",
              "      <td>Kurmaskie experienced a harsh scenery with hig...</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3449</th>\n",
              "      <td>12001</td>\n",
              "      <td>5</td>\n",
              "      <td>There is lots of emotion because Narciso talks...</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3450</th>\n",
              "      <td>15864</td>\n",
              "      <td>6</td>\n",
              "      <td>Also, \"Most dirigibles from out side of the Un...</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3451</th>\n",
              "      <td>21390</td>\n",
              "      <td>8</td>\n",
              "      <td>That's is how much i was laughing. I was laugh...</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3452</th>\n",
              "      <td>134</td>\n",
              "      <td>1</td>\n",
              "      <td>My second reason is that computers help with e...</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3453 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5c0a1106-07d3-4482-8e9d-1b9cc7741732')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5c0a1106-07d3-4482-8e9d-1b9cc7741732 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5c0a1106-07d3-4482-8e9d-1b9cc7741732');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      essay_id  ...  normalized_score\n",
              "0         9064  ...          0.333333\n",
              "1         8884  ...          0.333333\n",
              "2         6929  ...          0.666667\n",
              "3        15816  ...          0.750000\n",
              "4          368  ...          0.700000\n",
              "...        ...  ...               ...\n",
              "3448      6239  ...          0.000000\n",
              "3449     12001  ...          0.000000\n",
              "3450     15864  ...          0.000000\n",
              "3451     21390  ...          0.000000\n",
              "3452       134  ...          0.000000\n",
              "\n",
              "[3453 rows x 4 columns]"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "aug_data_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbbizpTdiYjZ"
      },
      "source": [
        "#### Creating aug TPD dataset with NSP Goldens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        },
        "id": "CcTCl7zViq5K",
        "outputId": "410094a8-b2be-4b6f-e2ef-15fe0db613f3"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "303eb063f8804eafb91c26cc1307871f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f26de9ba05cb498bafa031460fd0a576",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2f0573a9e67346bf98b68b62c48fdc46",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d2b56440c92e4decac8537a3fd642f90",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "86878317cd0844f68ac4680422add313",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/420M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForNextSentencePrediction: ['cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertForNextSentencePrediction from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForNextSentencePrediction from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertTokenizer, BertForNextSentencePrediction\n",
        "import torch\n",
        "from torch.nn import functional as F\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertForNextSentencePrediction.from_pretrained('bert-base-uncased')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gLECWZ_96Dh5"
      },
      "outputs": [],
      "source": [
        "def nsp_average(essay):\n",
        "  score = 0\n",
        "  avg_score = 0\n",
        "  sentences = split_into_sentences(essay)\n",
        "  if len(sentences) != 0:\n",
        "    for i in range(len(sentences)-1):\n",
        "        encoding = tokenizer.encode_plus(sentences[i], sentences[i+1], return_tensors='pt')\n",
        "        outputs = model(**encoding).logits\n",
        "        softmax = F.softmax(outputs, dim = 1)\n",
        "        score = score + np.float (softmax[0][0])\n",
        "    avg_score = score / len(sentences)\n",
        "  # print(\"Total score: \", score, \"Avg. score: \", avg_score)\n",
        "  # print (\"Sentences:\\n\", sentences)\n",
        "  return avg_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O7yoTJ4Piq5L",
        "outputId": "c7625b2e-aaaa-43fc-f965-3024c4fc95bb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 8629/8629 [2:30:37<00:00,  1.05s/it]\n",
            "100%|██████████| 3453/3453 [58:11<00:00,  1.01s/it]\n"
          ]
        }
      ],
      "source": [
        "#get nsp \n",
        "aug_data_train['nsp_golden'] = 0\n",
        "for i in tqdm(range(len(aug_data_train))):\n",
        "    aug_data_train.loc[i,'nsp_golden'] = nsp_average(aug_data_train['essay'][i])\n",
        "aug_data_train.to_csv(\"/content/drive/MyDrive/Colab Notebooks/AES/aug_data_train_coh_with_nsp.csv\")\n",
        "\n",
        "aug_data_test['nsp_golden'] = 0\n",
        "for i in tqdm(range(len(aug_data_test))):\n",
        "    aug_data_test.loc[i,'nsp_golden'] = nsp_average(aug_data_test['essay'][i])\n",
        "aug_data_test.to_csv(\"/content/drive/MyDrive/Colab Notebooks/AES/aug_data_test_coh_with_nsp.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0mgk4VSiTicZ"
      },
      "outputs": [],
      "source": [
        "aug_data_train = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/AES/aug_data_train_coh_with_nsp.csv')\n",
        "aug_data_test = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/AES/aug_data_test_coh_with_nsp.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfWlMOjF-8J3"
      },
      "source": [
        "#### Creating embeddings for training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1Oa-tbJ-8J3",
        "outputId": "f6f8bd02-4bb0-4e3a-8671-debef6219b0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Preparing Embeddings...\n",
            "Model Type:  coherence\n",
            "Embedding Type:  sen_avg\n",
            "hState:  last4sum\n",
            "Save File Directory:  /content/drive/MyDrive/Colab Notebooks/AES/aug_data_train_coh_with_nsp\n",
            "Dataframe provided, Size:  (8629, 6)\n",
            "Loading existing embeddings from file...\n",
            "LHS File chosen:  /content/drive/MyDrive/Colab Notebooks/AES/aug_data_train_coh_with_nsp/lhs_coherence_train.pt\n",
            "Y File chosen:  /content/drive/MyDrive/Colab Notebooks/AES/aug_data_train_coh_with_nsp/y_train_coh.pt\n",
            "Loaded, Size of LHS embeddings:  torch.Size([8629, 128, 768])\n",
            "Loaded, Size of y Gold:  (8629,)\n",
            "Returning lhs: Shape:  torch.Size([8629, 128, 768])\n",
            "Returning y_gold: Shape:  (8629,)\n"
          ]
        }
      ],
      "source": [
        "lhs_train_coh, y_train_coh = prepare_embeddings_updated (aug_data_train, model_type='coherence', train_or_test='train', load_from_file=True, embedding_type='sen_avg', max_words=max_words_for_full_emb, file_path='/content/drive/MyDrive/Colab Notebooks/AES/aug_data_train_coh_with_nsp')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDIpCNPP-8J3"
      },
      "source": [
        "#### Creating embedding for test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfTrk0E7-8J3",
        "outputId": "70a3d5b6-4ed6-4843-a2a0-7febfed6a0d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Preparing Embeddings...\n",
            "Model Type:  coherence\n",
            "Embedding Type:  sen_avg\n",
            "hState:  last4sum\n",
            "Save File Directory:  /content/drive/MyDrive/Colab Notebooks/AES/aug_data_test_coh_with_nsp\n",
            "Dataframe provided, Size:  (3453, 6)\n",
            "Loading existing embeddings from file...\n",
            "LHS File chosen:  /content/drive/MyDrive/Colab Notebooks/AES/aug_data_test_coh_with_nsp/lhs_coherence_test.pt\n",
            "Y File chosen:  /content/drive/MyDrive/Colab Notebooks/AES/aug_data_test_coh_with_nsp/y_test_coh.pt\n",
            "Loaded, Size of LHS embeddings:  torch.Size([3453, 128, 768])\n",
            "Loaded, Size of y Gold:  (3453,)\n",
            "Returning lhs: Shape:  torch.Size([3453, 128, 768])\n",
            "Returning y_gold: Shape:  (3453,)\n"
          ]
        }
      ],
      "source": [
        "lhs_test_coh, y_test_coh = prepare_embeddings_updated (aug_data_test, model_type='coherence', train_or_test='test', load_from_file=True, embedding_type='sen_avg', max_words=max_words_for_full_emb, file_path='/content/drive/MyDrive/Colab Notebooks/AES/aug_data_test_coh_with_nsp')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PBqEAArfcIJ"
      },
      "source": [
        "#### Load LSTM Model for Coherence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I3KS3IDFf2BW"
      },
      "outputs": [],
      "source": [
        "coh_nsp_model_save_path = \"/content/drive/MyDrive/Colab Notebooks/AES/coherence_model_with_nsp_goldens.pt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLgzJfVKf2BW",
        "outputId": "e57dd172-2033-46ec-b87d-477719dc328f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        }
      ],
      "source": [
        "load_trained_model_coh_nsp = True\n",
        "if (load_trained_model_coh_nsp == True):\n",
        "    lstm_model_coh_nsp = load_model(coh_nsp_model_save_path)\n",
        "else:\n",
        "  if (embedding == 'full_emb'):\n",
        "    lstm_model_coh_nsp = get_model(Hidden_dim1=1028, Hidden_dim2=512, return_sequences = True, dropout_dense=0.5, dropout_lstm=0.4, \n",
        "                             recurrent_dropout=0.4, sen_size=max_words_for_full_emb_sem, input_size=768, activation='sigmoid', \n",
        "                             opt_engine='adam', loss_fn='mse')\n",
        "  else:\n",
        "    lstm_model_coh_nsp = get_model(Hidden_dim1=1028, Hidden_dim2=512, return_sequences = True, dropout_dense=0.5, dropout_lstm=0.4, \n",
        "                             recurrent_dropout=0.4, sen_size=max_sentences, input_size=768, activation='sigmoid', \n",
        "                             opt_engine='adam', loss_fn='mse')\n",
        "  lstm_model_coh_nsp.fit(lhs_train_coh.numpy(), aug_data_train.nsp_golden, batch_size=64, epochs=100)\n",
        "  lstm_model_coh_nsp.save(coh_nsp_model_save_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-kREzfrgJ8X"
      },
      "source": [
        "#### Evaluating the coherence model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KxFRaDqbgHvY",
        "outputId": "481d4949-96d5-45f4-ebe0-f52c08eb4e8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Kappa Score: 0.738342082081648\n",
            "MSE:  0.010897710812705432\n",
            "RMSE:  0.1043921012946163\n"
          ]
        }
      ],
      "source": [
        "evaluate_model (lstm_model_coh_nsp, lhs_test=lhs_test_coh, y_test=aug_data_test.nsp_golden)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0R6BJduifK0"
      },
      "source": [
        "### Prompt Relevance LSTM Model w/ Cosine Sim Goldens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w57DHa9OisOA"
      },
      "source": [
        "#### Loading cosine sim dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "id": "bjHf1yjhiyxJ",
        "outputId": "66e2af85-384b-4556-9732-efc703a3efd8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cos_sim_prel_data shape:  (4542, 8)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-8b4dc8bb-13ad-45a8-b165-dc8f13ebfe9b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>essay_id</th>\n",
              "      <th>essay_set</th>\n",
              "      <th>essay</th>\n",
              "      <th>domain1_score</th>\n",
              "      <th>normalized_score</th>\n",
              "      <th>prompt</th>\n",
              "      <th>combined_essay</th>\n",
              "      <th>cosine_sim</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>15177</td>\n",
              "      <td>6</td>\n",
              "      <td>The builders of the empire state building atte...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.25</td>\n",
              "      <td>In their ambition to outshine the other, the a...</td>\n",
              "      <td>In their ambition to outshine the other, the a...</td>\n",
              "      <td>0.947607</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>14855</td>\n",
              "      <td>6</td>\n",
              "      <td>The builders of the many obstacles when attemp...</td>\n",
              "      <td>4</td>\n",
              "      <td>1.00</td>\n",
              "      <td>In their ambition to outshine the other, the a...</td>\n",
              "      <td>In their ambition to outshine the other, the a...</td>\n",
              "      <td>0.937073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>16587</td>\n",
              "      <td>6</td>\n",
              "      <td>The ability to dock dirigibles atop the Empire...</td>\n",
              "      <td>4</td>\n",
              "      <td>1.00</td>\n",
              "      <td>In their ambition to outshine the other, the a...</td>\n",
              "      <td>In their ambition to outshine the other, the a...</td>\n",
              "      <td>0.898640</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>16368</td>\n",
              "      <td>6</td>\n",
              "      <td>They faced many problems when trying to dock t...</td>\n",
              "      <td>2</td>\n",
              "      <td>0.50</td>\n",
              "      <td>In their ambition to outshine the other, the a...</td>\n",
              "      <td>In their ambition to outshine the other, the a...</td>\n",
              "      <td>0.862020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>15281</td>\n",
              "      <td>6</td>\n",
              "      <td>While attempting to allow dirigibles to dock a...</td>\n",
              "      <td>3</td>\n",
              "      <td>0.75</td>\n",
              "      <td>In their ambition to outshine the other, the a...</td>\n",
              "      <td>In their ambition to outshine the other, the a...</td>\n",
              "      <td>0.930908</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8b4dc8bb-13ad-45a8-b165-dc8f13ebfe9b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8b4dc8bb-13ad-45a8-b165-dc8f13ebfe9b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8b4dc8bb-13ad-45a8-b165-dc8f13ebfe9b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   essay_id  ...  cosine_sim\n",
              "0     15177  ...    0.947607\n",
              "1     14855  ...    0.937073\n",
              "2     16587  ...    0.898640\n",
              "3     16368  ...    0.862020\n",
              "4     15281  ...    0.930908\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cos_sim_prel_data = torch.load('/content/drive/MyDrive/Colab Notebooks/AES/prompt_data_with_cosine_sim.df')\n",
        "print(\"cos_sim_prel_data shape: \", cos_sim_prel_data.shape)\n",
        "cos_sim_prel_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-wGm_yHrRLmt"
      },
      "outputs": [],
      "source": [
        "prompt_data_train = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/AES/prel_data/prompt_data_train.csv\")\n",
        "prompt_data_test = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/AES/prel_data/prompt_data_test.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jCNmFzgfw6Ki"
      },
      "outputs": [],
      "source": [
        "lhs_prompts = torch.load( '/content/drive/MyDrive/Colab Notebooks/AES/prompts_lhs.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kTSB1iyGxSaM"
      },
      "outputs": [],
      "source": [
        "def return_shuffle_prompt(p, prompts):\n",
        "    essay_id = prompts.essay_set[prompts['prompt'] == p]\n",
        "    essay_ids = list(range(1,9))\n",
        "    essay_ids.remove(int(essay_id))\n",
        "    ran_id = random.choice(essay_ids)\n",
        "    return prompts.prompt[ran_id-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZmY07D-dI1Ao"
      },
      "outputs": [],
      "source": [
        "samp_prompt_train = prompt_data_train.sample(frac=0.33)\n",
        "samp_prompt_train['prompt'] = samp_prompt_train['prompt'].apply(lambda x: str(return_shuffle_prompt(x,prompts)))\n",
        "samp_prompt_train['combined_essay'] = samp_prompt_train['prompt'] + samp_prompt_train['essay']\n",
        "aug_data_train_prel = prompt_data_train.append(samp_prompt_train)\n",
        "aug_data_train_prel = aug_data_train_prel.reset_index()\n",
        "aug_data_train_prel = aug_data_train_prel.drop(columns=['index'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 657
        },
        "id": "enBzEN8zKtQM",
        "outputId": "17cd76be-c831-44aa-f3ae-1739d7127684"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-eef72711-8f85-41bb-9cf9-917be41c79bb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>essay_id</th>\n",
              "      <th>essay_set</th>\n",
              "      <th>essay</th>\n",
              "      <th>domain1_score</th>\n",
              "      <th>normalized_score</th>\n",
              "      <th>prompt</th>\n",
              "      <th>combined_essay</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9908</td>\n",
              "      <td>4</td>\n",
              "      <td>The author concludes the story w/this paragrap...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9872</td>\n",
              "      <td>4</td>\n",
              "      <td>I believe that the author concludes the story ...</td>\n",
              "      <td>2</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9441</td>\n",
              "      <td>4</td>\n",
              "      <td>The author of the Winter Hibiscus concludes th...</td>\n",
              "      <td>3</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9110</td>\n",
              "      <td>4</td>\n",
              "      <td>From the story, Winter Hibiscus, by Minfong ...</td>\n",
              "      <td>2</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10540</td>\n",
              "      <td>4</td>\n",
              "      <td>I believe that the author chose to conclude th...</td>\n",
              "      <td>2</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8624</th>\n",
              "      <td>7221</td>\n",
              "      <td>3</td>\n",
              "      <td>The setting sffects the cyclist by the need an...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>In their ambition to outshine the other, the a...</td>\n",
              "      <td>In their ambition to outshine the other, the a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8625</th>\n",
              "      <td>15703</td>\n",
              "      <td>6</td>\n",
              "      <td>While attempting to allow dirigibles to dock o...</td>\n",
              "      <td>4</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>The author is a second-generation Cuban migran...</td>\n",
              "      <td>The author is a second-generation Cuban migran...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8626</th>\n",
              "      <td>20933</td>\n",
              "      <td>8</td>\n",
              "      <td>Laughter is such a marvelous element to have i...</td>\n",
              "      <td>32</td>\n",
              "      <td>0.533333</td>\n",
              "      <td>In their ambition to outshine the other, the a...</td>\n",
              "      <td>In their ambition to outshine the other, the a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8627</th>\n",
              "      <td>9071</td>\n",
              "      <td>4</td>\n",
              "      <td>The author chooses to end this story like this...</td>\n",
              "      <td>2</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>The author is a second-generation Cuban migran...</td>\n",
              "      <td>The author is a second-generation Cuban migran...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8628</th>\n",
              "      <td>12381</td>\n",
              "      <td>5</td>\n",
              "      <td>The mood that the created in the memoir is . T...</td>\n",
              "      <td>2</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>We all understand the benefits of laughter. Fo...</td>\n",
              "      <td>We all understand the benefits of laughter. Fo...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8629 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eef72711-8f85-41bb-9cf9-917be41c79bb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-eef72711-8f85-41bb-9cf9-917be41c79bb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-eef72711-8f85-41bb-9cf9-917be41c79bb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      essay_id  ...                                     combined_essay\n",
              "0         9908  ...  Saeng is a teenaged Vietnamese migrant in the ...\n",
              "1         9872  ...  Saeng is a teenaged Vietnamese migrant in the ...\n",
              "2         9441  ...  Saeng is a teenaged Vietnamese migrant in the ...\n",
              "3         9110  ...  Saeng is a teenaged Vietnamese migrant in the ...\n",
              "4        10540  ...  Saeng is a teenaged Vietnamese migrant in the ...\n",
              "...        ...  ...                                                ...\n",
              "8624      7221  ...  In their ambition to outshine the other, the a...\n",
              "8625     15703  ...  The author is a second-generation Cuban migran...\n",
              "8626     20933  ...  In their ambition to outshine the other, the a...\n",
              "8627      9071  ...  The author is a second-generation Cuban migran...\n",
              "8628     12381  ...  We all understand the benefits of laughter. Fo...\n",
              "\n",
              "[8629 rows x 7 columns]"
            ]
          },
          "execution_count": 174,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "aug_data_train_prel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n16IZ7PmQJ5O"
      },
      "outputs": [],
      "source": [
        "samp_prompt_test = prompt_data_test.sample(frac=0.33)\n",
        "samp_prompt_test['prompt'] = samp_prompt_test['prompt'].apply(lambda x: str(return_shuffle_prompt(x,prompts)))\n",
        "samp_prompt_test['combined_essay'] = samp_prompt_test['prompt'] + samp_prompt_test['essay']\n",
        "aug_data_test_prel = prompt_data_test.append(samp_prompt_test)\n",
        "aug_data_test_prel = aug_data_test_prel.reset_index()\n",
        "aug_data_test_prel = aug_data_test_prel.drop(columns=['index'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "U4JnRjkZQiJK",
        "outputId": "8bf960bb-72d7-4510-84cb-80acabeb53a3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-55a37cbc-f9e0-460b-8be0-89b790f32592\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>essay_id</th>\n",
              "      <th>essay_set</th>\n",
              "      <th>essay</th>\n",
              "      <th>domain1_score</th>\n",
              "      <th>normalized_score</th>\n",
              "      <th>prompt</th>\n",
              "      <th>combined_essay</th>\n",
              "      <th>cosine_sim</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>5510</td>\n",
              "      <td>9064</td>\n",
              "      <td>4</td>\n",
              "      <td>The reason why at the end of the story she end...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "      <td>0.864728</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>5330</td>\n",
              "      <td>8884</td>\n",
              "      <td>4</td>\n",
              "      <td>They probably ended it like that to build susp...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "      <td>0.831380</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>6230</td>\n",
              "      <td>9787</td>\n",
              "      <td>4</td>\n",
              "      <td>The author coNcludes the story with this parag...</td>\n",
              "      <td>2</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "      <td>0.903829</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>6272</td>\n",
              "      <td>9829</td>\n",
              "      <td>4</td>\n",
              "      <td>The author concludes the story Winter Hibiscu...</td>\n",
              "      <td>3</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "      <td>0.945830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>6164</td>\n",
              "      <td>9721</td>\n",
              "      <td>4</td>\n",
              "      <td>He concludes this story like that so you dont ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "      <td>0.894628</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3448</th>\n",
              "      <td>3448</td>\n",
              "      <td>699</td>\n",
              "      <td>702</td>\n",
              "      <td>1</td>\n",
              "      <td>My opinion about the effects of computers is t...</td>\n",
              "      <td>6</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "      <td>0.890502</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3449</th>\n",
              "      <td>3449</td>\n",
              "      <td>6570</td>\n",
              "      <td>10127</td>\n",
              "      <td>4</td>\n",
              "      <td>The author of Winter Hibiscus included the l...</td>\n",
              "      <td>3</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>More and more people use computers, but not ev...</td>\n",
              "      <td>More and more people use computers, but not ev...</td>\n",
              "      <td>0.925911</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3450</th>\n",
              "      <td>3450</td>\n",
              "      <td>5207</td>\n",
              "      <td>7607</td>\n",
              "      <td>3</td>\n",
              "      <td>There are a lot of things that effect the cycl...</td>\n",
              "      <td>2</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>More and more people use computers, but not ev...</td>\n",
              "      <td>More and more people use computers, but not ev...</td>\n",
              "      <td>0.851332</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3451</th>\n",
              "      <td>3451</td>\n",
              "      <td>11559</td>\n",
              "      <td>18807</td>\n",
              "      <td>7</td>\n",
              "      <td>A time when I was patient was when I was in gr...</td>\n",
              "      <td>7</td>\n",
              "      <td>0.233333</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "      <td>0.773099</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3452</th>\n",
              "      <td>3452</td>\n",
              "      <td>7245</td>\n",
              "      <td>11993</td>\n",
              "      <td>5</td>\n",
              "      <td>I've often told them of my admiration for thei...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "      <td>0.847773</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3453 rows × 10 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-55a37cbc-f9e0-460b-8be0-89b790f32592')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-55a37cbc-f9e0-460b-8be0-89b790f32592 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-55a37cbc-f9e0-460b-8be0-89b790f32592');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      Unnamed: 0  ...  cosine_sim\n",
              "0              0  ...    0.864728\n",
              "1              1  ...    0.831380\n",
              "2              2  ...    0.903829\n",
              "3              3  ...    0.945830\n",
              "4              4  ...    0.894628\n",
              "...          ...  ...         ...\n",
              "3448        3448  ...    0.890502\n",
              "3449        3449  ...    0.925911\n",
              "3450        3450  ...    0.851332\n",
              "3451        3451  ...    0.773099\n",
              "3452        3452  ...    0.847773\n",
              "\n",
              "[3453 rows x 10 columns]"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "aug_data_test_prel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        },
        "id": "zkOpEHODQs60",
        "outputId": "41720c19-eeff-4869-bae0-99705f85d74f"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-3a3236163907>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maug_data_test_prel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/Colab Notebooks/AES/prel_data/aug_data_test_prel.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0maug_data_train_prel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/Colab Notebooks/AES/prel_data/aug_data_train_prel.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'aug_data_test_prel' is not defined"
          ]
        }
      ],
      "source": [
        "aug_data_test_prel.to_csv(\"/content/drive/MyDrive/Colab Notebooks/AES/prel_data/aug_data_test_prel.csv\")\n",
        "aug_data_train_prel.to_csv(\"/content/drive/MyDrive/Colab Notebooks/AES/prel_data/aug_data_train_prel.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UHzXvGRq0K3r"
      },
      "outputs": [],
      "source": [
        "aug_data_train_prel=pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/AES/prel_data/aug_data_train_prel_with.csv\")\n",
        "aug_data_test_prel=pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/AES/prel_data/aug_data_test_prel.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SH2N3gWYEfXc",
        "outputId": "8174f207-f5f2-4627-ff5d-8bf9740d8749"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train shape:  (8629, 8)\n",
            "test shape:  (3453, 9)\n"
          ]
        }
      ],
      "source": [
        "print(\"train shape: \", aug_data_train_prel.shape)\n",
        "print(\"test shape: \", aug_data_test_prel.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6KHYRTjjSgm6"
      },
      "outputs": [],
      "source": [
        "aug_data_test_prel['cosine_sim'] = 0\n",
        "aug_data_train_prel['cosine_sim'] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252,
          "referenced_widgets": [
            "c635355a8f054ec1b15f71862a838a98",
            "2a62ef463c4b436d9327831cb15e2dc3",
            "a2a246dc90564c6398e79803d06c2c55",
            "90e84be76bdc45629fb748db00aae92f",
            "e84b0e22768043cf89e7ccc7e538096d",
            "4f3b4bbb737841afa330e9459170433c",
            "b6edddb02efb425b903076f0cf87c976",
            "0171469191484006a9354720c27c5a0c",
            "8c7b8eeb26ab432f8eb6805533dbae27",
            "9884f1119288448384be09dd75f7b590",
            "461624643109418193f213d1e6b244ea",
            "3a74bf3f25fe417a90f9dabe99209cf4",
            "73792d96239e48909273911f0cb7db7b",
            "7194f17fea074ef8ace4c1fb7cbe3d13",
            "f3d2b2a2aaf54a6eac17fdf31af5242b",
            "e1df78df65cb4ffa889e0c6f87bf3546",
            "e15990c94df746818577f6d4987ac689",
            "8ce19927c9af4cc7ad8b4af9a94fbd42",
            "a617166331334ef38aa5ab60576416dc",
            "c4af460e3b3c4d2685808f564c17d915",
            "3d6da0d3a7b745308daeda0b221e19a6",
            "96f1e836186d4c768a280f860c4324da",
            "317829c743344e40b90d1ee5355653da",
            "5004b386c81c41429b2a9c6fa523c12f",
            "bf1fafd44b634c2396dc5e18d67a260d",
            "2ce86e3546634bb197c0e9ea950e9c56",
            "61e5bc5bb4614816a0a4678efd3a219f",
            "0f2f6a15053f4cd1baeadcf541d1a40b",
            "63a9a234010742f6bd279368e849b04b",
            "dfa7eccb0de44080808818706385adcc",
            "620345fed03b4b8f80b4ec250898b359",
            "8828c7e012ea49baa4f24c55e6895468",
            "53e18eef9f564a80a85e98439645b61a",
            "6197d372a233499890664cf3f1e40fda",
            "81b9c468215e45e49c2b8f9583be4245",
            "2b9989b684e04a32bb759c1ccba68f32",
            "cdf1b07671bd440b86c2687b11316673",
            "4bff61a41ab2416fb8058d46147b9c1a",
            "70606f4940f04977bf4cc8d63d725ac8",
            "e3e4a249923d4a0fbb06ec3a7319ba1b",
            "c1618c02b957453db8785e47f008f239",
            "fbdcf8e40cb748448a269b235dd59f2d",
            "1e889f1fe8a84d098a73cf2077f25862",
            "b11106c5a21948d3a0d50d5e39c31a1e",
            "0d2373f446df40bfb808af517dbc5f9b",
            "6d81e7badfa9490dac1415746931d5cf",
            "358c6230a3c44959909ad4649f6ab882",
            "ca4252a9263b46d4bab8df81f147ad67",
            "90cd40a619314bd4a7ce0901b1d02d43",
            "e4b63c6d1d094c948a5abceeafb872d3",
            "ad40979c03ef466b8a86c20bcef4b585",
            "7d5e5871f40a4f28b1117940a4cf27b3",
            "e01a6f5f808e4a70bd1a2ba20b655d00",
            "2474d7fa1d4d4f588c74c108f400edf0",
            "73e88557b7b549cba8c48a39df765d1d"
          ]
        },
        "id": "1OmVcw1mTK0L",
        "outputId": "b20654df-3d0e-49ca-ec29-652ddabb340e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c635355a8f054ec1b15f71862a838a98",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3a74bf3f25fe417a90f9dabe99209cf4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "317829c743344e40b90d1ee5355653da",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6197d372a233499890664cf3f1e40fda",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0d2373f446df40bfb808af517dbc5f9b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/420M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertModel, BertConfig, BertTokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "config = BertConfig.from_pretrained('bert-base-uncased', output_hidden_states=True)\n",
        "model = BertModel.from_pretrained('bert-base-uncased', config=config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ayQwdkYTrxJ"
      },
      "outputs": [],
      "source": [
        "cos = torch.nn.CosineSimilarity(dim=1, eps=1e-08)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iPyMX7VFw_Jn",
        "outputId": "caa4f5d0-cc72-4ca0-de4e-2d96ab238810"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/8629 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:1732: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._setitem_single_block(indexer, value, name)\n",
            "  1%|          | 107/8629 [00:37<56:54,  2.50it/s]  /usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.\n",
            "  out=out, **kwargs)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:182: RuntimeWarning: invalid value encountered in true_divide\n",
            "  ret, rcount, out=ret, casting='unsafe', subok=False)\n",
            "100%|██████████| 8629/8629 [2:05:38<00:00,  1.14it/s]\n"
          ]
        }
      ],
      "source": [
        "lhs_essay = torch.empty((1,768), dtype=torch.float)\n",
        "\n",
        "for j in tqdm(range(len(aug_data_train_prel))):\n",
        "  essay = aug_data_train_prel.essay.iloc[j]\n",
        "  sentences = split_into_sentences(essay)\n",
        "\n",
        "  sen_length = len(sentences)\n",
        "  \n",
        "  lhs_sentence_avg = np.zeros((1,768), dtype=float)\n",
        "  lhs_avg_sen = np.empty((0,768), dtype=float)\n",
        "\n",
        "  for i in range(min(max_sentences,len(sentences))):\n",
        "    tokenize_sentence = tokenizer.encode(sentences[i],add_special_tokens=True, max_length=512, truncation=True)\n",
        "    tt = torch.tensor(tokenize_sentence)\n",
        "    tts = tt.reshape(1,len(tt))\n",
        "    # getting the 2nd last layer\n",
        "    output = model(tts)\n",
        "    lhs_sentence = output.hidden_states[12] + output.hidden_states[11] + output.hidden_states[10] + output.hidden_states[9]\n",
        "    lhs_sentence_np = np.array(lhs_sentence.detach().numpy())\n",
        "    lhs_sentence_np_mean = np.mean(lhs_sentence_np,axis=1)\n",
        "    lhs_avg_sen = np.append(lhs_avg_sen,lhs_sentence_np_mean, axis=0)\n",
        "\n",
        "  lhs_sentence_avg = np.mean(lhs_avg_sen, axis=0, keepdims=True)\n",
        "  lhs_essay = torch.tensor(lhs_sentence_avg)\n",
        "#   print(\"Cosine sim: \", cos(lhs_prompts[aug_data_train_prel.essay_set.iloc[j]-1] , lhs_essay ))\n",
        "  aug_data_train_prel.cosine_sim.iloc[j] = float(cos(lhs_prompts[aug_data_train_prel.essay_set.iloc[j]-1] , lhs_essay))\n",
        "  \n",
        "torch.save(aug_data_train_prel, '/content/drive/MyDrive/Colab Notebooks/AES/prel_data/aug_data_train_prel_with_cosine_sim.df')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjSSbj-yjCuP",
        "outputId": "2976428d-b40e-4a4a-8d0b-071d1606c842"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/3453 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:1732: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._setitem_single_block(indexer, value, name)\n",
            "  1%|          | 36/3453 [00:11<14:52,  3.83it/s]/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.\n",
            "  out=out, **kwargs)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:182: RuntimeWarning: invalid value encountered in true_divide\n",
            "  ret, rcount, out=ret, casting='unsafe', subok=False)\n",
            "100%|██████████| 3453/3453 [49:49<00:00,  1.15it/s]\n"
          ]
        }
      ],
      "source": [
        "lhs_essay = torch.empty((1,768), dtype=torch.float)\n",
        "\n",
        "for j in tqdm(range(len(aug_data_test_prel))):\n",
        "  essay = aug_data_test_prel.essay.iloc[j]\n",
        "  sentences = split_into_sentences(essay)\n",
        "\n",
        "  sen_length = len(sentences)\n",
        "  \n",
        "  lhs_sentence_avg = np.zeros((1,768), dtype=float)\n",
        "  lhs_avg_sen = np.empty((0,768), dtype=float)\n",
        "\n",
        "  for i in range(min(max_sentences,len(sentences))):\n",
        "    tokenize_sentence = tokenizer.encode(sentences[i],add_special_tokens=True, max_length=512, truncation=True)\n",
        "    tt = torch.tensor(tokenize_sentence)\n",
        "    tts = tt.reshape(1,len(tt))\n",
        "    # getting the 2nd last layer\n",
        "    output = model(tts)\n",
        "    lhs_sentence = output.hidden_states[12] + output.hidden_states[11] + output.hidden_states[10] + output.hidden_states[9]\n",
        "    lhs_sentence_np = np.array(lhs_sentence.detach().numpy())\n",
        "    lhs_sentence_np_mean = np.mean(lhs_sentence_np,axis=1)\n",
        "    lhs_avg_sen = np.append(lhs_avg_sen,lhs_sentence_np_mean, axis=0)\n",
        "\n",
        "  lhs_sentence_avg = np.mean(lhs_avg_sen, axis=0, keepdims=True)\n",
        "  lhs_essay = torch.tensor(lhs_sentence_avg)\n",
        "#   print(\"Cosine sim: \", cos(lhs_prompts[aug_data_train_prel.essay_set.iloc[j]-1] , lhs_essay ))\n",
        "  aug_data_test_prel.cosine_sim.iloc[j] = float(cos(lhs_prompts[aug_data_test_prel.essay_set.iloc[j]-1] , lhs_essay))\n",
        "  \n",
        "torch.save(aug_data_test_prel, '/content/drive/MyDrive/Colab Notebooks/AES/prel_data/aug_data_test_prel_with_cosine_sim.df')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2OMjE6RkEFc"
      },
      "source": [
        "#### Load or Create BERT Embeddings for Training Data for Prompt Relevance Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wdac_SyPbDDu",
        "outputId": "579cb6d4-92a3-4f56-d517-9cf42c23dc85"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(6488, 6)"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "temp_df_train = pd.DataFrame()\n",
        "tpd_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rYs-I2YHZHnC"
      },
      "outputs": [],
      "source": [
        "aug_data_train_prel = torch.load(\"/content/drive/MyDrive/Colab Notebooks/AES/prel_data/aug_data_train_prel_with_cosine_sim.df\")\n",
        "aug_data_test_prel = torch.load(\"/content/drive/MyDrive/Colab Notebooks/AES/prel_data/aug_data_test_prel_with_cosine_sim.df\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tE8FtX2okEFd",
        "outputId": "185f04e1-30f4-4b41-cc82-5f290c4e29c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Preparing Embeddings...\n",
            "Model Type:  p_rel\n",
            "Embedding Type:  sen_avg\n",
            "hState:  last4sum\n",
            "Save File Directory:  /content/drive/MyDrive/Colab Notebooks/AES/prel_data\n",
            "Dataframe provided, Size:  (8629, 9)\n",
            "Loading existing embeddings from file...\n",
            "LHS File chosen:  /content/drive/MyDrive/Colab Notebooks/AES/prel_data/lhs_prel_train.pt\n",
            "Y File chosen:  /content/drive/MyDrive/Colab Notebooks/AES/prel_data/y_train_prel.pt\n",
            "Loaded, Size of LHS embeddings:  torch.Size([8629, 128, 768])\n",
            "Loaded, Size of y Gold:  (8629,)\n",
            "Returning lhs: Shape:  torch.Size([8629, 128, 768])\n",
            "Returning y_gold: Shape:  (8629,)\n"
          ]
        }
      ],
      "source": [
        "load_bert_prel=True\n",
        "lhs_train_prel, y_train_prel = prepare_embeddings_updated (aug_data_train_prel, model_type='p_rel', train_or_test='train', load_from_file=load_bert_prel, embedding_type=embedding, max_words=max_words_for_full_emb, file_path='/content/drive/MyDrive/Colab Notebooks/AES/prel_data', gold_field='cosine_sim')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qj7bzQCxSJDd",
        "outputId": "5e257d60-4d7a-4a6a-935f-c95329186b24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Preparing Embeddings...\n",
            "Model Type:  p_rel\n",
            "Embedding Type:  sen_avg\n",
            "hState:  last4sum\n",
            "Save File Directory:  /content/drive/MyDrive/Colab Notebooks/AES/prel_data\n",
            "Dataframe provided, Size:  (3453, 10)\n",
            "Loading existing embeddings from file...\n",
            "LHS File chosen:  /content/drive/MyDrive/Colab Notebooks/AES/prel_data/lhs_prel_test.pt\n",
            "Y File chosen:  /content/drive/MyDrive/Colab Notebooks/AES/prel_data/y_test_prel.pt\n",
            "Loaded, Size of LHS embeddings:  torch.Size([3453, 128, 768])\n",
            "Loaded, Size of y Gold:  (3453,)\n",
            "Returning lhs: Shape:  torch.Size([3453, 128, 768])\n",
            "Returning y_gold: Shape:  (3453,)\n"
          ]
        }
      ],
      "source": [
        "lhs_test_prel, y_test_prel = prepare_embeddings_updated (aug_data_test_prel, model_type='p_rel', train_or_test='test', load_from_file=load_bert_prel, embedding_type=embedding, max_words=max_words_for_full_emb, file_path='/content/drive/MyDrive/Colab Notebooks/AES/prel_data', gold_field='cosine_sim')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_JAL5tocverg",
        "outputId": "effef43e-c7fd-45f3-ad8e-b81979a3634e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    0.899656\n",
              "1    0.922672\n",
              "2    0.938123\n",
              "3    0.926424\n",
              "4    0.930165\n",
              "Name: cosine_sim, dtype: float64"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train_prel.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08Ob5orGjwJX"
      },
      "source": [
        "#### Build LSTM Model for Prompt Relevance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pqCdVwsfjwJY"
      },
      "outputs": [],
      "source": [
        "prel_model_save_path = \"/content/drive/MyDrive/Colab Notebooks/AES/prel_data/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3sK5B9vjwJY",
        "outputId": "78de9822-faae-4e42-c147-c853e4574e69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 128, 1028)         7389264   \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 512)               3155968   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 513       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 10,545,745\n",
            "Trainable params: 10,545,745\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "90/90 [==============================] - 71s 706ms/step - loss: nan - mae: nan\n",
            "Epoch 2/100\n",
            "90/90 [==============================] - 62s 685ms/step - loss: nan - mae: nan\n",
            "Epoch 3/100\n",
            "90/90 [==============================] - 61s 683ms/step - loss: nan - mae: nan\n",
            "Epoch 4/100\n",
            "90/90 [==============================] - 61s 682ms/step - loss: nan - mae: nan\n",
            "Epoch 5/100\n",
            "90/90 [==============================] - 61s 680ms/step - loss: nan - mae: nan\n",
            "Epoch 6/100\n",
            "90/90 [==============================] - 61s 681ms/step - loss: nan - mae: nan\n",
            "Epoch 7/100\n",
            "90/90 [==============================] - 62s 685ms/step - loss: nan - mae: nan\n",
            "Epoch 8/100\n",
            "90/90 [==============================] - 61s 683ms/step - loss: nan - mae: nan\n",
            "Epoch 9/100\n",
            "90/90 [==============================] - 62s 684ms/step - loss: nan - mae: nan\n",
            "Epoch 10/100\n",
            "90/90 [==============================] - 62s 684ms/step - loss: nan - mae: nan\n",
            "Epoch 11/100\n",
            "90/90 [==============================] - 61s 683ms/step - loss: nan - mae: nan\n",
            "Epoch 12/100\n",
            "90/90 [==============================] - 62s 685ms/step - loss: nan - mae: nan\n",
            "Epoch 13/100\n",
            "90/90 [==============================] - 62s 688ms/step - loss: nan - mae: nan\n",
            "Epoch 14/100\n",
            "90/90 [==============================] - 61s 683ms/step - loss: nan - mae: nan\n",
            "Epoch 15/100\n",
            "90/90 [==============================] - 62s 687ms/step - loss: nan - mae: nan\n",
            "Epoch 16/100\n",
            "90/90 [==============================] - 62s 684ms/step - loss: nan - mae: nan\n",
            "Epoch 17/100\n",
            "90/90 [==============================] - 62s 684ms/step - loss: nan - mae: nan\n",
            "Epoch 18/100\n",
            "90/90 [==============================] - 61s 683ms/step - loss: nan - mae: nan\n",
            "Epoch 19/100\n",
            "90/90 [==============================] - 62s 688ms/step - loss: nan - mae: nan\n",
            "Epoch 20/100\n",
            "90/90 [==============================] - 62s 685ms/step - loss: nan - mae: nan\n",
            "Epoch 21/100\n",
            "90/90 [==============================] - 62s 684ms/step - loss: nan - mae: nan\n",
            "Epoch 22/100\n",
            "90/90 [==============================] - 61s 682ms/step - loss: nan - mae: nan\n",
            "Epoch 23/100\n",
            "90/90 [==============================] - 61s 683ms/step - loss: nan - mae: nan\n",
            "Epoch 24/100\n",
            "90/90 [==============================] - 62s 688ms/step - loss: nan - mae: nan\n",
            "Epoch 25/100\n",
            "90/90 [==============================] - 62s 695ms/step - loss: nan - mae: nan\n",
            "Epoch 26/100\n",
            "90/90 [==============================] - 62s 694ms/step - loss: nan - mae: nan\n",
            "Epoch 27/100\n",
            "90/90 [==============================] - 63s 699ms/step - loss: nan - mae: nan\n",
            "Epoch 28/100\n",
            "90/90 [==============================] - 63s 695ms/step - loss: nan - mae: nan\n",
            "Epoch 29/100\n",
            "90/90 [==============================] - 62s 692ms/step - loss: nan - mae: nan\n",
            "Epoch 30/100\n",
            "90/90 [==============================] - 62s 685ms/step - loss: nan - mae: nan\n",
            "Epoch 31/100\n",
            "90/90 [==============================] - 63s 701ms/step - loss: nan - mae: nan\n",
            "Epoch 32/100\n",
            "90/90 [==============================] - 63s 695ms/step - loss: nan - mae: nan\n",
            "Epoch 33/100\n",
            "90/90 [==============================] - 62s 689ms/step - loss: nan - mae: nan\n",
            "Epoch 34/100\n",
            "90/90 [==============================] - 62s 688ms/step - loss: nan - mae: nan\n",
            "Epoch 35/100\n",
            "90/90 [==============================] - 62s 692ms/step - loss: nan - mae: nan\n",
            "Epoch 36/100\n",
            "90/90 [==============================] - 63s 700ms/step - loss: nan - mae: nan\n",
            "Epoch 37/100\n",
            "90/90 [==============================] - 63s 700ms/step - loss: nan - mae: nan\n",
            "Epoch 38/100\n",
            "90/90 [==============================] - 62s 691ms/step - loss: nan - mae: nan\n",
            "Epoch 39/100\n",
            "90/90 [==============================] - 62s 690ms/step - loss: nan - mae: nan\n",
            "Epoch 40/100\n",
            "90/90 [==============================] - 63s 696ms/step - loss: nan - mae: nan\n",
            "Epoch 41/100\n",
            "90/90 [==============================] - 62s 689ms/step - loss: nan - mae: nan\n",
            "Epoch 42/100\n",
            "90/90 [==============================] - 62s 693ms/step - loss: nan - mae: nan\n",
            "Epoch 43/100\n",
            "90/90 [==============================] - 62s 690ms/step - loss: nan - mae: nan\n",
            "Epoch 44/100\n",
            "90/90 [==============================] - 62s 693ms/step - loss: nan - mae: nan\n",
            "Epoch 45/100\n",
            "90/90 [==============================] - 62s 693ms/step - loss: nan - mae: nan\n",
            "Epoch 46/100\n",
            "90/90 [==============================] - 62s 688ms/step - loss: nan - mae: nan\n",
            "Epoch 47/100\n",
            "90/90 [==============================] - 62s 690ms/step - loss: nan - mae: nan\n",
            "Epoch 48/100\n",
            "90/90 [==============================] - 62s 689ms/step - loss: nan - mae: nan\n",
            "Epoch 49/100\n",
            "90/90 [==============================] - 62s 693ms/step - loss: nan - mae: nan\n",
            "Epoch 50/100\n",
            "90/90 [==============================] - 62s 688ms/step - loss: nan - mae: nan\n",
            "Epoch 51/100\n",
            "90/90 [==============================] - 62s 691ms/step - loss: nan - mae: nan\n",
            "Epoch 52/100\n",
            "90/90 [==============================] - 62s 690ms/step - loss: nan - mae: nan\n",
            "Epoch 53/100\n",
            "90/90 [==============================] - 62s 690ms/step - loss: nan - mae: nan\n",
            "Epoch 54/100\n",
            "90/90 [==============================] - 62s 687ms/step - loss: nan - mae: nan\n",
            "Epoch 55/100\n",
            "90/90 [==============================] - 62s 688ms/step - loss: nan - mae: nan\n",
            "Epoch 56/100\n",
            "90/90 [==============================] - 62s 687ms/step - loss: nan - mae: nan\n",
            "Epoch 57/100\n",
            "90/90 [==============================] - 62s 691ms/step - loss: nan - mae: nan\n",
            "Epoch 58/100\n",
            "90/90 [==============================] - 62s 693ms/step - loss: nan - mae: nan\n",
            "Epoch 59/100\n",
            "90/90 [==============================] - 62s 687ms/step - loss: nan - mae: nan\n",
            "Epoch 60/100\n",
            "90/90 [==============================] - 62s 688ms/step - loss: nan - mae: nan\n",
            "Epoch 61/100\n",
            "90/90 [==============================] - 62s 688ms/step - loss: nan - mae: nan\n",
            "Epoch 62/100\n",
            "90/90 [==============================] - 62s 688ms/step - loss: nan - mae: nan\n",
            "Epoch 63/100\n",
            "90/90 [==============================] - 62s 688ms/step - loss: nan - mae: nan\n",
            "Epoch 64/100\n",
            "90/90 [==============================] - 62s 690ms/step - loss: nan - mae: nan\n",
            "Epoch 65/100\n",
            "31/90 [=========>....................] - ETA: 40s - loss: nan - mae: nan"
          ]
        }
      ],
      "source": [
        "load_trained_model_prel = False\n",
        "if (load_trained_model_prel == True):\n",
        "    lstm_model_prel = load_model(prel_model_save_path)\n",
        "else:\n",
        "  if (embedding == 'full_emb'):\n",
        "    lstm_model_prel = get_model(Hidden_dim1=1540, Hidden_dim2=512, return_sequences = True, dropout_dense=0.5, dropout_lstm=0.4, \n",
        "                             recurrent_dropout=0.4, sen_size=max_words_for_full_emb, input_size=768, activation='sigmoid', \n",
        "                             opt_engine='adam', loss_fn='mse')\n",
        "  else:\n",
        "    lstm_model_prel = get_model(Hidden_dim1=1028, Hidden_dim2=512, return_sequences = True, dropout_dense=0.5, dropout_lstm=0.4, \n",
        "                             recurrent_dropout=0.4, sen_size=max_sentences, input_size=768, activation='sigmoid', \n",
        "                             opt_engine='adam', loss_fn='mse')\n",
        "  lstm_model_prel.fit(lhs_train_prel.numpy(), y_train_prel, batch_size=96, epochs=100)\n",
        "  lstm_model_prel.save(prel_model_save_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VcvmB411fSyk"
      },
      "source": [
        "## Experiment 1 (b): Sentence-wise embedding using sum of last 4 hidden states"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uOe9BDpgnKy"
      },
      "source": [
        "### Semantic Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhwAXyIbgwMO"
      },
      "source": [
        "#### Creating embedding for training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dwj5xvVAu_VM",
        "outputId": "917dfe0b-26cb-4b26-c06a-37f669009ef8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Preparing Embeddings...\n",
            "Model Type:  semantic\n",
            "Embedding Type:  sen_avg\n",
            "hState:  last4sum\n",
            "Save File Directory:  /content/drive/MyDrive/Colab Notebooks/AES/experiment_XX\n",
            "Dataframe provided, Size:  (6488, 6)\n",
            "Loading existing embeddings from file...\n",
            "LHS File chosen:  /content/drive/MyDrive/Colab Notebooks/AES/experiment_XX/lhs_train.pt\n",
            "Y File chosen:  /content/drive/MyDrive/Colab Notebooks/AES/experiment_XX/y_train.pt\n",
            "Loaded, Size of LHS embeddings:  torch.Size([6488, 128, 768])\n",
            "Loaded, Size of y Gold:  (6488,)\n",
            "Returning lhs: Shape:  torch.Size([6488, 128, 768])\n",
            "Returning y_gold: Shape:  (6488,)\n"
          ]
        }
      ],
      "source": [
        "lhs_train, y_train = prepare_embeddings_updated (tpd_train, model_type='semantic', train_or_test='train', load_from_file=load_bert_sem, embedding_type=embedding, max_words=max_words_for_full_emb_sem, file_path=model_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZ7I3wBRicOl"
      },
      "source": [
        "#### Creating embedding for test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3UO-BHj-hE_",
        "outputId": "8304c01f-d826-45c2-9f2d-3981c5867e51"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Preparing Embeddings...\n",
            "Model Type:  semantic\n",
            "Embedding Type:  sen_avg\n",
            "hState:  last4sum\n",
            "Save File Directory:  /content/drive/MyDrive/Colab Notebooks/AES/experiment_XX\n",
            "Dataframe provided, Size:  (2596, 6)\n",
            "Loading existing embeddings from file...\n",
            "LHS File chosen:  /content/drive/MyDrive/Colab Notebooks/AES/experiment_XX/lhs_test.pt\n",
            "Y File chosen:  /content/drive/MyDrive/Colab Notebooks/AES/experiment_XX/y_test.pt\n",
            "Loaded, Size of LHS embeddings:  torch.Size([2596, 128, 768])\n",
            "Loaded, Size of y Gold:  (2596,)\n",
            "Returning lhs: Shape:  torch.Size([2596, 128, 768])\n",
            "Returning y_gold: Shape:  (2596,)\n"
          ]
        }
      ],
      "source": [
        "lhs_test, y_test = prepare_embeddings_updated (tpd_test, model_type='semantic', train_or_test='test', load_from_file=load_bert_sem, embedding_type=embedding, max_words=max_words_for_full_emb_sem, file_path = model_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EfWPhdPskljK"
      },
      "source": [
        "#### Training/loading the semantic LSTM model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U90uxWO0ktsh",
        "outputId": "cf2b543d-3a14-4d7f-f639-f8c6de50c637"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        }
      ],
      "source": [
        "load_trained_model_sem = True\n",
        "if (load_trained_model_sem == True):\n",
        "    lstm_model_sem = load_model(sem_model_save_path)\n",
        "else:\n",
        "  if (embedding == 'full_emb'):\n",
        "    lstm_model_sem = get_model(Hidden_dim1=1028, Hidden_dim2=512, return_sequences = True, dropout_dense=0.5, dropout_lstm=0.4, \n",
        "                             recurrent_dropout=0.4, sen_size=max_words_for_full_emb_sem, input_size=768, activation='sigmoid', \n",
        "                             opt_engine='adam', loss_fn='mse')\n",
        "  else:\n",
        "    lstm_model_sem = get_model(Hidden_dim1=1028, Hidden_dim2=512, return_sequences = True, dropout_dense=0.5, dropout_lstm=0.4, \n",
        "                             recurrent_dropout=0.4, sen_size=max_sentences, input_size=768, activation='sigmoid', \n",
        "                             opt_engine='adam', loss_fn='mse')\n",
        "  lstm_model_sem.fit(lhs_train.numpy(), y_train, batch_size=64, epochs=100)\n",
        "  lstm_model_sem.save(sem_model_save_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtE0SCXzwr0n"
      },
      "source": [
        "#### Evaluating the semantic model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "blLv60Tjwqcy",
        "outputId": "6e439c18-0701-434a-870f-e826fcd6928c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Kappa Score: 0.746204577711272\n",
            "MSE:  0.02282681984321185\n",
            "RMSE:  0.15108547197931324\n"
          ]
        }
      ],
      "source": [
        "evaluate_model (lstm_model_sem, lhs_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3cKL8_6u51y"
      },
      "source": [
        "### Coherence Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7mx2WlOu510"
      },
      "source": [
        "#### Creating augmented dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FE7aZy1ru511",
        "outputId": "56bc3836-0e18-4e61-d45f-ee407cb705a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original Train Data Shape (6488, 6)\n",
            "Original Test Data Shape (2596, 6)\n",
            "Augmented Train Data Shape (8434, 4)\n",
            "Augmented Test Data Shape (3375, 4)\n"
          ]
        }
      ],
      "source": [
        "aug_data_train = pd.DataFrame(columns=['essay_id', 'essay_set', 'essay', 'normalized_score'])\n",
        "aug_data_test = pd.DataFrame(columns=['essay_id', 'essay_set', 'essay', 'normalized_score'])\n",
        "\n",
        "print (\"Original Train Data Shape\", tpd_train.shape)\n",
        "print (\"Original Test Data Shape\", tpd_test.shape)\n",
        "\n",
        "aug_data_train['essay'] = tpd_train['essay'].apply(lambda x: coherence_augment(x))\n",
        "aug_data_train['essay_id'] = tpd_train['essay_id'].apply(lambda x: (x))\n",
        "aug_data_train['essay_set'] = tpd_train['essay_set'].apply(lambda x: (x))\n",
        "#aug_data_train['normalized_score'] = 0.0\n",
        "aug_data_train['normalized_score']=tpd_train['normalized_score'].apply(lambda x: (x/8))\n",
        "aug_data_train = aug_data_train.sample(frac=0.3)\n",
        "\n",
        "aug_data_test['essay'] = tpd_test['essay'].apply(lambda x: coherence_augment(x))\n",
        "aug_data_test['essay_id'] = tpd_test['essay_id'].apply(lambda x: (x))\n",
        "aug_data_test['essay_set'] = tpd_test['essay_set'].apply(lambda x: (x))\n",
        "#aug_data_test['normalized_score'] = 0.0\n",
        "aug_data_test['normalized_score']=tpd_test['normalized_score'].apply(lambda x: (x/8))\n",
        "aug_data_test = aug_data_test.sample(frac=0.3)\n",
        "\n",
        "tpd_train_thin = tpd_train.drop(columns=['Unnamed: 0','domain1_score'])\n",
        "tpd_test_thin = tpd_test.drop(columns=['Unnamed: 0','domain1_score'])\n",
        "\n",
        "aug_data_train = aug_data_train.append(tpd_train_thin)\n",
        "aug_data_test = aug_data_test.append(tpd_test_thin)\n",
        "aug_data_train = aug_data_train.sample(frac = 1)\n",
        "aug_data_test = aug_data_test.sample(frac = 1)\n",
        "\n",
        "print (\"Augmented Train Data Shape\", aug_data_train.shape)\n",
        "print (\"Augmented Test Data Shape\", aug_data_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-MwLdJ1u511"
      },
      "source": [
        "#### Creating embeddings for training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQmNP8JBxq0f",
        "outputId": "85e90be2-4bf9-4cb0-dbff-d24a013db120"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Preparing Embeddings...\n",
            "Model Type:  coherence\n",
            "Embedding Type:  sen_avg\n",
            "hState:  last4sum\n",
            "Save File Directory:  /content/drive/MyDrive/Colab Notebooks/AES/experiment_XX\n",
            "Dataframe provided, Size:  (8434, 4)\n",
            "Loading existing embeddings from file...\n",
            "LHS File chosen:  /content/drive/MyDrive/Colab Notebooks/AES/experiment_XX/lhs_coherence_train.pt\n",
            "Y File chosen:  /content/drive/MyDrive/Colab Notebooks/AES/experiment_XX/y_train_coh.pt\n",
            "Loaded, Size of LHS embeddings:  torch.Size([8434, 128, 768])\n",
            "Loaded, Size of y Gold:  (8434,)\n",
            "Returning lhs: Shape:  torch.Size([8434, 128, 768])\n",
            "Returning y_gold: Shape:  (8434,)\n"
          ]
        }
      ],
      "source": [
        "lhs_train_coh, y_train_coh = prepare_embeddings_updated (aug_data_train, model_type='coherence', train_or_test='train', load_from_file=load_bert_coh, embedding_type=embedding, max_words=max_words_for_full_emb, file_path=model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "16yT1Z5ULoHB",
        "outputId": "bd19d78c-670a-4e41-bcd9-88c35dbc70a4"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/Colab Notebooks/AES/full_embeddings'"
            ]
          },
          "execution_count": 37,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLZjkD-Eu512"
      },
      "source": [
        "#### Creating embedding for test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_SRci49SxsLR",
        "outputId": "54a33601-607c-47ef-bb98-92ad53591f87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Preparing Embeddings...\n",
            "Model Type:  coherence\n",
            "Embedding Type:  sen_avg\n",
            "hState:  last4sum\n",
            "Save File Directory:  /content/drive/MyDrive/Colab Notebooks/AES/experiment_XX\n",
            "Dataframe provided, Size:  (3375, 4)\n",
            "Loading existing embeddings from file...\n",
            "LHS File chosen:  /content/drive/MyDrive/Colab Notebooks/AES/experiment_XX/lhs_coherence_test.pt\n",
            "Y File chosen:  /content/drive/MyDrive/Colab Notebooks/AES/experiment_XX/y_test_coh.pt\n",
            "Loaded, Size of LHS embeddings:  torch.Size([3375, 128, 768])\n",
            "Loaded, Size of y Gold:  (3375,)\n",
            "Returning lhs: Shape:  torch.Size([3375, 128, 768])\n",
            "Returning y_gold: Shape:  (3375,)\n"
          ]
        }
      ],
      "source": [
        "lhs_test_coh, y_test_coh = prepare_embeddings_updated (aug_data_test, model_type='coherence', train_or_test='test', load_from_file=load_bert_coh, embedding_type=embedding, max_words=200)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-E5y5axx1Mj"
      },
      "source": [
        "#### Load LSTM Model for Coherence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LP_tb-RBu513",
        "outputId": "606183aa-2f81-42fd-f68a-a6758bee42f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        }
      ],
      "source": [
        "if (load_trained_model_coh == True):\n",
        "    lstm_model_coh = load_model(coh_model_save_path)\n",
        "else:\n",
        "  if (embedding == 'full_emb'):\n",
        "    lstm_model_coh = get_model(Hidden_dim1=1028, Hidden_dim2=512, return_sequences = True, dropout_dense=0.5, dropout_lstm=0.4, \n",
        "                             recurrent_dropout=0.4, sen_size=max_words_for_full_emb, input_size=768, activation='sigmoid', \n",
        "                             opt_engine='adam', loss_fn='mse')\n",
        "  else:\n",
        "    lstm_model_coh = get_model(Hidden_dim1=1028, Hidden_dim2=512, return_sequences = True, dropout_dense=0.5, dropout_lstm=0.4, \n",
        "                             recurrent_dropout=0.4, sen_size=max_sentences, input_size=768, activation='sigmoid', \n",
        "                             opt_engine='adam', loss_fn='mse')\n",
        "  lstm_model_coh.fit(lhs_train_coh.numpy(), y_train_coh, batch_size=64, epochs=100)\n",
        "  lstm_model_coh.save(coh_model_save_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Y6xdCeXu513"
      },
      "source": [
        "#### Evaluating the coherence model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSkwkF7cu514",
        "outputId": "83ffd764-72db-472d-c5bb-6de9b7dfdda7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Kappa Score: 0.7488510161504939\n",
            "MSE:  0.03650495161279134\n",
            "RMSE:  0.19106269026890452\n"
          ]
        }
      ],
      "source": [
        "evaluate_model (lstm_model_coh, lhs_test_coh, y_test_coh)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "HDzjewh0zpdF",
        "outputId": "8d25302b-b3a0-4f71-c14c-03151f44e181"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/Colab Notebooks/AES/experiment_XX/coh-lstm_model-latest.pt'"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "coh_model_save_path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xCTUD8Jf13Z"
      },
      "source": [
        "### Prompt relevance Model (Baseline)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2_OI89NpwQK"
      },
      "source": [
        "#### Prepare prompts data & combined essay with prompt pre-pended"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DiXaLVpKAZZ3"
      },
      "outputs": [],
      "source": [
        "prompts = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/AES/prompts-aes-kaggle-dataset.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fN0KqrKIAZZ7"
      },
      "outputs": [],
      "source": [
        "prompts.columns = ['essay_set','prompt']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "-5owTzr9AZZ7",
        "outputId": "95a9ede0-7e14-4a5b-c35e-f4f33a28d229"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-5ee800eb-9de5-4249-a50f-951657b8ab27\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>essay_set</th>\n",
              "      <th>prompt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>More and more people use computers, but not ev...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>\"All of us can think of a book that we hope no...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>The author, on an ambitious cycling trip to Yo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>The author is a second-generation Cuban migran...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>In their ambition to outshine the other, the a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>Write about patience. Being patient means that...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>We all understand the benefits of laughter. Fo...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5ee800eb-9de5-4249-a50f-951657b8ab27')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5ee800eb-9de5-4249-a50f-951657b8ab27 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5ee800eb-9de5-4249-a50f-951657b8ab27');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   essay_set                                             prompt\n",
              "0          1  More and more people use computers, but not ev...\n",
              "1          2  \"All of us can think of a book that we hope no...\n",
              "2          3  The author, on an ambitious cycling trip to Yo...\n",
              "3          4  Saeng is a teenaged Vietnamese migrant in the ...\n",
              "4          5  The author is a second-generation Cuban migran...\n",
              "5          6  In their ambition to outshine the other, the a...\n",
              "6          7  Write about patience. Being patient means that...\n",
              "7          8  We all understand the benefits of laughter. Fo..."
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KqBn-hxfAZZ9"
      },
      "outputs": [],
      "source": [
        "#data_train_set = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/AES/experiment_3_part_datasettraining_set_33pc_sample.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UdluSantewk5"
      },
      "outputs": [],
      "source": [
        "#data_train_set = data_train_set.drop(columns = ['Unnamed: 0'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0TVRKtthAZZ-"
      },
      "outputs": [],
      "source": [
        "prompt_data_train = tpd_train.merge(prompts,on='essay_set')\n",
        "prompt_data_test = tpd_test.merge(prompts,on='essay_set')\n",
        "prompt_data_xgb = tpd_xgb.merge(prompts,on='essay_set')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "v3J-_N8Xzxmq",
        "outputId": "a062cc46-8d5b-40d6-d656-cb55c41e8eb7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-eb2bafdb-334e-4c10-8dd1-b0a90126c697\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>essay_id</th>\n",
              "      <th>essay_set</th>\n",
              "      <th>essay</th>\n",
              "      <th>domain1_score</th>\n",
              "      <th>normalized_score</th>\n",
              "      <th>prompt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6351</td>\n",
              "      <td>9908</td>\n",
              "      <td>4</td>\n",
              "      <td>The author concludes the story w/this paragrap...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6315</td>\n",
              "      <td>9872</td>\n",
              "      <td>4</td>\n",
              "      <td>I believe that the author concludes the story ...</td>\n",
              "      <td>2</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5885</td>\n",
              "      <td>9441</td>\n",
              "      <td>4</td>\n",
              "      <td>The author of the Winter Hibiscus concludes th...</td>\n",
              "      <td>3</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5556</td>\n",
              "      <td>9110</td>\n",
              "      <td>4</td>\n",
              "      <td>From the story, Winter Hibiscus, by Minfong ...</td>\n",
              "      <td>2</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6977</td>\n",
              "      <td>10540</td>\n",
              "      <td>4</td>\n",
              "      <td>I believe that the author chose to conclude th...</td>\n",
              "      <td>2</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eb2bafdb-334e-4c10-8dd1-b0a90126c697')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-eb2bafdb-334e-4c10-8dd1-b0a90126c697 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-eb2bafdb-334e-4c10-8dd1-b0a90126c697');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Unnamed: 0  ...                                             prompt\n",
              "0        6351  ...  Saeng is a teenaged Vietnamese migrant in the ...\n",
              "1        6315  ...  Saeng is a teenaged Vietnamese migrant in the ...\n",
              "2        5885  ...  Saeng is a teenaged Vietnamese migrant in the ...\n",
              "3        5556  ...  Saeng is a teenaged Vietnamese migrant in the ...\n",
              "4        6977  ...  Saeng is a teenaged Vietnamese migrant in the ...\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt_data_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "y1OB1E5Kz40l",
        "outputId": "a9693661-58fe-41ba-f7d3-b9cb98703bbd"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-e93e429c-95be-44c5-b2af-e94dd8420b6d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>essay_id</th>\n",
              "      <th>essay_set</th>\n",
              "      <th>essay</th>\n",
              "      <th>domain1_score</th>\n",
              "      <th>normalized_score</th>\n",
              "      <th>prompt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5510</td>\n",
              "      <td>9064</td>\n",
              "      <td>4</td>\n",
              "      <td>The reason why at the end of the story she end...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5330</td>\n",
              "      <td>8884</td>\n",
              "      <td>4</td>\n",
              "      <td>They probably ended it like that to build susp...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6230</td>\n",
              "      <td>9787</td>\n",
              "      <td>4</td>\n",
              "      <td>The author coNcludes the story with this parag...</td>\n",
              "      <td>2</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6272</td>\n",
              "      <td>9829</td>\n",
              "      <td>4</td>\n",
              "      <td>The author concludes the story Winter Hibiscu...</td>\n",
              "      <td>3</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6164</td>\n",
              "      <td>9721</td>\n",
              "      <td>4</td>\n",
              "      <td>He concludes this story like that so you dont ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e93e429c-95be-44c5-b2af-e94dd8420b6d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e93e429c-95be-44c5-b2af-e94dd8420b6d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e93e429c-95be-44c5-b2af-e94dd8420b6d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Unnamed: 0  ...                                             prompt\n",
              "0        5510  ...  Saeng is a teenaged Vietnamese migrant in the ...\n",
              "1        5330  ...  Saeng is a teenaged Vietnamese migrant in the ...\n",
              "2        6230  ...  Saeng is a teenaged Vietnamese migrant in the ...\n",
              "3        6272  ...  Saeng is a teenaged Vietnamese migrant in the ...\n",
              "4        6164  ...  Saeng is a teenaged Vietnamese migrant in the ...\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt_data_test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "R8jnbtiyAm_M",
        "outputId": "5b9fa242-759c-435d-ff4e-b44c8aa0246f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-2c60f695-ff2a-4ca0-964c-06932162628c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>essay_id</th>\n",
              "      <th>essay_set</th>\n",
              "      <th>essay</th>\n",
              "      <th>domain1_score</th>\n",
              "      <th>normalized_score</th>\n",
              "      <th>prompt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5736</td>\n",
              "      <td>9291</td>\n",
              "      <td>4</td>\n",
              "      <td>In the story Winter Hibiscus by Minfong Ho, ...</td>\n",
              "      <td>2</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6843</td>\n",
              "      <td>10402</td>\n",
              "      <td>4</td>\n",
              "      <td>I think the author ended the story with that p...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6449</td>\n",
              "      <td>10006</td>\n",
              "      <td>4</td>\n",
              "      <td>The author chose to end the story with this pa...</td>\n",
              "      <td>2</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6434</td>\n",
              "      <td>9991</td>\n",
              "      <td>4</td>\n",
              "      <td>This sentence concludes the passage, to show h...</td>\n",
              "      <td>3</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6569</td>\n",
              "      <td>10126</td>\n",
              "      <td>4</td>\n",
              "      <td>The author concludes the Story with this parag...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3887</th>\n",
              "      <td>12586</td>\n",
              "      <td>21132</td>\n",
              "      <td>8</td>\n",
              "      <td>Laughter is what connects me my friends. It's...</td>\n",
              "      <td>40</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>We all understand the benefits of laughter. Fo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3888</th>\n",
              "      <td>12411</td>\n",
              "      <td>20915</td>\n",
              "      <td>8</td>\n",
              "      <td>was , hot and dry hadn't seen any for a few m...</td>\n",
              "      <td>40</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>We all understand the benefits of laughter. Fo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3889</th>\n",
              "      <td>12826</td>\n",
              "      <td>21437</td>\n",
              "      <td>8</td>\n",
              "      <td>Laughter is the most important part when you ...</td>\n",
              "      <td>34</td>\n",
              "      <td>0.566667</td>\n",
              "      <td>We all understand the benefits of laughter. Fo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3890</th>\n",
              "      <td>12557</td>\n",
              "      <td>21095</td>\n",
              "      <td>8</td>\n",
              "      <td>Laughter can not only be a benefit to ourselv...</td>\n",
              "      <td>35</td>\n",
              "      <td>0.583333</td>\n",
              "      <td>We all understand the benefits of laughter. Fo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3891</th>\n",
              "      <td>12613</td>\n",
              "      <td>21161</td>\n",
              "      <td>8</td>\n",
              "      <td>It was a day like any other. I was going to c...</td>\n",
              "      <td>40</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>We all understand the benefits of laughter. Fo...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3892 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2c60f695-ff2a-4ca0-964c-06932162628c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2c60f695-ff2a-4ca0-964c-06932162628c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2c60f695-ff2a-4ca0-964c-06932162628c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      Unnamed: 0  ...                                             prompt\n",
              "0           5736  ...  Saeng is a teenaged Vietnamese migrant in the ...\n",
              "1           6843  ...  Saeng is a teenaged Vietnamese migrant in the ...\n",
              "2           6449  ...  Saeng is a teenaged Vietnamese migrant in the ...\n",
              "3           6434  ...  Saeng is a teenaged Vietnamese migrant in the ...\n",
              "4           6569  ...  Saeng is a teenaged Vietnamese migrant in the ...\n",
              "...          ...  ...                                                ...\n",
              "3887       12586  ...  We all understand the benefits of laughter. Fo...\n",
              "3888       12411  ...  We all understand the benefits of laughter. Fo...\n",
              "3889       12826  ...  We all understand the benefits of laughter. Fo...\n",
              "3890       12557  ...  We all understand the benefits of laughter. Fo...\n",
              "3891       12613  ...  We all understand the benefits of laughter. Fo...\n",
              "\n",
              "[3892 rows x 7 columns]"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt_data_xgb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iWkst6HLAZZ-"
      },
      "outputs": [],
      "source": [
        "prompt_data_train['combined_essay'] = prompt_data_train['prompt'] + prompt_data_train['essay']\n",
        "prompt_data_test['combined_essay'] = prompt_data_test['prompt'] + prompt_data_test['essay']\n",
        "prompt_data_xgb['combined_essay'] = prompt_data_xgb['prompt'] + prompt_data_xgb['essay']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "id": "uWG0MPZ_BOJt",
        "outputId": "2c675b35-c5b6-4bfd-f232-27d6e2fd1249"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-3e298fb5-034b-4122-8a85-223878fbd94c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>essay_id</th>\n",
              "      <th>essay_set</th>\n",
              "      <th>essay</th>\n",
              "      <th>domain1_score</th>\n",
              "      <th>normalized_score</th>\n",
              "      <th>prompt</th>\n",
              "      <th>combined_essay</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5736</td>\n",
              "      <td>9291</td>\n",
              "      <td>4</td>\n",
              "      <td>In the story Winter Hibiscus by Minfong Ho, ...</td>\n",
              "      <td>2</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6843</td>\n",
              "      <td>10402</td>\n",
              "      <td>4</td>\n",
              "      <td>I think the author ended the story with that p...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6449</td>\n",
              "      <td>10006</td>\n",
              "      <td>4</td>\n",
              "      <td>The author chose to end the story with this pa...</td>\n",
              "      <td>2</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6434</td>\n",
              "      <td>9991</td>\n",
              "      <td>4</td>\n",
              "      <td>This sentence concludes the passage, to show h...</td>\n",
              "      <td>3</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6569</td>\n",
              "      <td>10126</td>\n",
              "      <td>4</td>\n",
              "      <td>The author concludes the Story with this parag...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3e298fb5-034b-4122-8a85-223878fbd94c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3e298fb5-034b-4122-8a85-223878fbd94c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3e298fb5-034b-4122-8a85-223878fbd94c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Unnamed: 0  ...                                     combined_essay\n",
              "0        5736  ...  Saeng is a teenaged Vietnamese migrant in the ...\n",
              "1        6843  ...  Saeng is a teenaged Vietnamese migrant in the ...\n",
              "2        6449  ...  Saeng is a teenaged Vietnamese migrant in the ...\n",
              "3        6434  ...  Saeng is a teenaged Vietnamese migrant in the ...\n",
              "4        6569  ...  Saeng is a teenaged Vietnamese migrant in the ...\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt_data_xgb.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "id": "7CEWJ-DMAZZ_",
        "outputId": "ee2747dc-8c47-42b3-ad5c-a0a61b7a36d7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-f6594bff-30c2-4e02-b1e8-0ee7f52c8e63\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>essay_id</th>\n",
              "      <th>essay_set</th>\n",
              "      <th>essay</th>\n",
              "      <th>domain1_score</th>\n",
              "      <th>normalized_score</th>\n",
              "      <th>prompt</th>\n",
              "      <th>combined_essay</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6351</td>\n",
              "      <td>9908</td>\n",
              "      <td>4</td>\n",
              "      <td>The author concludes the story w/this paragrap...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6315</td>\n",
              "      <td>9872</td>\n",
              "      <td>4</td>\n",
              "      <td>I believe that the author concludes the story ...</td>\n",
              "      <td>2</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5885</td>\n",
              "      <td>9441</td>\n",
              "      <td>4</td>\n",
              "      <td>The author of the Winter Hibiscus concludes th...</td>\n",
              "      <td>3</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5556</td>\n",
              "      <td>9110</td>\n",
              "      <td>4</td>\n",
              "      <td>From the story, Winter Hibiscus, by Minfong ...</td>\n",
              "      <td>2</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6977</td>\n",
              "      <td>10540</td>\n",
              "      <td>4</td>\n",
              "      <td>I believe that the author chose to conclude th...</td>\n",
              "      <td>2</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f6594bff-30c2-4e02-b1e8-0ee7f52c8e63')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f6594bff-30c2-4e02-b1e8-0ee7f52c8e63 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f6594bff-30c2-4e02-b1e8-0ee7f52c8e63');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Unnamed: 0  ...                                     combined_essay\n",
              "0        6351  ...  Saeng is a teenaged Vietnamese migrant in the ...\n",
              "1        6315  ...  Saeng is a teenaged Vietnamese migrant in the ...\n",
              "2        5885  ...  Saeng is a teenaged Vietnamese migrant in the ...\n",
              "3        5556  ...  Saeng is a teenaged Vietnamese migrant in the ...\n",
              "4        6977  ...  Saeng is a teenaged Vietnamese migrant in the ...\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt_data_train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpgfaYZXqBIk"
      },
      "source": [
        "#### Prepare Augmented Data for building & testing prompt relevance model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wmb-BvamI05G"
      },
      "outputs": [],
      "source": [
        "temp_df_train = pd.DataFrame(columns=[\"essay\",\"prompt\",\"j_prompt\",\"essay_set\", \"essay_id\",\"combined_essay\",\"normalized_score\"])\n",
        "temp_df_test = pd.DataFrame(columns=[\"essay\",\"prompt\",\"j_prompt\",\"essay_set\", \"essay_id\",\"combined_essay\",\"normalized_score\"])\n",
        "temp_df_xgb = pd.DataFrame(columns=[\"essay\",\"prompt\",\"j_prompt\",\"essay_set\", \"essay_id\",\"combined_essay\",\"normalized_score\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WquRCnqdLbN2",
        "outputId": "597e5487-ac3a-4c62-ce9e-d5c0aca22562"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Size of additional aumented TRAIN data:  (1622, 4)\n",
            "Size of additional aumented TRAIN data:  (649, 4)\n"
          ]
        }
      ],
      "source": [
        "temp_df_train['essay'] = prompt_data_train[\"essay\"].apply(lambda x: (x))\n",
        "temp_df_train['essay_id'] = prompt_data_train['essay_id'].apply(lambda x: (x))\n",
        "temp_df_train['essay_set'] = prompt_data_train['essay_set'].apply(lambda x: (x))\n",
        "temp_df_train['normalized_score'] = prompt_data_train['normalized_score'].apply(lambda x: (x))\n",
        "temp_df_train['prompt'] = prompt_data_train['prompt'].apply(lambda x: (x))\n",
        "temp_df_train['j_prompt'] = np.random.choice(prompts.prompt, size=len(temp_df_train))\n",
        "temp_df_train.loc[temp_df_train.prompt != temp_df_train.j_prompt, 'normalized_score'] = 0\n",
        "temp_df_train['combined_essay'] = temp_df_train['j_prompt'] + temp_df_train['essay']\n",
        "temp_df_train = temp_df_train.drop(columns=[\"essay\", \"prompt\", \"j_prompt\"])\n",
        "prompt_data_train_thin = prompt_data_train.drop(columns=[\"Unnamed: 0\", \"essay\", \"domain1_score\", 'prompt'])\n",
        "temp_df_train = temp_df_train.sample(frac=0.25)\n",
        "print (\"Size of additional aumented TRAIN data: \", temp_df_train.shape)\n",
        "temp_df_train = temp_df_train.append(prompt_data_train_thin)\n",
        "temp_df_train = temp_df_train.sample(frac = 1)\n",
        "temp_df_train = temp_df_train.rename(columns={\"combined_essay\": \"essay\"})\n",
        "\n",
        "temp_df_test['essay'] = prompt_data_test[\"essay\"].apply(lambda x: (x))\n",
        "temp_df_test['essay_id'] = prompt_data_test['essay_id'].apply(lambda x: (x))\n",
        "temp_df_test['essay_set'] = prompt_data_test['essay_set'].apply(lambda x: (x))\n",
        "temp_df_test['normalized_score'] = prompt_data_test['normalized_score'].apply(lambda x: (x))\n",
        "temp_df_test['prompt'] = prompt_data_test['prompt'].apply(lambda x: (x))\n",
        "temp_df_test['j_prompt'] = np.random.choice(prompts.prompt, size=len(temp_df_test))\n",
        "temp_df_test.loc[temp_df_test.prompt != temp_df_test.j_prompt, 'normalized_score'] = 0\n",
        "temp_df_test['combined_essay'] = temp_df_test['j_prompt'] + temp_df_test['essay']\n",
        "temp_df_test = temp_df_test.drop(columns=[\"essay\", \"prompt\", \"j_prompt\"])\n",
        "prompt_data_test_thin = prompt_data_test.drop(columns=[\"Unnamed: 0\", \"essay\", \"domain1_score\", 'prompt'])\n",
        "temp_df_test = temp_df_test.sample(frac=0.25)\n",
        "print (\"Size of additional aumented TRAIN data: \", temp_df_test.shape)\n",
        "temp_df_test = temp_df_test.append(prompt_data_test_thin)\n",
        "temp_df_test = temp_df_test.sample(frac = 1)\n",
        "temp_df_test = temp_df_test.rename(columns={\"combined_essay\": \"essay\"})\n",
        "\n",
        "#temp_df_xgb['essay'] = prompt_data_xgb[\"essay\"].apply(lambda x: (x))\n",
        "#temp_df_xgb['essay_id'] = prompt_data_xgb['essay_id'].apply(lambda x: (x))\n",
        "#temp_df_xgb['essay_set'] = prompt_data_xgb['essay_set'].apply(lambda x: (x))\n",
        "#temp_df_xgb['normalized_score'] = prompt_data_xgb['normalized_score'].apply(lambda x: (x))\n",
        "#temp_df_xgb['prompt'] = prompt_data_xgb['prompt'].apply(lambda x: (x))\n",
        "#temp_df_xgb['j_prompt'] = np.random.choice(prompts.prompt, size=len(temp_df_xgb))\n",
        "#temp_df_xgb.loc[temp_df_xgb.prompt != temp_df_xgb.j_prompt, 'normalized_score'] = 0\n",
        "#temp_df_xgb['combined_essay'] = temp_df_xgb['j_prompt'] + temp_df_xgb['essay']\n",
        "#temp_df_xgb['combined_essay'] = temp_df_xgb['prompt'] + temp_df_xgb['essay']\n",
        "#temp_df_xgb = temp_df_xgb.drop(columns=[\"essay\", \"prompt\", \"j_prompt\"])\n",
        "#prompt_data_xgb_thin = prompt_data_xgb.drop(columns=[\"Unnamed: 0\", \"essay\", \"domain1_score\", 'prompt'])\n",
        "##temp_df_xgb = temp_df_xgb.sample(frac=0.25)\n",
        "#print (\"Size of additional aumented XGB TEST/TRAIN data: \", temp_df_xgb.shape)\n",
        "#temp_df_xgb = temp_df_xgb.append(prompt_data_xgb_thin)\n",
        "#temp_df_xgb = temp_df_xgb.sample(frac = 1)\n",
        "#temp_df_xgb = temp_df_xgb.rename(columns={\"combined_essay\": \"essay\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tC1oowHdrsac",
        "outputId": "98285d8d-63b3-4d18-dd60-3f69c9274acf"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-65e33979-87ce-4cf4-b85d-f239f274014e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>essay_id</th>\n",
              "      <th>essay_set</th>\n",
              "      <th>essay</th>\n",
              "      <th>domain1_score</th>\n",
              "      <th>normalized_score</th>\n",
              "      <th>prompt</th>\n",
              "      <th>combined_essay</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6351</td>\n",
              "      <td>9908</td>\n",
              "      <td>4</td>\n",
              "      <td>The author concludes the story w/this paragrap...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6315</td>\n",
              "      <td>9872</td>\n",
              "      <td>4</td>\n",
              "      <td>I believe that the author concludes the story ...</td>\n",
              "      <td>2</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5885</td>\n",
              "      <td>9441</td>\n",
              "      <td>4</td>\n",
              "      <td>The author of the Winter Hibiscus concludes th...</td>\n",
              "      <td>3</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5556</td>\n",
              "      <td>9110</td>\n",
              "      <td>4</td>\n",
              "      <td>From the story, Winter Hibiscus, by Minfong ...</td>\n",
              "      <td>2</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6977</td>\n",
              "      <td>10540</td>\n",
              "      <td>4</td>\n",
              "      <td>I believe that the author chose to conclude th...</td>\n",
              "      <td>2</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6483</th>\n",
              "      <td>11629</td>\n",
              "      <td>18884</td>\n",
              "      <td>7</td>\n",
              "      <td>Once upon a time there was a princess named wa...</td>\n",
              "      <td>20</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>Write about patience. Being patient means that...</td>\n",
              "      <td>Write about patience. Being patient means that...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6484</th>\n",
              "      <td>10939</td>\n",
              "      <td>18121</td>\n",
              "      <td>7</td>\n",
              "      <td>I am never paitent, but which I am it is only ...</td>\n",
              "      <td>14</td>\n",
              "      <td>0.466667</td>\n",
              "      <td>Write about patience. Being patient means that...</td>\n",
              "      <td>Write about patience. Being patient means that...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6485</th>\n",
              "      <td>11355</td>\n",
              "      <td>18591</td>\n",
              "      <td>7</td>\n",
              "      <td>Have you ever been patient? I have, especially...</td>\n",
              "      <td>24</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>Write about patience. Being patient means that...</td>\n",
              "      <td>Write about patience. Being patient means that...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6486</th>\n",
              "      <td>11541</td>\n",
              "      <td>18789</td>\n",
              "      <td>7</td>\n",
              "      <td>One day my brother, my mom and me were going t...</td>\n",
              "      <td>19</td>\n",
              "      <td>0.633333</td>\n",
              "      <td>Write about patience. Being patient means that...</td>\n",
              "      <td>Write about patience. Being patient means that...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6487</th>\n",
              "      <td>11891</td>\n",
              "      <td>19172</td>\n",
              "      <td>7</td>\n",
              "      <td>Having a melt ! I have expereanced this scene ...</td>\n",
              "      <td>16</td>\n",
              "      <td>0.533333</td>\n",
              "      <td>Write about patience. Being patient means that...</td>\n",
              "      <td>Write about patience. Being patient means that...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6488 rows × 8 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-65e33979-87ce-4cf4-b85d-f239f274014e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-65e33979-87ce-4cf4-b85d-f239f274014e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-65e33979-87ce-4cf4-b85d-f239f274014e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      Unnamed: 0  ...                                     combined_essay\n",
              "0           6351  ...  Saeng is a teenaged Vietnamese migrant in the ...\n",
              "1           6315  ...  Saeng is a teenaged Vietnamese migrant in the ...\n",
              "2           5885  ...  Saeng is a teenaged Vietnamese migrant in the ...\n",
              "3           5556  ...  Saeng is a teenaged Vietnamese migrant in the ...\n",
              "4           6977  ...  Saeng is a teenaged Vietnamese migrant in the ...\n",
              "...          ...  ...                                                ...\n",
              "6483       11629  ...  Write about patience. Being patient means that...\n",
              "6484       10939  ...  Write about patience. Being patient means that...\n",
              "6485       11355  ...  Write about patience. Being patient means that...\n",
              "6486       11541  ...  Write about patience. Being patient means that...\n",
              "6487       11891  ...  Write about patience. Being patient means that...\n",
              "\n",
              "[6488 rows x 8 columns]"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt_data_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wP2sGkemJAUP",
        "outputId": "2508344b-54d6-49fe-f9af-614e1ee5401f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-00487cc9-210f-4178-8f03-b7d9ae8a384b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>essay_id</th>\n",
              "      <th>essay_set</th>\n",
              "      <th>essay</th>\n",
              "      <th>domain1_score</th>\n",
              "      <th>normalized_score</th>\n",
              "      <th>prompt</th>\n",
              "      <th>combined_essay</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5510</td>\n",
              "      <td>9064</td>\n",
              "      <td>4</td>\n",
              "      <td>The reason why at the end of the story she end...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5330</td>\n",
              "      <td>8884</td>\n",
              "      <td>4</td>\n",
              "      <td>They probably ended it like that to build susp...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6230</td>\n",
              "      <td>9787</td>\n",
              "      <td>4</td>\n",
              "      <td>The author coNcludes the story with this parag...</td>\n",
              "      <td>2</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6272</td>\n",
              "      <td>9829</td>\n",
              "      <td>4</td>\n",
              "      <td>The author concludes the story Winter Hibiscu...</td>\n",
              "      <td>3</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6164</td>\n",
              "      <td>9721</td>\n",
              "      <td>4</td>\n",
              "      <td>He concludes this story like that so you dont ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2591</th>\n",
              "      <td>2747</td>\n",
              "      <td>3942</td>\n",
              "      <td>2</td>\n",
              "      <td>Things that mean so much to just one person to...</td>\n",
              "      <td>3</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>\"All of us can think of a book that we hope no...</td>\n",
              "      <td>\"All of us can think of a book that we hope no...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2592</th>\n",
              "      <td>2047</td>\n",
              "      <td>3242</td>\n",
              "      <td>2</td>\n",
              "      <td>Censorship is a big controversy in modern soci...</td>\n",
              "      <td>4</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>\"All of us can think of a book that we hope no...</td>\n",
              "      <td>\"All of us can think of a book that we hope no...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2593</th>\n",
              "      <td>2558</td>\n",
              "      <td>3753</td>\n",
              "      <td>2</td>\n",
              "      <td>In libraries there are a bunch of books, music...</td>\n",
              "      <td>3</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>\"All of us can think of a book that we hope no...</td>\n",
              "      <td>\"All of us can think of a book that we hope no...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2594</th>\n",
              "      <td>3385</td>\n",
              "      <td>4580</td>\n",
              "      <td>2</td>\n",
              "      <td>Yes, I do think so because everyone has an opi...</td>\n",
              "      <td>2</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>\"All of us can think of a book that we hope no...</td>\n",
              "      <td>\"All of us can think of a book that we hope no...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2595</th>\n",
              "      <td>2433</td>\n",
              "      <td>3628</td>\n",
              "      <td>2</td>\n",
              "      <td>Censorship in Libraries I believe that there s...</td>\n",
              "      <td>4</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>\"All of us can think of a book that we hope no...</td>\n",
              "      <td>\"All of us can think of a book that we hope no...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2596 rows × 8 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-00487cc9-210f-4178-8f03-b7d9ae8a384b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-00487cc9-210f-4178-8f03-b7d9ae8a384b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-00487cc9-210f-4178-8f03-b7d9ae8a384b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      Unnamed: 0  ...                                     combined_essay\n",
              "0           5510  ...  Saeng is a teenaged Vietnamese migrant in the ...\n",
              "1           5330  ...  Saeng is a teenaged Vietnamese migrant in the ...\n",
              "2           6230  ...  Saeng is a teenaged Vietnamese migrant in the ...\n",
              "3           6272  ...  Saeng is a teenaged Vietnamese migrant in the ...\n",
              "4           6164  ...  Saeng is a teenaged Vietnamese migrant in the ...\n",
              "...          ...  ...                                                ...\n",
              "2591        2747  ...  \"All of us can think of a book that we hope no...\n",
              "2592        2047  ...  \"All of us can think of a book that we hope no...\n",
              "2593        2558  ...  \"All of us can think of a book that we hope no...\n",
              "2594        3385  ...  \"All of us can think of a book that we hope no...\n",
              "2595        2433  ...  \"All of us can think of a book that we hope no...\n",
              "\n",
              "[2596 rows x 8 columns]"
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt_data_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "rT4QG73VI-RN",
        "outputId": "31ab5e08-71fa-4ca0-f69b-c47bf8e7e0cb"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-dfd148a4-0b76-44e5-9a3b-8d7aacf017e1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>essay_id</th>\n",
              "      <th>essay_set</th>\n",
              "      <th>normalized_score</th>\n",
              "      <th>essay</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9291</td>\n",
              "      <td>4</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10402</td>\n",
              "      <td>4</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10006</td>\n",
              "      <td>4</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9991</td>\n",
              "      <td>4</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10126</td>\n",
              "      <td>4</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dfd148a4-0b76-44e5-9a3b-8d7aacf017e1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dfd148a4-0b76-44e5-9a3b-8d7aacf017e1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dfd148a4-0b76-44e5-9a3b-8d7aacf017e1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   essay_id  ...                                              essay\n",
              "0      9291  ...  Saeng is a teenaged Vietnamese migrant in the ...\n",
              "1     10402  ...  Saeng is a teenaged Vietnamese migrant in the ...\n",
              "2     10006  ...  Saeng is a teenaged Vietnamese migrant in the ...\n",
              "3      9991  ...  Saeng is a teenaged Vietnamese migrant in the ...\n",
              "4     10126  ...  Saeng is a teenaged Vietnamese migrant in the ...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "new_validation_df_xgb = prompt_data_xgb.drop(columns=[\"Unnamed: 0\", \"domain1_score\",\"prompt\",\"essay\"])\n",
        "new_validation_df_xgb = new_validation_df_xgb.rename(columns={\"combined_essay\": \"essay\"})\n",
        "new_validation_df_xgb.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTUoYjLbI0K4",
        "outputId": "c7b481f0-714f-40c0-9b8b-efb8ae92594f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\"All of us can think of a book that we hope none of our children or any other children have taken off the shelf. But if I have the right to remove that book from the shelf -- that work I abhor -- then you also have exactly the same right and so does everyone else. And then we have no books left on the shelf for any of us.\" --Katherine Paterson, Author. Write a persuasive essay to a newspaper reflecting your vies on censorship in libraries. Do you believe that certain materials, such as books, music, movies, magazines, etc., should be removed from the shelves if they are found offensive? Support your position with convincing arguments from your own experience, observations, and/or reading.'"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompts[prompts['essay_set']==2].prompt.iloc[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AKRWCnWLxnX7"
      },
      "outputs": [],
      "source": [
        "prompt_data_train.to_csv(\"/content/drive/MyDrive/Colab Notebooks/AES/prel_data/prompt_data_train.csv\")\n",
        "prompt_data_test.to_csv(\"/content/drive/MyDrive/Colab Notebooks/AES/prel_data/prompt_data_test.csv\")\n",
        "new_validation_df_xgb.to_csv(\"/content/drive/MyDrive/Colab Notebooks/AES/prel_data/new_validation_df_xgb.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EoAJSoLJqfrC"
      },
      "source": [
        "#### Load or Create BERT Embeddings for Training Data for Prompt Relevance Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "kxiWPiSAgayJ",
        "outputId": "a387b51f-1ac4-4425-ca29-4b87a3a05df9"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'sen_avg'"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "id": "UXZj-Wn1pdOX",
        "outputId": "a35780e3-27d6-4942-c49c-3109b03fb314"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Preparing Embeddings...\n",
            "Model Type:  prel\n",
            "Embedding Type:  sen_avg\n",
            "hState:  last4sum\n",
            "Save File Directory:  /content/drive/MyDrive/Colab Notebooks/AES/experiment_XX\n",
            "Dataframe provided, Size:  (8110, 4)\n",
            "Loading existing embeddings from file...\n",
            "LHS File chosen:  /content/drive/MyDrive/Colab Notebooks/AES/experiment_XX/lhs_prel_train.pt\n",
            "Y File chosen:  /content/drive/MyDrive/Colab Notebooks/AES/experiment_XX/y_train_prel.pt\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-1e0e00ce7e51>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mload_bert_prel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlhs_train_prel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_prel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_embeddings_updated\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtemp_df_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'prel'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_or_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_from_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mload_bert_prel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_words_for_full_emb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-27-ade9c48fcb7e>\u001b[0m in \u001b[0;36mprepare_embeddings_updated\u001b[0;34m(df, model_type, train_or_test, load_from_file, file_path, embedding_type, max_sentences, max_words, hstate)\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"LHS File chosen: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlhs_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Y File chosen: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m     \u001b[0mlhs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlhs_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m     \u001b[0my_gold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Loaded, Size of LHS embeddings: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlhs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    605\u001b[0m                     \u001b[0mopened_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_position\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    608\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_legacy_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m    880\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnpicklerWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_loaded_sparse_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mpersistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m    855\u001b[0m         \u001b[0mdata_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloaded_storages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 857\u001b[0;31m             \u001b[0mload_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_maybe_decode_ascii\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    858\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloaded_storages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload_tensor\u001b[0;34m(data_type, size, key, location)\u001b[0m\n\u001b[1;32m    843\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 845\u001b[0;31m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_storage_from_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    846\u001b[0m         \u001b[0mloaded_storages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrestore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "load_bert_prel=False\n",
        "lhs_train_prel, y_train_prel = prepare_embeddings_updated (temp_df_train, model_type='prel', train_or_test='train', load_from_file=load_bert_prel, embedding_type=embedding, max_words=max_words_for_full_emb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OC8oQB46Smte"
      },
      "source": [
        "#### Load or Create BERT Embeddings for TEST set for Prompt Relevance Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKW1vv-EQYAK",
        "outputId": "8df53d1b-a102-4411-acf8-f3063b7322f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Preparing Embeddings...\n",
            "Model Type:  prel\n",
            "Train or Test:  test\n",
            "Dataframe provided, Size:  (3245, 4)\n",
            "Loading existing embeddings from file...\n",
            "LHS File chosen:  /content/drive/MyDrive/Colab Notebooks/AES/experiment_XX/lhs_prel_test.pt\n",
            "Y File chosen:  /content/drive/MyDrive/Colab Notebooks/AES/experiment_XX/y_test_prel.pt\n",
            "Loaded, Size of LHS embeddings:  torch.Size([3245, 128, 768])\n",
            "Loaded, Size of y Gold:  (3245,)\n",
            "Returning lhs: Shape:  torch.Size([3245, 128, 768])\n",
            "Returning y_gold: Shape:  (3245,)\n"
          ]
        }
      ],
      "source": [
        "load_bert_prel=True\n",
        "lhs_test_prel, y_test_prel = prepare_embeddings (temp_df_test, model_type='prel', train_or_test='test', load_from_file=load_bert_prel)\n",
        "#lhs_xgb_prel, y_xgb_prel = prepare_embeddings (new_validation_df_xgb, model_type='prel', train_or_test='test', load_from_file=load_bert_prel, file_path='/content/drive/MyDrive/Colab Notebooks/AES/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rX6iiq7kTWjA"
      },
      "source": [
        "### Build LSTM Model for Prompt Relevance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "XTn7joO3XES1",
        "outputId": "2c5d7b64-9c2d-4813-af42-98f5db7a77aa"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/Colab Notebooks/AES/experiment_XX/prel-lstm_model-latest.pt'"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prel_model_save_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15_0umJ6TJNl",
        "outputId": "7fa68968-a6a8-4139-bf71-ede593a8b4ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        }
      ],
      "source": [
        "load_trained_model_prel = True\n",
        "if (load_trained_model_prel == True):\n",
        "    lstm_model_prel = load_model(prel_model_save_path)\n",
        "else:\n",
        "  if (embedding == 'full_emb'):\n",
        "    lstm_model_prel = get_model(Hidden_dim1=1540, Hidden_dim2=512, return_sequences = True, dropout_dense=0.5, dropout_lstm=0.4, \n",
        "                             recurrent_dropout=0.4, sen_size=max_words_for_full_emb, input_size=768, activation='sigmoid', \n",
        "                             opt_engine='adam', loss_fn='mse')\n",
        "  else:\n",
        "    lstm_model_prel = get_model(Hidden_dim1=1028, Hidden_dim2=512, return_sequences = True, dropout_dense=0.5, dropout_lstm=0.4, \n",
        "                             recurrent_dropout=0.4, sen_size=max_sentences, input_size=768, activation='sigmoid', \n",
        "                             opt_engine='adam', loss_fn='mse')\n",
        "  lstm_model_prel.fit(lhs_train_prel.numpy(), y_train_prel, batch_size=96, epochs=100)\n",
        "  lstm_model_prel.save(prel_model_save_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A3UADPQLaEzF"
      },
      "outputs": [],
      "source": [
        "#lstm_model_prel.save(prel_model_save_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lyBJ_6a1T81w"
      },
      "source": [
        "### Validate the Prompt Relevance Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbx5GuaNTxnl",
        "outputId": "9268786b-7cc9-47f7-f20d-c91b365b6e6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Kappa Score: 0.8722539037517647\n",
            "MSE:  0.02049779149266475\n",
            "RMSE:  0.14317049798287618\n"
          ]
        }
      ],
      "source": [
        "evaluate_model (lstm_model_prel, lhs_test_prel, y_test_prel)\n",
        "#evaluate_model (lstm_model_prel, lhs_xgb_prel, y_xgb_prel)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5P6qpV90otoB"
      },
      "source": [
        "###XGBoost Regression Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "id": "jS7uPtDjo2hX",
        "outputId": "16160002-2816-449a-d66a-5774f4725f79"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>essay_id</th>\n",
              "      <th>essay_set</th>\n",
              "      <th>essay</th>\n",
              "      <th>domain1_score</th>\n",
              "      <th>normalized_score</th>\n",
              "      <th>prompt_x</th>\n",
              "      <th>prompt_y</th>\n",
              "      <th>prompt_x.1</th>\n",
              "      <th>prompt_y.1</th>\n",
              "      <th>prompt</th>\n",
              "      <th>spell_err</th>\n",
              "      <th>gram_err</th>\n",
              "      <th>oth_err</th>\n",
              "      <th>semantic_score</th>\n",
              "      <th>coherence_score</th>\n",
              "      <th>prel_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>5736</td>\n",
              "      <td>9291</td>\n",
              "      <td>4</td>\n",
              "      <td>In the story Winter Hibiscus by Minfong Ho, ...</td>\n",
              "      <td>2</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.803541</td>\n",
              "      <td>0.658268</td>\n",
              "      <td>0.637365</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>6843</td>\n",
              "      <td>10402</td>\n",
              "      <td>4</td>\n",
              "      <td>I think the author ended the story with that p...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.367756</td>\n",
              "      <td>0.304968</td>\n",
              "      <td>0.324565</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>6449</td>\n",
              "      <td>10006</td>\n",
              "      <td>4</td>\n",
              "      <td>The author chose to end the story with this pa...</td>\n",
              "      <td>2</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.560226</td>\n",
              "      <td>0.464632</td>\n",
              "      <td>0.572027</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>6434</td>\n",
              "      <td>9991</td>\n",
              "      <td>4</td>\n",
              "      <td>This sentence concludes the passage, to show h...</td>\n",
              "      <td>3</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.994009</td>\n",
              "      <td>0.726757</td>\n",
              "      <td>0.688145</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>6569</td>\n",
              "      <td>10126</td>\n",
              "      <td>4</td>\n",
              "      <td>The author concludes the Story with this parag...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "      <td>Saeng is a teenaged Vietnamese migrant in the ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.011546</td>\n",
              "      <td>0.112469</td>\n",
              "      <td>0.197627</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  Unnamed: 0.1  ...  coherence_score  prel_score\n",
              "0           0          5736  ...         0.658268    0.637365\n",
              "1           1          6843  ...         0.304968    0.324565\n",
              "2           2          6449  ...         0.464632    0.572027\n",
              "3           3          6434  ...         0.726757    0.688145\n",
              "4           4          6569  ...         0.112469    0.197627\n",
              "\n",
              "[5 rows x 18 columns]"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "compute_handcrafted_features = False\n",
        "prelEval = True\n",
        "if (compute_handcrafted_features == True):\n",
        "  tpd_xgb = tpd_xgb.merge(prompts, on=\"essay_set\") \n",
        "  data_with_handcrafted = augment_handcrafted_features(tpd_xgb, prelEval=prelEval)\n",
        "  data_with_handcrafted.to_csv(data_with_errors_path)\n",
        "else:\n",
        "  data_with_handcrafted = pd.read_csv(data_with_errors_path)\n",
        "data_with_handcrafted.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "lUGtiJFeBMRI"
      },
      "outputs": [],
      "source": [
        "training_df_xgb_fin = data_with_handcrafted.drop(columns=['Unnamed: 0', 'domain1_score', 'prompt','Unnamed: 0.1','prompt_x', 'prompt_y', 'prompt_x.1', 'prompt_y.1' ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "_e-WD3IIoYV2",
        "outputId": "c3369570-9875-4120-980d-6ed6f6ef9644"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>essay_id</th>\n",
              "      <th>essay_set</th>\n",
              "      <th>essay</th>\n",
              "      <th>normalized_score</th>\n",
              "      <th>spell_err</th>\n",
              "      <th>gram_err</th>\n",
              "      <th>oth_err</th>\n",
              "      <th>semantic_score</th>\n",
              "      <th>coherence_score</th>\n",
              "      <th>prel_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9291</td>\n",
              "      <td>4</td>\n",
              "      <td>In the story Winter Hibiscus by Minfong Ho, ...</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.803541</td>\n",
              "      <td>0.658268</td>\n",
              "      <td>0.637365</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10402</td>\n",
              "      <td>4</td>\n",
              "      <td>I think the author ended the story with that p...</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.367756</td>\n",
              "      <td>0.304968</td>\n",
              "      <td>0.324565</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10006</td>\n",
              "      <td>4</td>\n",
              "      <td>The author chose to end the story with this pa...</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.560226</td>\n",
              "      <td>0.464632</td>\n",
              "      <td>0.572027</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9991</td>\n",
              "      <td>4</td>\n",
              "      <td>This sentence concludes the passage, to show h...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.994009</td>\n",
              "      <td>0.726757</td>\n",
              "      <td>0.688145</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10126</td>\n",
              "      <td>4</td>\n",
              "      <td>The author concludes the Story with this parag...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.011546</td>\n",
              "      <td>0.112469</td>\n",
              "      <td>0.197627</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   essay_id  essay_set  ... coherence_score  prel_score\n",
              "0      9291          4  ...        0.658268    0.637365\n",
              "1     10402          4  ...        0.304968    0.324565\n",
              "2     10006          4  ...        0.464632    0.572027\n",
              "3      9991          4  ...        0.726757    0.688145\n",
              "4     10126          4  ...        0.112469    0.197627\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "training_df_xgb_fin.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "64paLkd3oX4j"
      },
      "outputs": [],
      "source": [
        "tmp_merge = training_df_xgb_fin.merge(average_essay_lens, left_on='essay_set', right_on='essay_set')\n",
        "# training_df_xgb_fin['length_deviation'] = "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "id": "X2u7kJ7biMNN",
        "outputId": "d2bd6cc8-3ce8-46da-daf2-e49e2423eec8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>essay_id</th>\n",
              "      <th>essay_set</th>\n",
              "      <th>essay</th>\n",
              "      <th>normalized_score</th>\n",
              "      <th>spell_err</th>\n",
              "      <th>gram_err</th>\n",
              "      <th>oth_err</th>\n",
              "      <th>semantic_score</th>\n",
              "      <th>coherence_score</th>\n",
              "      <th>prel_score</th>\n",
              "      <th>essay_len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9291</td>\n",
              "      <td>4</td>\n",
              "      <td>In the story Winter Hibiscus by Minfong Ho, ...</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.803541</td>\n",
              "      <td>0.658268</td>\n",
              "      <td>0.637365</td>\n",
              "      <td>91</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10402</td>\n",
              "      <td>4</td>\n",
              "      <td>I think the author ended the story with that p...</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.367756</td>\n",
              "      <td>0.304968</td>\n",
              "      <td>0.324565</td>\n",
              "      <td>91</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10006</td>\n",
              "      <td>4</td>\n",
              "      <td>The author chose to end the story with this pa...</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.560226</td>\n",
              "      <td>0.464632</td>\n",
              "      <td>0.572027</td>\n",
              "      <td>91</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9991</td>\n",
              "      <td>4</td>\n",
              "      <td>This sentence concludes the passage, to show h...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.994009</td>\n",
              "      <td>0.726757</td>\n",
              "      <td>0.688145</td>\n",
              "      <td>91</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10126</td>\n",
              "      <td>4</td>\n",
              "      <td>The author concludes the Story with this parag...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.011546</td>\n",
              "      <td>0.112469</td>\n",
              "      <td>0.197627</td>\n",
              "      <td>91</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3887</th>\n",
              "      <td>21132</td>\n",
              "      <td>8</td>\n",
              "      <td>Laughter is what connects me my friends. It's...</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>0.615803</td>\n",
              "      <td>0.602049</td>\n",
              "      <td>0.537702</td>\n",
              "      <td>571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3888</th>\n",
              "      <td>20915</td>\n",
              "      <td>8</td>\n",
              "      <td>was , hot and dry hadn't seen any for a few m...</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>46</td>\n",
              "      <td>0.740394</td>\n",
              "      <td>0.772299</td>\n",
              "      <td>0.609743</td>\n",
              "      <td>571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3889</th>\n",
              "      <td>21437</td>\n",
              "      <td>8</td>\n",
              "      <td>Laughter is the most important part when you ...</td>\n",
              "      <td>0.566667</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>0.563059</td>\n",
              "      <td>0.589851</td>\n",
              "      <td>0.551155</td>\n",
              "      <td>571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3890</th>\n",
              "      <td>21095</td>\n",
              "      <td>8</td>\n",
              "      <td>Laughter can not only be a benefit to ourselv...</td>\n",
              "      <td>0.583333</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>11</td>\n",
              "      <td>0.721744</td>\n",
              "      <td>0.672230</td>\n",
              "      <td>0.619011</td>\n",
              "      <td>571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3891</th>\n",
              "      <td>21161</td>\n",
              "      <td>8</td>\n",
              "      <td>It was a day like any other. I was going to c...</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>22</td>\n",
              "      <td>0.616700</td>\n",
              "      <td>0.731181</td>\n",
              "      <td>0.640652</td>\n",
              "      <td>571</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3892 rows × 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      essay_id  essay_set  ... prel_score  essay_len\n",
              "0         9291          4  ...   0.637365         91\n",
              "1        10402          4  ...   0.324565         91\n",
              "2        10006          4  ...   0.572027         91\n",
              "3         9991          4  ...   0.688145         91\n",
              "4        10126          4  ...   0.197627         91\n",
              "...        ...        ...  ...        ...        ...\n",
              "3887     21132          8  ...   0.537702        571\n",
              "3888     20915          8  ...   0.609743        571\n",
              "3889     21437          8  ...   0.551155        571\n",
              "3890     21095          8  ...   0.619011        571\n",
              "3891     21161          8  ...   0.640652        571\n",
              "\n",
              "[3892 rows x 11 columns]"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tmp_merge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0aw-h7Df8bOa"
      },
      "outputs": [],
      "source": [
        "tmp_merge['e_len'] = tmp_merge.essay.apply(lambda x: sum([i.strip(string.punctuation).isalpha() for i in x.split()]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "id": "J6Bo2Bmxiha9",
        "outputId": "046b1ca6-10b7-4237-a631-18b06d77e353"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>essay_id</th>\n",
              "      <th>essay_set</th>\n",
              "      <th>essay</th>\n",
              "      <th>normalized_score</th>\n",
              "      <th>spell_err</th>\n",
              "      <th>gram_err</th>\n",
              "      <th>oth_err</th>\n",
              "      <th>semantic_score</th>\n",
              "      <th>coherence_score</th>\n",
              "      <th>prel_score</th>\n",
              "      <th>essay_len</th>\n",
              "      <th>e_len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9291</td>\n",
              "      <td>4</td>\n",
              "      <td>In the story Winter Hibiscus by Minfong Ho, ...</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.803541</td>\n",
              "      <td>0.658268</td>\n",
              "      <td>0.637365</td>\n",
              "      <td>91</td>\n",
              "      <td>132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10402</td>\n",
              "      <td>4</td>\n",
              "      <td>I think the author ended the story with that p...</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.367756</td>\n",
              "      <td>0.304968</td>\n",
              "      <td>0.324565</td>\n",
              "      <td>91</td>\n",
              "      <td>79</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10006</td>\n",
              "      <td>4</td>\n",
              "      <td>The author chose to end the story with this pa...</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.560226</td>\n",
              "      <td>0.464632</td>\n",
              "      <td>0.572027</td>\n",
              "      <td>91</td>\n",
              "      <td>82</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9991</td>\n",
              "      <td>4</td>\n",
              "      <td>This sentence concludes the passage, to show h...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.994009</td>\n",
              "      <td>0.726757</td>\n",
              "      <td>0.688145</td>\n",
              "      <td>91</td>\n",
              "      <td>123</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10126</td>\n",
              "      <td>4</td>\n",
              "      <td>The author concludes the Story with this parag...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.011546</td>\n",
              "      <td>0.112469</td>\n",
              "      <td>0.197627</td>\n",
              "      <td>91</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3887</th>\n",
              "      <td>21132</td>\n",
              "      <td>8</td>\n",
              "      <td>Laughter is what connects me my friends. It's...</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>0.615803</td>\n",
              "      <td>0.602049</td>\n",
              "      <td>0.537702</td>\n",
              "      <td>571</td>\n",
              "      <td>293</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3888</th>\n",
              "      <td>20915</td>\n",
              "      <td>8</td>\n",
              "      <td>was , hot and dry hadn't seen any for a few m...</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>46</td>\n",
              "      <td>0.740394</td>\n",
              "      <td>0.772299</td>\n",
              "      <td>0.609743</td>\n",
              "      <td>571</td>\n",
              "      <td>731</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3889</th>\n",
              "      <td>21437</td>\n",
              "      <td>8</td>\n",
              "      <td>Laughter is the most important part when you ...</td>\n",
              "      <td>0.566667</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>0.563059</td>\n",
              "      <td>0.589851</td>\n",
              "      <td>0.551155</td>\n",
              "      <td>571</td>\n",
              "      <td>602</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3890</th>\n",
              "      <td>21095</td>\n",
              "      <td>8</td>\n",
              "      <td>Laughter can not only be a benefit to ourselv...</td>\n",
              "      <td>0.583333</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>11</td>\n",
              "      <td>0.721744</td>\n",
              "      <td>0.672230</td>\n",
              "      <td>0.619011</td>\n",
              "      <td>571</td>\n",
              "      <td>811</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3891</th>\n",
              "      <td>21161</td>\n",
              "      <td>8</td>\n",
              "      <td>It was a day like any other. I was going to c...</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>22</td>\n",
              "      <td>0.616700</td>\n",
              "      <td>0.731181</td>\n",
              "      <td>0.640652</td>\n",
              "      <td>571</td>\n",
              "      <td>701</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3892 rows × 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      essay_id  essay_set  ... essay_len  e_len\n",
              "0         9291          4  ...        91    132\n",
              "1        10402          4  ...        91     79\n",
              "2        10006          4  ...        91     82\n",
              "3         9991          4  ...        91    123\n",
              "4        10126          4  ...        91     27\n",
              "...        ...        ...  ...       ...    ...\n",
              "3887     21132          8  ...       571    293\n",
              "3888     20915          8  ...       571    731\n",
              "3889     21437          8  ...       571    602\n",
              "3890     21095          8  ...       571    811\n",
              "3891     21161          8  ...       571    701\n",
              "\n",
              "[3892 rows x 12 columns]"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tmp_merge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pe410rweBDHJ"
      },
      "outputs": [],
      "source": [
        "def fnx(x):\n",
        "  return (x['e_len']-x['essay_len'])/x['essay_len']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fLHIWqiu_qSm"
      },
      "outputs": [],
      "source": [
        "tmp_merge['length_deviation'] = tmp_merge.apply(fnx, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nhoz5p48jU6Z",
        "outputId": "44478977-44b5-46fa-d056-d6de8703133d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>essay_id</th>\n",
              "      <th>essay_set</th>\n",
              "      <th>essay</th>\n",
              "      <th>normalized_score</th>\n",
              "      <th>spell_err</th>\n",
              "      <th>gram_err</th>\n",
              "      <th>oth_err</th>\n",
              "      <th>semantic_score</th>\n",
              "      <th>coherence_score</th>\n",
              "      <th>prel_score</th>\n",
              "      <th>essay_len</th>\n",
              "      <th>e_len</th>\n",
              "      <th>length_deviation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9291</td>\n",
              "      <td>4</td>\n",
              "      <td>In the story Winter Hibiscus by Minfong Ho, ...</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.803541</td>\n",
              "      <td>0.658268</td>\n",
              "      <td>0.637365</td>\n",
              "      <td>91</td>\n",
              "      <td>132</td>\n",
              "      <td>0.450549</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10402</td>\n",
              "      <td>4</td>\n",
              "      <td>I think the author ended the story with that p...</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.367756</td>\n",
              "      <td>0.304968</td>\n",
              "      <td>0.324565</td>\n",
              "      <td>91</td>\n",
              "      <td>79</td>\n",
              "      <td>-0.131868</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10006</td>\n",
              "      <td>4</td>\n",
              "      <td>The author chose to end the story with this pa...</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.560226</td>\n",
              "      <td>0.464632</td>\n",
              "      <td>0.572027</td>\n",
              "      <td>91</td>\n",
              "      <td>82</td>\n",
              "      <td>-0.098901</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9991</td>\n",
              "      <td>4</td>\n",
              "      <td>This sentence concludes the passage, to show h...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.994009</td>\n",
              "      <td>0.726757</td>\n",
              "      <td>0.688145</td>\n",
              "      <td>91</td>\n",
              "      <td>123</td>\n",
              "      <td>0.351648</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10126</td>\n",
              "      <td>4</td>\n",
              "      <td>The author concludes the Story with this parag...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.011546</td>\n",
              "      <td>0.112469</td>\n",
              "      <td>0.197627</td>\n",
              "      <td>91</td>\n",
              "      <td>27</td>\n",
              "      <td>-0.703297</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3887</th>\n",
              "      <td>21132</td>\n",
              "      <td>8</td>\n",
              "      <td>Laughter is what connects me my friends. It's...</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>0.615803</td>\n",
              "      <td>0.602049</td>\n",
              "      <td>0.537702</td>\n",
              "      <td>571</td>\n",
              "      <td>293</td>\n",
              "      <td>-0.486865</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3888</th>\n",
              "      <td>20915</td>\n",
              "      <td>8</td>\n",
              "      <td>was , hot and dry hadn't seen any for a few m...</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>46</td>\n",
              "      <td>0.740394</td>\n",
              "      <td>0.772299</td>\n",
              "      <td>0.609743</td>\n",
              "      <td>571</td>\n",
              "      <td>731</td>\n",
              "      <td>0.280210</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3889</th>\n",
              "      <td>21437</td>\n",
              "      <td>8</td>\n",
              "      <td>Laughter is the most important part when you ...</td>\n",
              "      <td>0.566667</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>0.563059</td>\n",
              "      <td>0.589851</td>\n",
              "      <td>0.551155</td>\n",
              "      <td>571</td>\n",
              "      <td>602</td>\n",
              "      <td>0.054291</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3890</th>\n",
              "      <td>21095</td>\n",
              "      <td>8</td>\n",
              "      <td>Laughter can not only be a benefit to ourselv...</td>\n",
              "      <td>0.583333</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>11</td>\n",
              "      <td>0.721744</td>\n",
              "      <td>0.672230</td>\n",
              "      <td>0.619011</td>\n",
              "      <td>571</td>\n",
              "      <td>811</td>\n",
              "      <td>0.420315</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3891</th>\n",
              "      <td>21161</td>\n",
              "      <td>8</td>\n",
              "      <td>It was a day like any other. I was going to c...</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>22</td>\n",
              "      <td>0.616700</td>\n",
              "      <td>0.731181</td>\n",
              "      <td>0.640652</td>\n",
              "      <td>571</td>\n",
              "      <td>701</td>\n",
              "      <td>0.227671</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3892 rows × 13 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      essay_id  essay_set  ... e_len  length_deviation\n",
              "0         9291          4  ...   132          0.450549\n",
              "1        10402          4  ...    79         -0.131868\n",
              "2        10006          4  ...    82         -0.098901\n",
              "3         9991          4  ...   123          0.351648\n",
              "4        10126          4  ...    27         -0.703297\n",
              "...        ...        ...  ...   ...               ...\n",
              "3887     21132          8  ...   293         -0.486865\n",
              "3888     20915          8  ...   731          0.280210\n",
              "3889     21437          8  ...   602          0.054291\n",
              "3890     21095          8  ...   811          0.420315\n",
              "3891     21161          8  ...   701          0.227671\n",
              "\n",
              "[3892 rows x 13 columns]"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tmp_merge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "NFzMhV34Bdt4"
      },
      "outputs": [],
      "source": [
        "training_df_xgb_fin = tmp_merge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "5GwqDQ2WorzV",
        "outputId": "9019bed7-5af6-4476-a694-0c6ac53b3d1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input Data shape:  (3892, 13)\n",
            "X_xgb Data shape after drop:  (3892, 7)\n",
            "Original Input Data shape after assigment of X_xgb:  (3892, 13)\n",
            "y shape:  (3892,)\n",
            "Sample Inputs:\n",
            "   spell_err  gram_err  oth_err  ...  semantic_score  prel_score  length_deviation\n",
            "0          8         1        1  ...        0.803541    0.637365          0.450549\n",
            "1          2         0        2  ...        0.367756    0.324565         -0.131868\n",
            "2          1         0        0  ...        0.560226    0.572027         -0.098901\n",
            "3          5         0        0  ...        0.994009    0.688145          0.351648\n",
            "4          1         0        0  ...        0.011546    0.197627         -0.703297\n",
            "\n",
            "[5 rows x 7 columns]\n",
            "Sample Tags - y:\n",
            "0    0.666667\n",
            "1    0.333333\n",
            "2    0.666667\n",
            "3    1.000000\n",
            "4    0.000000\n",
            "Name: normalized_score, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "X_xgb = pd.DataFrame()\n",
        "print (\"Input Data shape: \", training_df_xgb_fin.shape)\n",
        "X_xgb['spell_err'] = training_df_xgb_fin['spell_err']\n",
        "X_xgb['gram_err'] = training_df_xgb_fin['gram_err']\n",
        "#X_xgb['num_words'] = training_df_xgb_fin['num_words']\n",
        "X_xgb['oth_err'] = training_df_xgb_fin['oth_err']\n",
        "X_xgb['coherence_score'] = training_df_xgb_fin['coherence_score']\n",
        "X_xgb['semantic_score'] = training_df_xgb_fin['semantic_score']\n",
        "X_xgb['prel_score'] = training_df_xgb_fin['prel_score']\n",
        "X_xgb['length_deviation'] = training_df_xgb_fin['length_deviation']\n",
        "y_xgb = training_df_xgb_fin['normalized_score']\n",
        "#X_xgb = X_xgb.drop(columns=[\"Unnamed: 0.1.1\"])\n",
        "#X_xgb = X_xgb.drop(columns=[\"Unnamed: 0.1\"])\n",
        "#X_xgb = X_xgb.drop(columns=[\"Unnamed: 0\"])\n",
        "print (\"X_xgb Data shape after drop: \", X_xgb.shape)\n",
        "print (\"Original Input Data shape after assigment of X_xgb: \", training_df_xgb_fin.shape)\n",
        "print (\"y shape: \", y_xgb.shape)\n",
        "print (\"Sample Inputs:\")\n",
        "print (X_xgb.head())\n",
        "print (\"Sample Tags - y:\")\n",
        "print (y_xgb.head())\n",
        "Xgb_train, Xgb_test, ygb_train, ygb_test = train_test_split(X_xgb, y_xgb, test_size=0.2, random_state=42)\n",
        "Xgb_train_noprel, Xgb_test_noprel, ygb_train_noprel, ygb_test_noprel = train_test_split(X_xgb.drop(columns=\"prel_score\"), y_xgb, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "jS8Gx8W1BCVU",
        "outputId": "7fa8a807-0ccd-4c8b-e0f9-63bdb2c41101"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>spell_err</th>\n",
              "      <th>gram_err</th>\n",
              "      <th>oth_err</th>\n",
              "      <th>coherence_score</th>\n",
              "      <th>semantic_score</th>\n",
              "      <th>prel_score</th>\n",
              "      <th>length_deviation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3731</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>0.561768</td>\n",
              "      <td>0.621032</td>\n",
              "      <td>0.582219</td>\n",
              "      <td>-0.133100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3079</th>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>0.360528</td>\n",
              "      <td>0.549661</td>\n",
              "      <td>0.557382</td>\n",
              "      <td>-0.262821</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>175</th>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.506822</td>\n",
              "      <td>0.477708</td>\n",
              "      <td>0.436400</td>\n",
              "      <td>0.307692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>278</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.398197</td>\n",
              "      <td>0.433544</td>\n",
              "      <td>0.418570</td>\n",
              "      <td>-0.164835</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1074</th>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0.749560</td>\n",
              "      <td>0.707989</td>\n",
              "      <td>0.731731</td>\n",
              "      <td>0.013333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1130</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0.810506</td>\n",
              "      <td>0.780722</td>\n",
              "      <td>0.842737</td>\n",
              "      <td>0.566667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1294</th>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.764380</td>\n",
              "      <td>0.737699</td>\n",
              "      <td>0.731473</td>\n",
              "      <td>-0.140000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>860</th>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.716068</td>\n",
              "      <td>0.526516</td>\n",
              "      <td>0.783841</td>\n",
              "      <td>0.372881</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3507</th>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0.633262</td>\n",
              "      <td>0.619817</td>\n",
              "      <td>0.548944</td>\n",
              "      <td>0.045714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3174</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0.848205</td>\n",
              "      <td>0.775588</td>\n",
              "      <td>0.807526</td>\n",
              "      <td>0.217143</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3113 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      spell_err  gram_err  ...  prel_score  length_deviation\n",
              "3731          3         3  ...    0.582219         -0.133100\n",
              "3079          4         2  ...    0.557382         -0.262821\n",
              "175          14         0  ...    0.436400          0.307692\n",
              "278           2         0  ...    0.418570         -0.164835\n",
              "1074         12         0  ...    0.731731          0.013333\n",
              "...         ...       ...  ...         ...               ...\n",
              "1130          1         0  ...    0.842737          0.566667\n",
              "1294          6         1  ...    0.731473         -0.140000\n",
              "860           7         0  ...    0.783841          0.372881\n",
              "3507         12         1  ...    0.548944          0.045714\n",
              "3174          4         4  ...    0.807526          0.217143\n",
              "\n",
              "[3113 rows x 7 columns]"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Xgb_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "VO60Xz3DB6_F",
        "outputId": "67ca875a-022f-43f1-add0-e3265e8e7d4e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>spell_err</th>\n",
              "      <th>gram_err</th>\n",
              "      <th>oth_err</th>\n",
              "      <th>coherence_score</th>\n",
              "      <th>semantic_score</th>\n",
              "      <th>length_deviation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3731</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>0.561768</td>\n",
              "      <td>0.621032</td>\n",
              "      <td>-0.133100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3079</th>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>0.360528</td>\n",
              "      <td>0.549661</td>\n",
              "      <td>-0.262821</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>175</th>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.506822</td>\n",
              "      <td>0.477708</td>\n",
              "      <td>0.307692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>278</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.398197</td>\n",
              "      <td>0.433544</td>\n",
              "      <td>-0.164835</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1074</th>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0.749560</td>\n",
              "      <td>0.707989</td>\n",
              "      <td>0.013333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1130</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0.810506</td>\n",
              "      <td>0.780722</td>\n",
              "      <td>0.566667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1294</th>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.764380</td>\n",
              "      <td>0.737699</td>\n",
              "      <td>-0.140000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>860</th>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.716068</td>\n",
              "      <td>0.526516</td>\n",
              "      <td>0.372881</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3507</th>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0.633262</td>\n",
              "      <td>0.619817</td>\n",
              "      <td>0.045714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3174</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0.848205</td>\n",
              "      <td>0.775588</td>\n",
              "      <td>0.217143</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3113 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      spell_err  gram_err  ...  semantic_score  length_deviation\n",
              "3731          3         3  ...        0.621032         -0.133100\n",
              "3079          4         2  ...        0.549661         -0.262821\n",
              "175          14         0  ...        0.477708          0.307692\n",
              "278           2         0  ...        0.433544         -0.164835\n",
              "1074         12         0  ...        0.707989          0.013333\n",
              "...         ...       ...  ...             ...               ...\n",
              "1130          1         0  ...        0.780722          0.566667\n",
              "1294          6         1  ...        0.737699         -0.140000\n",
              "860           7         0  ...        0.526516          0.372881\n",
              "3507         12         1  ...        0.619817          0.045714\n",
              "3174          4         4  ...        0.775588          0.217143\n",
              "\n",
              "[3113 rows x 6 columns]"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Xgb_train_noprel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "50Dra4Ovo742",
        "outputId": "f468c69d-44b4-4543-d756-e91a0c1351f0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>spell_err</th>\n",
              "      <th>gram_err</th>\n",
              "      <th>oth_err</th>\n",
              "      <th>coherence_score</th>\n",
              "      <th>semantic_score</th>\n",
              "      <th>prel_score</th>\n",
              "      <th>length_deviation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3107</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0.405781</td>\n",
              "      <td>0.411133</td>\n",
              "      <td>0.350979</td>\n",
              "      <td>-0.615385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2398</th>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.278744</td>\n",
              "      <td>0.337107</td>\n",
              "      <td>0.310831</td>\n",
              "      <td>-0.571816</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3864</th>\n",
              "      <td>15</td>\n",
              "      <td>4</td>\n",
              "      <td>59</td>\n",
              "      <td>0.679779</td>\n",
              "      <td>0.725295</td>\n",
              "      <td>0.612141</td>\n",
              "      <td>0.316988</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1187</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.973537</td>\n",
              "      <td>0.996845</td>\n",
              "      <td>0.833963</td>\n",
              "      <td>0.753333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>315</th>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.541859</td>\n",
              "      <td>0.697749</td>\n",
              "      <td>0.658260</td>\n",
              "      <td>0.252747</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3453</th>\n",
              "      <td>8</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>0.530352</td>\n",
              "      <td>0.466695</td>\n",
              "      <td>0.526662</td>\n",
              "      <td>-0.234286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2765</th>\n",
              "      <td>24</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0.632146</td>\n",
              "      <td>0.553861</td>\n",
              "      <td>0.625056</td>\n",
              "      <td>0.371795</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>978</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.685724</td>\n",
              "      <td>0.752813</td>\n",
              "      <td>0.698727</td>\n",
              "      <td>-0.127119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>650</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.181323</td>\n",
              "      <td>0.408657</td>\n",
              "      <td>0.316767</td>\n",
              "      <td>-0.449153</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2661</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>0.540764</td>\n",
              "      <td>0.546425</td>\n",
              "      <td>0.524655</td>\n",
              "      <td>-0.096154</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>779 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      spell_err  gram_err  ...  prel_score  length_deviation\n",
              "3107          1         0  ...    0.350979         -0.615385\n",
              "2398          8         0  ...    0.310831         -0.571816\n",
              "3864         15         4  ...    0.612141          0.316988\n",
              "1187          0         0  ...    0.833963          0.753333\n",
              "315           6         1  ...    0.658260          0.252747\n",
              "...         ...       ...  ...         ...               ...\n",
              "3453          8         6  ...    0.526662         -0.234286\n",
              "2765         24         1  ...    0.625056          0.371795\n",
              "978           0         1  ...    0.698727         -0.127119\n",
              "650           1         0  ...    0.316767         -0.449153\n",
              "2661          1         2  ...    0.524655         -0.096154\n",
              "\n",
              "[779 rows x 7 columns]"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Xgb_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "62qu5_6cCJnd",
        "outputId": "862c25a0-b9ec-432c-faa4-e8fff4b0a861"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>spell_err</th>\n",
              "      <th>gram_err</th>\n",
              "      <th>oth_err</th>\n",
              "      <th>coherence_score</th>\n",
              "      <th>semantic_score</th>\n",
              "      <th>length_deviation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3107</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0.405781</td>\n",
              "      <td>0.411133</td>\n",
              "      <td>-0.615385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2398</th>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.278744</td>\n",
              "      <td>0.337107</td>\n",
              "      <td>-0.571816</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3864</th>\n",
              "      <td>15</td>\n",
              "      <td>4</td>\n",
              "      <td>59</td>\n",
              "      <td>0.679779</td>\n",
              "      <td>0.725295</td>\n",
              "      <td>0.316988</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1187</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.973537</td>\n",
              "      <td>0.996845</td>\n",
              "      <td>0.753333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>315</th>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.541859</td>\n",
              "      <td>0.697749</td>\n",
              "      <td>0.252747</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3453</th>\n",
              "      <td>8</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>0.530352</td>\n",
              "      <td>0.466695</td>\n",
              "      <td>-0.234286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2765</th>\n",
              "      <td>24</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0.632146</td>\n",
              "      <td>0.553861</td>\n",
              "      <td>0.371795</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>978</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.685724</td>\n",
              "      <td>0.752813</td>\n",
              "      <td>-0.127119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>650</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.181323</td>\n",
              "      <td>0.408657</td>\n",
              "      <td>-0.449153</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2661</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>0.540764</td>\n",
              "      <td>0.546425</td>\n",
              "      <td>-0.096154</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>779 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      spell_err  gram_err  ...  semantic_score  length_deviation\n",
              "3107          1         0  ...        0.411133         -0.615385\n",
              "2398          8         0  ...        0.337107         -0.571816\n",
              "3864         15         4  ...        0.725295          0.316988\n",
              "1187          0         0  ...        0.996845          0.753333\n",
              "315           6         1  ...        0.697749          0.252747\n",
              "...         ...       ...  ...             ...               ...\n",
              "3453          8         6  ...        0.466695         -0.234286\n",
              "2765         24         1  ...        0.553861          0.371795\n",
              "978           0         1  ...        0.752813         -0.127119\n",
              "650           1         0  ...        0.408657         -0.449153\n",
              "2661          1         2  ...        0.546425         -0.096154\n",
              "\n",
              "[779 rows x 6 columns]"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Xgb_test_noprel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSh_of60COYo",
        "outputId": "4f70a89d-d26c-42c8-a488-28a50b90d4d0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3731    0.600000\n",
              "3079    0.666667\n",
              "175     0.666667\n",
              "278     0.333333\n",
              "1074    0.500000\n",
              "          ...   \n",
              "1130    0.750000\n",
              "1294    0.750000\n",
              "860     0.750000\n",
              "3507    0.600000\n",
              "3174    0.800000\n",
              "Name: normalized_score, Length: 3113, dtype: float64"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ygb_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxMuTU6aCYZH",
        "outputId": "366cb90e-1372-43bf-8d6b-6b01bfe59848"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3731    0.600000\n",
              "3079    0.666667\n",
              "175     0.666667\n",
              "278     0.333333\n",
              "1074    0.500000\n",
              "          ...   \n",
              "1130    0.750000\n",
              "1294    0.750000\n",
              "860     0.750000\n",
              "3507    0.600000\n",
              "3174    0.800000\n",
              "Name: normalized_score, Length: 3113, dtype: float64"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ygb_train_noprel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jwljQI4jCjso",
        "outputId": "923e706e-7630-49e8-b48a-3c0bbeedf1ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Building standard scaler model from input training vecotrs, scaling input training vectors, soting the SC model to file!\n",
            "Input training vectors scaled & saved Standard Scaler model WITHOUT PREL to a file\n"
          ]
        }
      ],
      "source": [
        "#normalized_Xgb_train=(Xgb_train-Xgb_train.mean())/Xgb_train.std()\n",
        "from sklearn import preprocessing\n",
        "load_trained_model_RF = False\n",
        "second_layer_with_prel = False\n",
        "\n",
        "if (load_trained_model_RF == True):\n",
        "  # No need to generate/scale training vectors, simple load the pre-trained Standard Scaler models from file\n",
        "  # Load Standard Scaler Model\n",
        "  print (\"Not generating input training vecotrs, only loading standard scaler model from file\")\n",
        "  if (second_layer_with_prel == True):\n",
        "    sc = pickle.load(open(\"/content/drive/MyDrive/Colab Notebooks/AES/std_scaler_aes_withprel_15Sep2021\", 'rb'))\n",
        "    print (\"Loaded Standard Scaler model WITH PREL from file\")\n",
        "  else:\n",
        "    sc = pickle.load(open(\"/content/drive/MyDrive/Colab Notebooks/AES/std_scaler_aes_wo_prel_15Sep2021\", 'rb'))\n",
        "    print (\"Loaded Standard Scaler model WITHOUT PREL from file\")\n",
        "\n",
        "else:\n",
        "  # Fit standard scaler model on input training vectors & scale the input training vectors\n",
        "  print (\"Building standard scaler model from input training vecotrs, scaling input training vectors, soting the SC model to file!\")\n",
        "  sc = preprocessing.StandardScaler()\n",
        "  if (second_layer_with_prel == True):\n",
        "    # Build second layer RF model with prompt relevence\n",
        "    sc.fit(Xgb_train)\n",
        "    normalized_Xgb_train = sc.transform(Xgb_train.values)\n",
        "    normalized_Xgb_train_df = pd.DataFrame(normalized_Xgb_train, index=Xgb_train.index, columns=Xgb_train.columns)\n",
        "    ygb_class = np.around(ygb_train*20).astype(int)\n",
        "    feature_names = ['spell_err','gram_err','oth_err','coherence_score','semantic_score', 'prel_score','length_deviation']\n",
        "    # Save Standard Scaler Model\n",
        "    pickle.dump(sc, open(\"/content/drive/MyDrive/Colab Notebooks/AES/std_scaler_aes_withprel_15Sep2021\", 'wb'))\n",
        "    print (\"Input training vectors scaled and saved Standard Scaler model WITH PREL to a file\")\n",
        "  else:\n",
        "    # Build second layer RF model with prompt relevence\n",
        "    sc.fit(Xgb_train_noprel)\n",
        "    normalized_Xgb_train = sc.transform(Xgb_train_noprel.values)\n",
        "    normalized_Xgb_train_df = pd.DataFrame(normalized_Xgb_train, index=Xgb_train_noprel.index, columns=Xgb_train_noprel.columns)\n",
        "    ygb_class = np.around(ygb_train_noprel*20).astype(int)\n",
        "    feature_names = ['spell_err','gram_err','oth_err','coherence_score','semantic_score', 'length_deviation']\n",
        "    # Save Standard Scaler Model\n",
        "    pickle.dump(sc, open(\"/content/drive/MyDrive/Colab Notebooks/AES/std_scaler_aes_wo_prel_15Sep2021\", 'wb'))\n",
        "    print (\"Input training vectors scaled & saved Standard Scaler model WITHOUT PREL to a file\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "Y-o7hWm3CrnL",
        "outputId": "9b2d03d6-8345-4cc2-f616-e66d4cba0b2c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>spell_err</th>\n",
              "      <th>gram_err</th>\n",
              "      <th>oth_err</th>\n",
              "      <th>coherence_score</th>\n",
              "      <th>semantic_score</th>\n",
              "      <th>length_deviation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3731</th>\n",
              "      <td>-0.499252</td>\n",
              "      <td>1.372664</td>\n",
              "      <td>0.849337</td>\n",
              "      <td>0.011327</td>\n",
              "      <td>0.121764</td>\n",
              "      <td>-0.305810</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3079</th>\n",
              "      <td>-0.338962</td>\n",
              "      <td>0.694716</td>\n",
              "      <td>1.052128</td>\n",
              "      <td>-0.865662</td>\n",
              "      <td>-0.205519</td>\n",
              "      <td>-0.593669</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>175</th>\n",
              "      <td>1.263937</td>\n",
              "      <td>-0.661178</td>\n",
              "      <td>-0.772989</td>\n",
              "      <td>-0.228124</td>\n",
              "      <td>-0.535475</td>\n",
              "      <td>0.672337</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>278</th>\n",
              "      <td>-0.659542</td>\n",
              "      <td>-0.661178</td>\n",
              "      <td>-0.772989</td>\n",
              "      <td>-0.701504</td>\n",
              "      <td>-0.737996</td>\n",
              "      <td>-0.376233</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1074</th>\n",
              "      <td>0.943357</td>\n",
              "      <td>-0.661178</td>\n",
              "      <td>0.646546</td>\n",
              "      <td>0.829706</td>\n",
              "      <td>0.520518</td>\n",
              "      <td>0.019135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1130</th>\n",
              "      <td>-0.819832</td>\n",
              "      <td>-0.661178</td>\n",
              "      <td>0.240965</td>\n",
              "      <td>1.095305</td>\n",
              "      <td>0.854048</td>\n",
              "      <td>1.247018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1294</th>\n",
              "      <td>-0.018382</td>\n",
              "      <td>0.016769</td>\n",
              "      <td>-0.367408</td>\n",
              "      <td>0.894290</td>\n",
              "      <td>0.656760</td>\n",
              "      <td>-0.321122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>860</th>\n",
              "      <td>0.141908</td>\n",
              "      <td>-0.661178</td>\n",
              "      <td>-0.772989</td>\n",
              "      <td>0.683751</td>\n",
              "      <td>-0.311657</td>\n",
              "      <td>0.816996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3507</th>\n",
              "      <td>0.943357</td>\n",
              "      <td>0.016769</td>\n",
              "      <td>0.038174</td>\n",
              "      <td>0.322893</td>\n",
              "      <td>0.116192</td>\n",
              "      <td>0.090990</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3174</th>\n",
              "      <td>-0.338962</td>\n",
              "      <td>2.050611</td>\n",
              "      <td>0.038174</td>\n",
              "      <td>1.259596</td>\n",
              "      <td>0.830505</td>\n",
              "      <td>0.471402</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3113 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      spell_err  gram_err  ...  semantic_score  length_deviation\n",
              "3731  -0.499252  1.372664  ...        0.121764         -0.305810\n",
              "3079  -0.338962  0.694716  ...       -0.205519         -0.593669\n",
              "175    1.263937 -0.661178  ...       -0.535475          0.672337\n",
              "278   -0.659542 -0.661178  ...       -0.737996         -0.376233\n",
              "1074   0.943357 -0.661178  ...        0.520518          0.019135\n",
              "...         ...       ...  ...             ...               ...\n",
              "1130  -0.819832 -0.661178  ...        0.854048          1.247018\n",
              "1294  -0.018382  0.016769  ...        0.656760         -0.321122\n",
              "860    0.141908 -0.661178  ...       -0.311657          0.816996\n",
              "3507   0.943357  0.016769  ...        0.116192          0.090990\n",
              "3174  -0.338962  2.050611  ...        0.830505          0.471402\n",
              "\n",
              "[3113 rows x 6 columns]"
            ]
          },
          "execution_count": 105,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "normalized_Xgb_train_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P_eCIbI3u72w"
      },
      "outputs": [],
      "source": [
        "if (second_layer_with_prel == True):  \n",
        "  tt = np.array(20* ygb_test)\n",
        "else:\n",
        "  tt = np.array(20* ygb_test_noprel)\n",
        "xgb_gold_values_class = tt.astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oW_NpH29T1O6"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib notebook\n",
        "def f_importances (coef, names):\n",
        "  imp = coef[0]\n",
        "  imp,names = zip(*sorted(zip(imp,names)))\n",
        "  print (\"AS Importance, names: \", imp, names)\n",
        "  plt.barh(range(len(names)), imp, align='center')\n",
        "  plt.yticks(range(len(names)), names)\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0BxDT2RLQWpt"
      },
      "outputs": [],
      "source": [
        "from sklearn import svm\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "import pickle as pkl\n",
        "\n",
        "clfs = {'RF': RandomForestClassifier (n_estimators=50, n_jobs=-1),\n",
        "        'ET': ExtraTreesClassifier (n_estimators=10, n_jobs=-1, criterion='entropy'),\n",
        "        'AS': AdaBoostClassifier (DecisionTreeClassifier(max_depth=1), algorithm='SAMME', n_estimators=200),\n",
        "        'LR': LogisticRegression (penalty='l1', solver='liblinear', C=1e5),\n",
        "        'SVM': svm.SVC(kernel='linear', probability=True, random_state=0),\n",
        "        'GB': GradientBoostingClassifier (learning_rate=0.05, subsample=0.5, max_depth=6, n_estimators=10),\n",
        "        'NB': GaussianNB(),\n",
        "        'DT': DecisionTreeClassifier()\n",
        "        }\n",
        "model = clfs['RF'].fit(normalized_Xgb_train_df, ygb_class)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Uzgc-TIc1px"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ADUO7hrMY_1h"
      },
      "outputs": [],
      "source": [
        "if (second_layer_with_prel == True):\n",
        "  # Build second layer RF model with prompt relevence\n",
        "  normalized_Xgb_test = sc.transform(Xgb_test.values)\n",
        "  normalized_Xgb_test_df = pd.DataFrame(normalized_Xgb_test, index=Xgb_test.index, columns=Xgb_test.columns)\n",
        "  tt = np.array(20* ygb_test)\n",
        "else:\n",
        "  normalized_Xgb_test = sc.transform(Xgb_test_noprel.values)\n",
        "  normalized_Xgb_test_df = pd.DataFrame(normalized_Xgb_test, index=Xgb_test_noprel.index, columns=Xgb_test_noprel.columns)\n",
        "  tt = np.array(20* ygb_test_noprel)\n",
        "\n",
        "xgb_gold_values_class = tt.astype(int)\n",
        "xgb_y_pred = model.predict(normalized_Xgb_test_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "NBD2HpPhSO_Z",
        "outputId": "277e4904-6243-4ba2-eb12-b1555b4f066e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>spell_err</th>\n",
              "      <th>gram_err</th>\n",
              "      <th>oth_err</th>\n",
              "      <th>coherence_score</th>\n",
              "      <th>semantic_score</th>\n",
              "      <th>length_deviation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3107</th>\n",
              "      <td>-0.819832</td>\n",
              "      <td>-0.661178</td>\n",
              "      <td>-0.164617</td>\n",
              "      <td>-0.668454</td>\n",
              "      <td>-0.840762</td>\n",
              "      <td>-1.376032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2398</th>\n",
              "      <td>0.302198</td>\n",
              "      <td>-0.661178</td>\n",
              "      <td>-0.367408</td>\n",
              "      <td>-1.222071</td>\n",
              "      <td>-1.180223</td>\n",
              "      <td>-1.279349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3864</th>\n",
              "      <td>1.424227</td>\n",
              "      <td>2.050611</td>\n",
              "      <td>11.191668</td>\n",
              "      <td>0.525610</td>\n",
              "      <td>0.599878</td>\n",
              "      <td>0.692964</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1187</th>\n",
              "      <td>-0.980122</td>\n",
              "      <td>-0.661178</td>\n",
              "      <td>-0.772989</td>\n",
              "      <td>1.805783</td>\n",
              "      <td>1.845119</td>\n",
              "      <td>1.661244</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>315</th>\n",
              "      <td>-0.018382</td>\n",
              "      <td>0.016769</td>\n",
              "      <td>-0.570198</td>\n",
              "      <td>-0.075435</td>\n",
              "      <td>0.473564</td>\n",
              "      <td>0.550410</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3453</th>\n",
              "      <td>0.302198</td>\n",
              "      <td>3.406506</td>\n",
              "      <td>0.240965</td>\n",
              "      <td>-0.125582</td>\n",
              "      <td>-0.585974</td>\n",
              "      <td>-0.530348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2765</th>\n",
              "      <td>2.866837</td>\n",
              "      <td>0.016769</td>\n",
              "      <td>0.240965</td>\n",
              "      <td>0.318026</td>\n",
              "      <td>-0.186260</td>\n",
              "      <td>0.814585</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>978</th>\n",
              "      <td>-0.980122</td>\n",
              "      <td>0.016769</td>\n",
              "      <td>-0.772989</td>\n",
              "      <td>0.551518</td>\n",
              "      <td>0.726069</td>\n",
              "      <td>-0.292537</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>650</th>\n",
              "      <td>-0.819832</td>\n",
              "      <td>-0.661178</td>\n",
              "      <td>-0.367408</td>\n",
              "      <td>-1.646625</td>\n",
              "      <td>-0.852116</td>\n",
              "      <td>-1.007152</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2661</th>\n",
              "      <td>-0.819832</td>\n",
              "      <td>0.694716</td>\n",
              "      <td>0.240965</td>\n",
              "      <td>-0.080210</td>\n",
              "      <td>-0.220359</td>\n",
              "      <td>-0.223824</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>779 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      spell_err  gram_err  ...  semantic_score  length_deviation\n",
              "3107  -0.819832 -0.661178  ...       -0.840762         -1.376032\n",
              "2398   0.302198 -0.661178  ...       -1.180223         -1.279349\n",
              "3864   1.424227  2.050611  ...        0.599878          0.692964\n",
              "1187  -0.980122 -0.661178  ...        1.845119          1.661244\n",
              "315   -0.018382  0.016769  ...        0.473564          0.550410\n",
              "...         ...       ...  ...             ...               ...\n",
              "3453   0.302198  3.406506  ...       -0.585974         -0.530348\n",
              "2765   2.866837  0.016769  ...       -0.186260          0.814585\n",
              "978   -0.980122  0.016769  ...        0.726069         -0.292537\n",
              "650   -0.819832 -0.661178  ...       -0.852116         -1.007152\n",
              "2661  -0.819832  0.694716  ...       -0.220359         -0.223824\n",
              "\n",
              "[779 rows x 6 columns]"
            ]
          },
          "execution_count": 111,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "normalized_Xgb_test_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXC7z7CxZOZw",
        "outputId": "a1dba352-d801-4f50-8fc5-acd36bb85f3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Kappa Score: 0.777496800526493\n"
          ]
        }
      ],
      "source": [
        "result = cohen_kappa_score(xgb_gold_values_class,xgb_y_pred,weights='quadratic')\n",
        "print(\"Kappa Score: {}\".format(result))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vwm78InupUEr"
      },
      "outputs": [],
      "source": [
        "bst = xgb.XGBRegressor({'nthread':4})\n",
        "bst.load_model(file_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ht0L9Vs5pcEt"
      },
      "outputs": [],
      "source": [
        "xgb_y_pred = bst.predict(Xgb_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "id": "0n5TXyPUpe0e",
        "outputId": "39a800a9-879d-4707-fd84-81502618ce01"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-6f250c12a1c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mxgb_y_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXgb_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'regressor' is not defined"
          ]
        }
      ],
      "source": [
        "xgb_y_pred = regressor.predict(Xgb_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FIYFpO-zgczf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gLyyXujjCdvW"
      },
      "outputs": [],
      "source": [
        "if (second_layer_with_prel == True):\n",
        "  pkl.dump(model,open('/content/drive/MyDrive/Colab Notebooks/AES/RandomForest_with_prel.sav','wb'))\n",
        "else:\n",
        "  pkl.dump(model,open('/content/drive/MyDrive/Colab Notebooks/AES/RandomForest_wo_prel.sav','wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ePFnkebxO_sX"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame(regressor.feature_importances_.reshape(1, -1), columns=['spell_err','gram_err','oth_err','coherence_score','semantic_score', 'prel_score','length_deviation'])\n",
        "\n",
        "xgb_y_pred = regressor.predict(Xgb_test)\n",
        "\n",
        "MSE = np.square(np.subtract(ygb_test, xgb_y_pred)).mean()\n",
        "RMSE = math.sqrt(MSE)\n",
        "print (\"Coherence Model: MSE: \", MSE)\n",
        "print (\"COherence Model: RMSE: \", RMSE)\n",
        "\n",
        "file_name = \"/content/drive/MyDrive/Colab Notebooks/AES/xgb_reg.pkl\"\n",
        "\n",
        "# save XGB Model\n",
        "regressor.save_model(file_name)\n",
        "result = cohen_kappa_score(xgb_gold_values_class,xgb_pred_class,weights='quadratic')\n",
        "print(\"Kappa Score: {}\".format(result))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwS6ftQnS3Ms"
      },
      "source": [
        "## Cosine Similarity for Prompt Relevance & Next Sentence Prediction model for Coherence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I-6YCr37FLMY"
      },
      "outputs": [],
      "source": [
        "#prompt_data['cosine_sim'] = 0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ewNupLsPX8X",
        "outputId": "189cf8ec-2af8-436e-a82d-61d710601b5c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertModel, BertConfig, BertTokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "config = BertConfig.from_pretrained('bert-base-uncased', output_hidden_states=True)\n",
        "model = BertModel.from_pretrained('bert-base-uncased', config=config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xASzKqbDR7gZ"
      },
      "outputs": [],
      "source": [
        "lhs_prompts = torch.empty((len(prompts),1,768), dtype=torch.float)\n",
        "\n",
        "for i in range(len(prompts)):\n",
        "  prompt = prompts.prompt.iloc[i]\n",
        "  prompt_sentences = split_into_sentences(prompt)\n",
        "  sen_length = len(prompt_sentences)\n",
        "\n",
        "  lhs_sentence_avg = np.zeros((1,768), dtype = float)\n",
        "  lhs_avg_sen = np.empty((0,768), dtype=float)\n",
        "\n",
        "  for j in range(min(max_sentences,sen_length)):\n",
        "    tokenize_sentence = tokenizer.encode(prompt_sentences[j], add_special_tokens=True, max_length=512, truncation=True)\n",
        "    tt = torch.tensor(tokenize_sentence)\n",
        "    tts = tt.reshape(1,len(tt))\n",
        "    # getting the 2nd last layer\n",
        "    output = model(tts)\n",
        "    lhs_sentence = output.hidden_states[12] + output.hidden_states[11] + output.hidden_states[10] + output.hidden_states[9]\n",
        "    lhs_sentence_np = np.array(lhs_sentence.detach().numpy())\n",
        "    lhs_sentence_np_mean = np.mean(lhs_sentence_np,axis=1)\n",
        "    lhs_avg_sen = np.append(lhs_avg_sen,lhs_sentence_np_mean, axis=0)\n",
        "  lhs_sentence_avg = np.mean(lhs_avg_sen, axis=0)\n",
        "\n",
        "  lhs_prompts[i] = torch.tensor(lhs_sentence_avg)\n",
        "\n",
        "torch.save(lhs_prompts, '/content/drive/MyDrive/Colab Notebooks/AES/prompts_lhs.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVBItOzFVZdP",
        "outputId": "b74c1f14-9917-441f-ba93-c108a94bd700"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([8, 1, 768])"
            ]
          },
          "execution_count": 84,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lhs_prompts.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y5ltbT3hZ7mp"
      },
      "outputs": [],
      "source": [
        "cos = torch.nn.CosineSimilarity(dim=0, eps=1e-08)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "id": "cDrQ0Fc3IYg7",
        "outputId": "f618bdea-68a0-49a0-8cd6-ca001f0f980e"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-024bddfbdc52>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minput1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m768\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0minput2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m768\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ],
      "source": [
        "input1 = torch.randn(1, 768)\n",
        "input2 = torch.randn(1, 768)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FsJgDrb1IfH-",
        "outputId": "d1926925-117c-43b9-c58b-d74a4714e69c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([-0.0735, -0.0395, -0.1273,  0.0273, -0.1357,  0.0424, -0.0101,  0.1760,\n",
              "        -0.0862, -0.0300,  0.0151,  0.0976, -0.0567,  0.1664, -0.0106, -0.0485,\n",
              "         0.0470, -0.1434, -0.0121,  0.0388, -0.1286,  0.0011,  0.0601,  0.2076,\n",
              "        -0.0657,  0.0909, -0.0322,  0.0533,  0.0668, -0.1319, -0.0291,  0.1785,\n",
              "        -0.0184,  0.2033,  0.0617,  0.0654, -0.0874, -0.1517, -0.2302,  0.2155,\n",
              "         0.1217, -0.1152, -0.0351, -0.0500, -0.0870,  0.1235, -0.0581, -0.0784,\n",
              "         0.0679,  0.0482,  0.0541, -0.2324,  0.2389,  0.0947,  0.0015,  0.0865,\n",
              "        -0.0198, -0.1263, -0.1202, -0.1421, -0.1142,  0.0237, -0.1126,  0.1057,\n",
              "         0.0484, -0.0793,  0.1952, -0.0747,  0.0134, -0.1639,  0.2234, -0.0713,\n",
              "         0.0472, -0.0408,  0.0570,  0.0212, -0.0656,  0.0661, -0.0477,  0.0899,\n",
              "        -0.0613,  0.1057,  0.0440, -0.0396,  0.0081,  0.1307, -0.0538, -0.1125,\n",
              "        -0.0027, -0.0480, -0.0281,  0.1326, -0.0061,  0.1386,  0.0103,  0.0321,\n",
              "        -0.0608,  0.0912, -0.2205,  0.0968, -0.1562,  0.0594, -0.0236,  0.1022,\n",
              "        -0.0434, -0.1216, -0.1093, -0.0764,  0.0652,  0.0405, -0.0834,  0.0023,\n",
              "        -0.0623,  0.0507, -0.1524,  0.1060, -0.0110, -0.0118,  0.0860, -0.0543,\n",
              "        -0.1270, -0.1170,  0.0556,  0.0411, -0.1345, -0.0330, -0.0160,  0.0254])"
            ]
          },
          "execution_count": 16,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cos(input1, input2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iIqWOJRSAmcK",
        "outputId": "a57a162d-240a-43a8-f855-b6da8c59e3d5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4542/4542 [1:19:42<00:00,  1.05s/it]\n"
          ]
        }
      ],
      "source": [
        "lhs_essay = torch.empty((1,768), dtype=torch.float)\n",
        "# emb_for_padding = tokenizer.encode_plus(\"\", add_special_tokens=True, truncation=True, padding=\"max_length\", return_tensors=\"pt\", max_length=10)\n",
        "# tt = torch.tensor(emb_for_padding['input_ids'])\n",
        "# output = model(tt)\n",
        "# lhs_for_padding = output.hidden_states[12] + output.hidden_states[11] + output.hidden_states[10] + output.hidden_states[9]\n",
        "# lhs_for_padding_np = np.array(lhs_for_padding.detach().numpy())\n",
        "# lhs_for_padding_mean = np.mean(lhs_for_padding_np,axis=1)\n",
        "# lhs_avg_for_padding = torch.tensor(lhs_for_padding_mean[0])\n",
        "\n",
        "for j in tqdm(range(len(prompt_data))):\n",
        "  essay = prompt_data.essay.iloc[j]\n",
        "  sentences = split_into_sentences(essay)\n",
        "\n",
        "  sen_length = len(sentences)\n",
        "  \n",
        "  lhs_sentence_avg = np.zeros((1,768), dtype=float)\n",
        "  lhs_avg_sen = np.empty((0,768), dtype=float)\n",
        "\n",
        "  for i in range(min(max_sentences,len(sentences))):\n",
        "    tokenize_sentence = tokenizer.encode(sentences[i],add_special_tokens=True, max_length=512, truncation=True)\n",
        "    tt = torch.tensor(tokenize_sentence)\n",
        "    tts = tt.reshape(1,len(tt))\n",
        "    # getting the 2nd last layer\n",
        "    output = model(tts)\n",
        "    lhs_sentence = output.hidden_states[12] + output.hidden_states[11] + output.hidden_states[10] + output.hidden_states[9]\n",
        "    lhs_sentence_np = np.array(lhs_sentence.detach().numpy())\n",
        "    lhs_sentence_np_mean = np.mean(lhs_sentence_np,axis=1)\n",
        "    lhs_avg_sen = np.append(lhs_avg_sen,lhs_sentence_np_mean, axis=0)\n",
        "\n",
        "  lhs_sentence_avg = np.mean(lhs_avg_sen, axis=0, keepdims=True)\n",
        "  lhs_essay = torch.tensor(lhs_sentence_avg)\n",
        "\n",
        "  prompt_data.cosine_sim.iloc[j] = float(cos(lhs_prompts[prompt_data.essay_set.iloc[j]-1] , lhs_essay))\n",
        "  \n",
        "torch.save(prompt_data, '/content/drive/MyDrive/Colab Notebooks/AES/prompt_data_with_cosine_sim.df')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhxcBUP_F2-j",
        "outputId": "ff5ebc2a-b82c-426f-f2d1-879f8d1a35ee"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 768])"
            ]
          },
          "execution_count": 86,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lhs_prompts[prompt_data.essay_set.iloc[j]-1].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qkYJCbQHb0TY"
      },
      "outputs": [],
      "source": [
        "prompt_data.cosine_sim.iloc[0] = 0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JdMhrZ0SF-eG",
        "outputId": "4a552538-3a22-417a-ce83-bddbdfe15e35"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([768])"
            ]
          },
          "execution_count": 87,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lhs_essay.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4PITaZrcCjQ",
        "outputId": "2c26ae48-78a1-4341-c57a-93f8b918bcc1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([80, 768])"
            ]
          },
          "execution_count": 48,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lhs_prompts[prompt_data.essay_set.iloc[0]-1].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eIyL7TMAcNWf",
        "outputId": "596381d2-aa2a-408b-bff1-86e49b991bf9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "execution_count": 52,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt_data.essay_set.iloc[10000]-1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "id": "DjEHrvBqclzD",
        "outputId": "583ef6bf-4f49-4195-d6ed-9eed525a45ca"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>essay_id</th>\n",
              "      <th>essay_set</th>\n",
              "      <th>essay</th>\n",
              "      <th>domain1_score</th>\n",
              "      <th>normalized_score</th>\n",
              "      <th>prompt</th>\n",
              "      <th>combined_essay</th>\n",
              "      <th>cosine_sim</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>15177</td>\n",
              "      <td>6</td>\n",
              "      <td>The builders of the empire state building atte...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.25</td>\n",
              "      <td>In their ambition to outshine the other, the a...</td>\n",
              "      <td>In their ambition to outshine the other, the a...</td>\n",
              "      <td>0.947607</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>14855</td>\n",
              "      <td>6</td>\n",
              "      <td>The builders of the many obstacles when attemp...</td>\n",
              "      <td>4</td>\n",
              "      <td>1.00</td>\n",
              "      <td>In their ambition to outshine the other, the a...</td>\n",
              "      <td>In their ambition to outshine the other, the a...</td>\n",
              "      <td>0.937073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>16587</td>\n",
              "      <td>6</td>\n",
              "      <td>The ability to dock dirigibles atop the Empire...</td>\n",
              "      <td>4</td>\n",
              "      <td>1.00</td>\n",
              "      <td>In their ambition to outshine the other, the a...</td>\n",
              "      <td>In their ambition to outshine the other, the a...</td>\n",
              "      <td>0.898640</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>16368</td>\n",
              "      <td>6</td>\n",
              "      <td>They faced many problems when trying to dock t...</td>\n",
              "      <td>2</td>\n",
              "      <td>0.50</td>\n",
              "      <td>In their ambition to outshine the other, the a...</td>\n",
              "      <td>In their ambition to outshine the other, the a...</td>\n",
              "      <td>0.862020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>15281</td>\n",
              "      <td>6</td>\n",
              "      <td>While attempting to allow dirigibles to dock a...</td>\n",
              "      <td>3</td>\n",
              "      <td>0.75</td>\n",
              "      <td>In their ambition to outshine the other, the a...</td>\n",
              "      <td>In their ambition to outshine the other, the a...</td>\n",
              "      <td>0.930908</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   essay_id  ...  cosine_sim\n",
              "0     15177  ...    0.947607\n",
              "1     14855  ...    0.937073\n",
              "2     16587  ...    0.898640\n",
              "3     16368  ...    0.862020\n",
              "4     15281  ...    0.930908\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "execution_count": 89,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "id": "pFKx882McoSN",
        "outputId": "51a27d78-a44c-4085-af76-ddd1cc1be6a5"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-e881ab7b2645>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprompt_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'prompt_data' is not defined"
          ]
        }
      ],
      "source": [
        "prompt_data.iloc[10000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "id": "dp78gO7xcyDd",
        "outputId": "4bef3dd5-88aa-4afe-d102-c57b486de81f"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-576a364c7ba2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlhs_prompts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprompt_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0messay_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mlhs_essay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'cos' is not defined"
          ]
        }
      ],
      "source": [
        "cos(lhs_prompts[prompt_data.essay_set.iloc[j]-1] , lhs_essay)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rp_Td2RGABcz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNG0M19Kr96K"
      },
      "source": [
        "### XGBoost Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcrEKfSTsD1B"
      },
      "source": [
        "#####Prepare Handcrafted Data  for XGBoost Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2DEEGIgSc52n"
      },
      "outputs": [],
      "source": [
        "compute_handcrafted_features = False\n",
        "if (compute_handcrafted_features == True):\n",
        "  data_with_handcrafted = augment_handcrafted_features(data)\n",
        "  data_with_handcrafted.to_csv(data_with_errors_path)\n",
        "else:\n",
        "  data_with_handcrafted = pd.read_csv(data_with_errors_path)\n",
        "data_with_handcrafted.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfBiTey3AmHX"
      },
      "source": [
        "## New coherence model with NSP goldens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSGL44I4SEuy"
      },
      "source": [
        "### Loading/creating dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnLCSFYfAyDt",
        "outputId": "2bbc1f9c-df1f-47eb-ef8f-6cc6937a4755"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Preparing Embeddings...\n",
            "Model Type:  semantic\n",
            "Embedding Type:  sen_avg\n",
            "hState:  last4sum\n",
            "Save File Directory:  /content/drive/MyDrive/Colab Notebooks/AES/experiment_XX\n",
            "Dataframe provided, Size:  (6488, 6)\n",
            "Loading existing embeddings from file...\n",
            "LHS File chosen:  /content/drive/MyDrive/Colab Notebooks/AES/experiment_XX/lhs_train.pt\n",
            "Y File chosen:  /content/drive/MyDrive/Colab Notebooks/AES/experiment_XX/y_train.pt\n",
            "Loaded, Size of LHS embeddings:  torch.Size([6488, 128, 768])\n",
            "Loaded, Size of y Gold:  (6488,)\n",
            "Returning lhs: Shape:  torch.Size([6488, 128, 768])\n",
            "Returning y_gold: Shape:  (6488,)\n"
          ]
        }
      ],
      "source": [
        "lhs_train, y_train = prepare_embeddings_updated (tpd_train, model_type='semantic', train_or_test='train', load_from_file=load_bert_sem, embedding_type=embedding, max_words=max_words_for_full_emb_sem, file_path=model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVZCzhcoKrg7",
        "outputId": "4b40d304-115c-4fa1-c1b6-ebdbaf9f83ab"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f58545f215534d038bacf204726bef99",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fcbf8df7ae4848e5ad274e603179e7a3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "43730a8144cb401f9919485ebb5e154f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2d3de14333234cd496cd3f81fd0d1258",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c6fae8eb1a0f4bcb9f6e6ef9d33ed873",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/420M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForNextSentencePrediction: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertForNextSentencePrediction from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForNextSentencePrediction from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertTokenizer, BertForNextSentencePrediction\n",
        "import torch\n",
        "from torch.nn import functional as F\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertForNextSentencePrediction.from_pretrained('bert-base-uncased')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QHmjLXgmCTxr"
      },
      "outputs": [],
      "source": [
        "calculate_nsp_goldens = False\n",
        "def nsp_average(essay):\n",
        "  score = 0\n",
        "  avg_score = 0\n",
        "  sentences = split_into_sentences(essay)\n",
        "  if len(sentences) != 0:\n",
        "    for i in range(len(sentences)-1):\n",
        "        encoding = tokenizer.encode_plus(sentences[i], sentences[i+1], return_tensors='pt')\n",
        "        outputs = model(**encoding).logits\n",
        "        softmax = F.softmax(outputs, dim = 1)\n",
        "        score = score + np.float (softmax[0][0])\n",
        "    avg_score = score / len(sentences)\n",
        "  # print(\"Total score: \", score, \"Avg. score: \", avg_score)\n",
        "  # print (\"Sentences:\\n\", sentences)\n",
        "  return avg_score\n",
        "  \n",
        "if calculate_nsp_goldens:\n",
        "    tpd_train['nsp_golden'] = 0\n",
        "    for i in tqdm(range(len(tpd_train))):\n",
        "        tpd_train['nsp_golden'].iloc[i] = nsp_average(tpd_train['essay'][i])\n",
        "    nsp_average(tpd_train['essay'][0])\n",
        "    tpd_train.to_csv(\"/content/drive/MyDrive/Colab Notebooks/AES/tpd_train_with_nsp.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0suZvUevZ60",
        "outputId": "ded406c2-220c-4d19-8a90-b670e5f3ac83"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>essay_id</th>\n",
              "      <th>essay_set</th>\n",
              "      <th>essay</th>\n",
              "      <th>domain1_score</th>\n",
              "      <th>normalized_score</th>\n",
              "      <th>nsp_golden</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>6351</td>\n",
              "      <td>9908</td>\n",
              "      <td>4</td>\n",
              "      <td>The author concludes the story w/this paragrap...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.666664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>6315</td>\n",
              "      <td>9872</td>\n",
              "      <td>4</td>\n",
              "      <td>I believe that the author concludes the story ...</td>\n",
              "      <td>2</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.857135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>304</td>\n",
              "      <td>305</td>\n",
              "      <td>1</td>\n",
              "      <td>Computers, a very much talked about subject. D...</td>\n",
              "      <td>10</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.956475</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>8023</td>\n",
              "      <td>12771</td>\n",
              "      <td>5</td>\n",
              "      <td>I think in my opion is that the author was ver...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.666370</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4442</td>\n",
              "      <td>6839</td>\n",
              "      <td>3</td>\n",
              "      <td>The setting that affect the cyclist is the con...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.666664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6483</th>\n",
              "      <td>6483</td>\n",
              "      <td>12781</td>\n",
              "      <td>21380</td>\n",
              "      <td>8</td>\n",
              "      <td>When I was fourteen years old I think my fami...</td>\n",
              "      <td>37</td>\n",
              "      <td>0.616667</td>\n",
              "      <td>0.962917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6484</th>\n",
              "      <td>6484</td>\n",
              "      <td>7107</td>\n",
              "      <td>11855</td>\n",
              "      <td>5</td>\n",
              "      <td>In Narciso Rodriguez's memoir, the mood and fe...</td>\n",
              "      <td>3</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.857108</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6485</th>\n",
              "      <td>6485</td>\n",
              "      <td>1736</td>\n",
              "      <td>1741</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear, local newspaper, you like computers? I ,...</td>\n",
              "      <td>8</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.965063</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6486</th>\n",
              "      <td>6486</td>\n",
              "      <td>12296</td>\n",
              "      <td>20770</td>\n",
              "      <td>8</td>\n",
              "      <td>Laughter is indeed an important part of anyon...</td>\n",
              "      <td>39</td>\n",
              "      <td>0.650000</td>\n",
              "      <td>0.934141</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6487</th>\n",
              "      <td>6487</td>\n",
              "      <td>9628</td>\n",
              "      <td>15578</td>\n",
              "      <td>6</td>\n",
              "      <td>In \"The Mooring Mast,\" a historical article by...</td>\n",
              "      <td>3</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.864184</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6488 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Unnamed: 0  Unnamed: 0.1  ...  normalized_score  nsp_golden\n",
              "0              0          6351  ...          0.333333    0.666664\n",
              "1              1          6315  ...          0.666667    0.857135\n",
              "2              2           304  ...          0.800000    0.956475\n",
              "3              3          8023  ...          0.250000    0.666370\n",
              "4              4          4442  ...          0.333333    0.666664\n",
              "...          ...           ...  ...               ...         ...\n",
              "6483        6483         12781  ...          0.616667    0.962917\n",
              "6484        6484          7107  ...          0.750000    0.857108\n",
              "6485        6485          1736  ...          0.600000    0.965063\n",
              "6486        6486         12296  ...          0.650000    0.934141\n",
              "6487        6487          9628  ...          0.750000    0.864184\n",
              "\n",
              "[6488 rows x 8 columns]"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nsp_tpd_train = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/AES/tpd_train_with_nsp.csv\")\n",
        "nsp_tpd_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKEKUY3TP7CH"
      },
      "source": [
        "### Training/loading the coherence (NSP) LSTM model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UpY98e9dQkQ4"
      },
      "outputs": [],
      "source": [
        "coh_nsp_model_save_path = \"/content/drive/MyDrive/Colab Notebooks/AES/coherence_model_with_nsp_goldens.pt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UM80ATlNP7CI",
        "outputId": "c5ccdde3-8bbe-49a7-d661-878d68c2f741"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 128, 1028)         7389264   \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 512)               3155968   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 513       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 10,545,745\n",
            "Trainable params: 10,545,745\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "102/102 [==============================] - 76s 691ms/step - loss: 0.0845 - mae: 0.2134\n",
            "Epoch 2/100\n",
            "102/102 [==============================] - 69s 677ms/step - loss: 0.0840 - mae: 0.2125\n",
            "Epoch 3/100\n",
            "102/102 [==============================] - 69s 678ms/step - loss: 0.0840 - mae: 0.2125\n",
            "Epoch 4/100\n",
            "102/102 [==============================] - 68s 670ms/step - loss: 0.0840 - mae: 0.2125\n",
            "Epoch 5/100\n",
            "102/102 [==============================] - 69s 675ms/step - loss: 0.0644 - mae: 0.1762\n",
            "Epoch 6/100\n",
            "102/102 [==============================] - 68s 670ms/step - loss: 0.0411 - mae: 0.1349\n",
            "Epoch 7/100\n",
            "102/102 [==============================] - 68s 668ms/step - loss: 0.0403 - mae: 0.1333\n",
            "Epoch 8/100\n",
            "102/102 [==============================] - 68s 668ms/step - loss: 0.0398 - mae: 0.1339\n",
            "Epoch 9/100\n",
            "102/102 [==============================] - 68s 668ms/step - loss: 0.0395 - mae: 0.1333\n",
            "Epoch 10/100\n",
            "102/102 [==============================] - 68s 667ms/step - loss: 0.0397 - mae: 0.1330\n",
            "Epoch 11/100\n",
            "102/102 [==============================] - 68s 667ms/step - loss: 0.0372 - mae: 0.1270\n",
            "Epoch 12/100\n",
            "102/102 [==============================] - 68s 668ms/step - loss: 0.0231 - mae: 0.1030\n",
            "Epoch 13/100\n",
            "102/102 [==============================] - 68s 667ms/step - loss: 0.0193 - mae: 0.0976\n",
            "Epoch 14/100\n",
            "102/102 [==============================] - 68s 666ms/step - loss: 0.0181 - mae: 0.0948\n",
            "Epoch 15/100\n",
            "102/102 [==============================] - 68s 666ms/step - loss: 0.0156 - mae: 0.0868\n",
            "Epoch 16/100\n",
            "102/102 [==============================] - 68s 666ms/step - loss: 0.0147 - mae: 0.0849\n",
            "Epoch 17/100\n",
            "102/102 [==============================] - 68s 668ms/step - loss: 0.0144 - mae: 0.0845\n",
            "Epoch 18/100\n",
            "102/102 [==============================] - 68s 668ms/step - loss: 0.0134 - mae: 0.0806\n",
            "Epoch 19/100\n",
            "102/102 [==============================] - 68s 667ms/step - loss: 0.0124 - mae: 0.0779\n",
            "Epoch 20/100\n",
            "102/102 [==============================] - 68s 669ms/step - loss: 0.0118 - mae: 0.0758\n",
            "Epoch 21/100\n",
            "102/102 [==============================] - 68s 668ms/step - loss: 0.0114 - mae: 0.0745\n",
            "Epoch 22/100\n",
            "102/102 [==============================] - 68s 669ms/step - loss: 0.0117 - mae: 0.0753\n",
            "Epoch 23/100\n",
            "102/102 [==============================] - 68s 671ms/step - loss: 0.0110 - mae: 0.0726\n",
            "Epoch 24/100\n",
            "102/102 [==============================] - 68s 671ms/step - loss: 0.0099 - mae: 0.0698\n",
            "Epoch 25/100\n",
            "102/102 [==============================] - 69s 672ms/step - loss: 0.0099 - mae: 0.0699\n",
            "Epoch 26/100\n",
            "102/102 [==============================] - 69s 674ms/step - loss: 0.0098 - mae: 0.0694\n",
            "Epoch 27/100\n",
            "102/102 [==============================] - 68s 667ms/step - loss: 0.0094 - mae: 0.0671\n",
            "Epoch 28/100\n",
            "102/102 [==============================] - 68s 669ms/step - loss: 0.0094 - mae: 0.0676\n",
            "Epoch 29/100\n",
            "102/102 [==============================] - 68s 669ms/step - loss: 0.0086 - mae: 0.0656\n",
            "Epoch 30/100\n",
            "102/102 [==============================] - 68s 668ms/step - loss: 0.0084 - mae: 0.0645\n",
            "Epoch 31/100\n",
            "102/102 [==============================] - 69s 672ms/step - loss: 0.0082 - mae: 0.0631\n",
            "Epoch 32/100\n",
            "102/102 [==============================] - 68s 668ms/step - loss: 0.0082 - mae: 0.0629\n",
            "Epoch 33/100\n",
            "102/102 [==============================] - 68s 666ms/step - loss: 0.0077 - mae: 0.0615\n",
            "Epoch 34/100\n",
            "102/102 [==============================] - 68s 667ms/step - loss: 0.0089 - mae: 0.0654\n",
            "Epoch 35/100\n",
            "102/102 [==============================] - 68s 668ms/step - loss: 0.0097 - mae: 0.0689\n",
            "Epoch 36/100\n",
            "102/102 [==============================] - 68s 666ms/step - loss: 0.0088 - mae: 0.0654\n",
            "Epoch 37/100\n",
            "102/102 [==============================] - 68s 666ms/step - loss: 0.0089 - mae: 0.0651\n",
            "Epoch 38/100\n",
            "102/102 [==============================] - 68s 668ms/step - loss: 0.0085 - mae: 0.0637\n",
            "Epoch 39/100\n",
            "102/102 [==============================] - 68s 669ms/step - loss: 0.0080 - mae: 0.0627\n",
            "Epoch 40/100\n",
            "102/102 [==============================] - 68s 670ms/step - loss: 0.0079 - mae: 0.0623\n",
            "Epoch 41/100\n",
            "102/102 [==============================] - 68s 667ms/step - loss: 0.0071 - mae: 0.0592\n",
            "Epoch 42/100\n",
            "102/102 [==============================] - 68s 668ms/step - loss: 0.0067 - mae: 0.0582\n",
            "Epoch 43/100\n",
            "102/102 [==============================] - 68s 667ms/step - loss: 0.0071 - mae: 0.0594\n",
            "Epoch 44/100\n",
            "102/102 [==============================] - 68s 671ms/step - loss: 0.0067 - mae: 0.0584\n",
            "Epoch 45/100\n",
            "102/102 [==============================] - 68s 667ms/step - loss: 0.0067 - mae: 0.0574\n",
            "Epoch 46/100\n",
            "102/102 [==============================] - 68s 667ms/step - loss: 0.0065 - mae: 0.0577\n",
            "Epoch 47/100\n",
            "102/102 [==============================] - 68s 668ms/step - loss: 0.0077 - mae: 0.0600\n",
            "Epoch 48/100\n",
            "102/102 [==============================] - 68s 668ms/step - loss: 0.0077 - mae: 0.0605\n",
            "Epoch 49/100\n",
            "102/102 [==============================] - 68s 667ms/step - loss: 0.0074 - mae: 0.0599\n",
            "Epoch 50/100\n",
            "102/102 [==============================] - 68s 668ms/step - loss: 0.0062 - mae: 0.0559\n",
            "Epoch 51/100\n",
            "102/102 [==============================] - 68s 668ms/step - loss: 0.0061 - mae: 0.0554\n",
            "Epoch 52/100\n",
            "102/102 [==============================] - 68s 667ms/step - loss: 0.0062 - mae: 0.0553\n",
            "Epoch 53/100\n",
            "102/102 [==============================] - 68s 667ms/step - loss: 0.0061 - mae: 0.0550\n",
            "Epoch 54/100\n",
            "102/102 [==============================] - 68s 666ms/step - loss: 0.0059 - mae: 0.0544\n",
            "Epoch 55/100\n",
            "102/102 [==============================] - 68s 668ms/step - loss: 0.0055 - mae: 0.0525\n",
            "Epoch 56/100\n",
            "102/102 [==============================] - 68s 664ms/step - loss: 0.0056 - mae: 0.0536\n",
            "Epoch 57/100\n",
            "102/102 [==============================] - 68s 666ms/step - loss: 0.0051 - mae: 0.0506\n",
            "Epoch 58/100\n",
            "102/102 [==============================] - 68s 670ms/step - loss: 0.0053 - mae: 0.0513\n",
            "Epoch 59/100\n",
            "102/102 [==============================] - 68s 666ms/step - loss: 0.0053 - mae: 0.0518\n",
            "Epoch 60/100\n",
            "102/102 [==============================] - 68s 664ms/step - loss: 0.0053 - mae: 0.0513\n",
            "Epoch 61/100\n",
            "102/102 [==============================] - 68s 666ms/step - loss: 0.0054 - mae: 0.0523\n",
            "Epoch 62/100\n",
            "102/102 [==============================] - 68s 668ms/step - loss: 0.0051 - mae: 0.0515\n",
            "Epoch 63/100\n",
            "102/102 [==============================] - 68s 667ms/step - loss: 0.0049 - mae: 0.0501\n",
            "Epoch 64/100\n",
            "102/102 [==============================] - 68s 665ms/step - loss: 0.0051 - mae: 0.0500\n",
            "Epoch 65/100\n",
            "102/102 [==============================] - 68s 663ms/step - loss: 0.0048 - mae: 0.0495\n",
            "Epoch 66/100\n",
            "102/102 [==============================] - 68s 667ms/step - loss: 0.0073 - mae: 0.0584\n",
            "Epoch 67/100\n",
            "102/102 [==============================] - 69s 672ms/step - loss: 0.0043 - mae: 0.0473\n",
            "Epoch 68/100\n",
            "102/102 [==============================] - 68s 669ms/step - loss: 0.0044 - mae: 0.0475\n",
            "Epoch 69/100\n",
            "102/102 [==============================] - 68s 666ms/step - loss: 0.0045 - mae: 0.0475\n",
            "Epoch 70/100\n",
            "102/102 [==============================] - 68s 670ms/step - loss: 0.0040 - mae: 0.0458\n",
            "Epoch 71/100\n",
            "102/102 [==============================] - 69s 672ms/step - loss: 0.0040 - mae: 0.0462\n",
            "Epoch 72/100\n",
            "102/102 [==============================] - 68s 667ms/step - loss: 0.0039 - mae: 0.0449\n",
            "Epoch 73/100\n",
            "102/102 [==============================] - 68s 669ms/step - loss: 0.0039 - mae: 0.0454\n",
            "Epoch 74/100\n",
            "102/102 [==============================] - 69s 679ms/step - loss: 0.0043 - mae: 0.0474\n",
            "Epoch 75/100\n",
            "102/102 [==============================] - 70s 689ms/step - loss: 0.0044 - mae: 0.0473\n",
            "Epoch 76/100\n",
            "102/102 [==============================] - 69s 680ms/step - loss: 0.0049 - mae: 0.0484\n",
            "Epoch 77/100\n",
            "102/102 [==============================] - 68s 671ms/step - loss: 0.0042 - mae: 0.0466\n",
            "Epoch 78/100\n",
            "102/102 [==============================] - 68s 669ms/step - loss: 0.0040 - mae: 0.0451\n",
            "Epoch 79/100\n",
            "102/102 [==============================] - 68s 670ms/step - loss: 0.0040 - mae: 0.0458\n",
            "Epoch 80/100\n",
            "102/102 [==============================] - 68s 670ms/step - loss: 0.0038 - mae: 0.0443\n",
            "Epoch 81/100\n",
            "102/102 [==============================] - 69s 675ms/step - loss: 0.0038 - mae: 0.0442\n",
            "Epoch 82/100\n",
            "102/102 [==============================] - 69s 678ms/step - loss: 0.0036 - mae: 0.0428\n",
            "Epoch 83/100\n",
            "102/102 [==============================] - 69s 679ms/step - loss: 0.0033 - mae: 0.0419\n",
            "Epoch 84/100\n",
            "102/102 [==============================] - 70s 682ms/step - loss: 0.0034 - mae: 0.0423\n",
            "Epoch 85/100\n",
            "102/102 [==============================] - 69s 680ms/step - loss: 0.0036 - mae: 0.0430\n",
            "Epoch 86/100\n",
            "102/102 [==============================] - 69s 679ms/step - loss: 0.0033 - mae: 0.0413\n",
            "Epoch 87/100\n",
            "102/102 [==============================] - 70s 689ms/step - loss: 0.0031 - mae: 0.0412\n",
            "Epoch 88/100\n",
            "102/102 [==============================] - 69s 679ms/step - loss: 0.0047 - mae: 0.0446\n",
            "Epoch 89/100\n",
            "102/102 [==============================] - 69s 677ms/step - loss: 0.0042 - mae: 0.0444\n",
            "Epoch 90/100\n",
            "102/102 [==============================] - 69s 675ms/step - loss: 0.0049 - mae: 0.0480\n",
            "Epoch 91/100\n",
            "102/102 [==============================] - 69s 674ms/step - loss: 0.0036 - mae: 0.0421\n",
            "Epoch 92/100\n",
            "102/102 [==============================] - 69s 677ms/step - loss: 0.0033 - mae: 0.0427\n",
            "Epoch 93/100\n",
            "102/102 [==============================] - 69s 676ms/step - loss: 0.0037 - mae: 0.0430\n",
            "Epoch 94/100\n",
            "102/102 [==============================] - 69s 675ms/step - loss: 0.0037 - mae: 0.0432\n",
            "Epoch 95/100\n",
            "102/102 [==============================] - 69s 673ms/step - loss: 0.0048 - mae: 0.0473\n",
            "Epoch 96/100\n",
            "102/102 [==============================] - 68s 671ms/step - loss: 0.0034 - mae: 0.0424\n",
            "Epoch 97/100\n",
            "102/102 [==============================] - 70s 688ms/step - loss: 0.0033 - mae: 0.0407\n",
            "Epoch 98/100\n",
            "102/102 [==============================] - 69s 673ms/step - loss: 0.0032 - mae: 0.0408\n",
            "Epoch 99/100\n",
            "102/102 [==============================] - 68s 670ms/step - loss: 0.0033 - mae: 0.0412\n",
            "Epoch 100/100\n",
            "102/102 [==============================] - 68s 671ms/step - loss: 0.0032 - mae: 0.0410\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab Notebooks/AES/coherence_model_with_nsp_goldens.pt/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Assets written to: /content/drive/MyDrive/Colab Notebooks/AES/coherence_model_with_nsp_goldens.pt/assets\n",
            "<keras.layers.recurrent.LSTMCell object at 0x7f42c12f4ed0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "<keras.layers.recurrent.LSTMCell object at 0x7f42c12ed550> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        }
      ],
      "source": [
        "load_trained_model_coh_nsp = False\n",
        "if (load_trained_model_coh_nsp == True):\n",
        "    lstm_model_coh_nsp = load_model(coh_nsp_model_save_path)\n",
        "else:\n",
        "  if (embedding == 'full_emb'):\n",
        "    lstm_model_coh_nsp = get_model(Hidden_dim1=1028, Hidden_dim2=512, return_sequences = True, dropout_dense=0.5, dropout_lstm=0.4, \n",
        "                             recurrent_dropout=0.4, sen_size=max_words_for_full_emb_sem, input_size=768, activation='sigmoid', \n",
        "                             opt_engine='adam', loss_fn='mse')\n",
        "  else:\n",
        "    lstm_model_coh_nsp = get_model(Hidden_dim1=1028, Hidden_dim2=512, return_sequences = True, dropout_dense=0.5, dropout_lstm=0.4, \n",
        "                             recurrent_dropout=0.4, sen_size=max_sentences, input_size=768, activation='sigmoid', \n",
        "                             opt_engine='adam', loss_fn='mse')\n",
        "  lstm_model_coh_nsp.fit(lhs_train.numpy(), nsp_tpd_train.nsp_golden, batch_size=64, epochs=100)\n",
        "  lstm_model_coh_nsp.save(coh_nsp_model_save_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQCVB_jZQ8lM",
        "outputId": "15c42612-76ea-45ca-afda-e4f43fe92f9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Preparing Embeddings...\n",
            "Model Type:  semantic\n",
            "Embedding Type:  sen_avg\n",
            "hState:  last4sum\n",
            "Save File Directory:  /content/drive/MyDrive/Colab Notebooks/AES/experiment_XX\n",
            "Dataframe provided, Size:  (2596, 6)\n",
            "Loading existing embeddings from file...\n",
            "LHS File chosen:  /content/drive/MyDrive/Colab Notebooks/AES/experiment_XX/lhs_test.pt\n",
            "Y File chosen:  /content/drive/MyDrive/Colab Notebooks/AES/experiment_XX/y_test.pt\n",
            "Loaded, Size of LHS embeddings:  torch.Size([2596, 128, 768])\n",
            "Loaded, Size of y Gold:  (2596,)\n",
            "Returning lhs: Shape:  torch.Size([2596, 128, 768])\n",
            "Returning y_gold: Shape:  (2596,)\n"
          ]
        }
      ],
      "source": [
        "lhs_test, y_test = prepare_embeddings_updated (tpd_test, model_type='semantic', train_or_test='test', load_from_file=load_bert_sem, embedding_type=embedding, max_words=max_words_for_full_emb_sem, file_path = model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OfQB3tSa_rGE"
      },
      "outputs": [],
      "source": [
        "evaluate_model (lstm_model_sem, lhs_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ID5kxnvHDKPh"
      },
      "source": [
        "## NSP v/s OG model- on IELTS Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZFN_vKeDYwj"
      },
      "source": [
        "### Loading IELTS dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSgjSlULDIHv",
        "outputId": "3a558db8-849d-4556-9a5b-53cc86325a5f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py:311: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
            "  return func(*args, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "ielts_dataset = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/AES/essay-training-data-scraped.xlsx - IELTS-Essays.csv\", header=0, index_col=False, names=['id','prompt','essay','score','comments', 'COH','LR','GR',\"TA\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9vVZjJd0D3XG"
      },
      "outputs": [],
      "source": [
        "ielts_dataset = ielts_dataset.drop(columns=['id'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "9CgMWe2BEa-j",
        "outputId": "3eb18062-0fbd-4204-edb8-d6ae0ac88e18"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'This is a great essay. Seems worthy of Band 8. No improvements are necessary, keep up the good work!'"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ielts_dataset.comments[3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DK8gtWtHdQvW"
      },
      "outputs": [],
      "source": [
        "ielts_dataset['normalized_score'] = ielts_dataset.score.apply(lambda x: float(normalize_value(x, ielts_dataset.score.min(), ielts_dataset.score.max())))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "kBPTDs8mLLrN",
        "outputId": "752d3f01-9adc-4080-c8d4-6b0cb2b8f111"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-b199a0f9-eea5-4732-8b3f-c7c1c078a5bb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>prompt</th>\n",
              "      <th>essay</th>\n",
              "      <th>score</th>\n",
              "      <th>comments</th>\n",
              "      <th>COH</th>\n",
              "      <th>LR</th>\n",
              "      <th>GR</th>\n",
              "      <th>TA</th>\n",
              "      <th>normalized_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>As computers are being used more and more in e...</td>\n",
              "      <td>There is no doubt that education and the learn...</td>\n",
              "      <td>8.00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.833333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Popular events like the Football World Cup and...</td>\n",
              "      <td>Every four years, the whole world stops to wat...</td>\n",
              "      <td>8.00</td>\n",
              "      <td>This is a great essay, the ideas, language, st...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.833333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Some say that rich countries should help poor ...</td>\n",
              "      <td>Improvements in health, education and trade ar...</td>\n",
              "      <td>8.00</td>\n",
              "      <td>This is a great essay, seems to be on a Band 8...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.833333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>As computers are being used more and more in e...</td>\n",
              "      <td>There have been immense advances in technology...</td>\n",
              "      <td>8.00</td>\n",
              "      <td>This is a great essay. Seems worthy of Band 8....</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.833333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Financial education should be a mandatory comp...</td>\n",
              "      <td>It is an obvious fact that financial aspects a...</td>\n",
              "      <td>7.75</td>\n",
              "      <td>This is a wonderful essay. It covers the task,...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.791667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>210</th>\n",
              "      <td>Some people view teenage conflict with their p...</td>\n",
              "      <td>There is no doubt that adolescence can be a di...</td>\n",
              "      <td>9.00</td>\n",
              "      <td>COH: 9,9,9,9,9; LR: 8,9; GR: 9,9; TA: 9,9,9,ok</td>\n",
              "      <td>9.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>211</th>\n",
              "      <td>Some people believe money is a less important ...</td>\n",
              "      <td>It is widely believed by some that compared wi...</td>\n",
              "      <td>7.00</td>\n",
              "      <td>COH: 9,9,9,7,4; LR: 6,9; GR: 9,9; TA: 9,8,9,ok</td>\n",
              "      <td>4.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>212</th>\n",
              "      <td>People are now living much longer lives than b...</td>\n",
              "      <td>In recent times, people are beginning to live ...</td>\n",
              "      <td>7.00</td>\n",
              "      <td>COH: 9,9,6,9,9; LR: 6,9; GR: 9,9; TA: 9, 6.5, ...</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>213</th>\n",
              "      <td>Nowadays the way many people interact with eac...</td>\n",
              "      <td>It is widely observed that the mode of communi...</td>\n",
              "      <td>7.00</td>\n",
              "      <td>COH: 9,9,9,9,7; LR: 7,9; GR: 9,9; TA: 5,7,9,ok</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>214</th>\n",
              "      <td>People living in large cities have to face man...</td>\n",
              "      <td>There is no doubt that nowadays city-dwellers ...</td>\n",
              "      <td>7.00</td>\n",
              "      <td>COH: 9,9,9,9,9; LR: 6,9; GR: 9,9; TA: 4,8,9,ok</td>\n",
              "      <td>9.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.666667</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>215 rows × 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b199a0f9-eea5-4732-8b3f-c7c1c078a5bb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b199a0f9-eea5-4732-8b3f-c7c1c078a5bb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b199a0f9-eea5-4732-8b3f-c7c1c078a5bb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                prompt  ... normalized_score\n",
              "0    As computers are being used more and more in e...  ...         0.833333\n",
              "1    Popular events like the Football World Cup and...  ...         0.833333\n",
              "2    Some say that rich countries should help poor ...  ...         0.833333\n",
              "3    As computers are being used more and more in e...  ...         0.833333\n",
              "4    Financial education should be a mandatory comp...  ...         0.791667\n",
              "..                                                 ...  ...              ...\n",
              "210  Some people view teenage conflict with their p...  ...         1.000000\n",
              "211  Some people believe money is a less important ...  ...         0.666667\n",
              "212  People are now living much longer lives than b...  ...         0.666667\n",
              "213  Nowadays the way many people interact with eac...  ...         0.666667\n",
              "214  People living in large cities have to face man...  ...         0.666667\n",
              "\n",
              "[215 rows x 9 columns]"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ielts_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxGAAoB6cO4V"
      },
      "source": [
        "### Creating embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hp_gLymucOcZ"
      },
      "outputs": [],
      "source": [
        "# prepare_embeddings_updated(ielts_dataset,load_from_file=False,file_path=\"/content/drive/MyDrive/Colab Notebooks/AES/IELTS_dataset_data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mt6IGaR9cJ-t"
      },
      "outputs": [],
      "source": [
        "lhs_ielts_dataset = torch.load(\"/content/drive/MyDrive/Colab Notebooks/AES/IELTS_dataset_data/lhs_test.pt\")\n",
        "y_test_ielts_dataset = torch.load(\"/content/drive/MyDrive/Colab Notebooks/AES/IELTS_dataset_data/y_test.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_SvqGRSGjDrt"
      },
      "outputs": [],
      "source": [
        "non_norm_y_test_ielts = ielts_dataset.score.apply(lambda x: x/10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NlJUhHwlhqc0"
      },
      "source": [
        "###Loading NSP Coherence Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "lfC5jgAuhqE0",
        "outputId": "34ebf3f5-e2a6-435a-db1a-106954f65635"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        }
      ],
      "source": [
        "coh_nsp_model_save_path = \"/content/drive/MyDrive/Colab Notebooks/AES/coherence_model_with_nsp_goldens.pt\"\n",
        "nsp_model = load_model(coh_nsp_model_save_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hilMtawjhTPm",
        "outputId": "d2c7c88f-d95e-4449-9f5b-708f018fb972"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Kappa Score: 0.013717608825793093\n",
            "MSE:  0.07298263263898985\n",
            "RMSE:  0.27015298006683147\n"
          ]
        }
      ],
      "source": [
        "evaluate_model(nsp_model,lhs_ielts_dataset, non_norm_y_test_ielts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TrCLrXbriWPU"
      },
      "source": [
        "###Loading OG model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H817lb6yiPPI",
        "outputId": "3032d2a9-33bd-4eaa-8edc-530a4f3694a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        }
      ],
      "source": [
        "og_model = load_model(\"/content/drive/MyDrive/Colab Notebooks/AES/experiment_XX/coh-lstm_model-latest.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exZEZBxzi9uh",
        "outputId": "08028b20-9edf-427a-ca0d-3bc6ade97346"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Kappa Score: 0.1655800969599387\n",
            "MSE:  0.08179962083601923\n",
            "RMSE:  0.2860063300628488\n"
          ]
        }
      ],
      "source": [
        "evaluate_model(og_model,lhs_ielts_dataset, non_norm_y_test_ielts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "DP5DyTlJFxy1",
        "outputId": "c7e15277-54b8-4845-fdc7-08303472eb58"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Every four years, the whole world stops to watch international sporting events such as the Olympics and the Football World Cup in which athletes show their best performance to make their country proud. These sporting occasions have proved to be helpful in easing international tension in difficult times when powerful leaders were trying to control the world’s economy and other governments were fighting over the land. The Olympic Games are one of the best examples which prove how sporting events can bring nations together, at least temporarily. From the ancient History, when Greeks and Romans would interrupt battles to participate in the games, to the more recent international disputes, when athletes from Palestine and Israel would forget their differences, compete peacefully and even embrace each other after an event. Moreover, these popular events have called the world’s attention to the terrible consequences of wars; thus some leaders have tried to reach agreements to end their disputes and live peacefully. Similarly, international sporting events show benefits in some developing countries which live in a daily internal civil war. For example, Brazil has a high rate of unemployment, lack of education, hunger, crime, poverty and corruption which leads to an immense embarrassment of being Brazilian and a low self-esteem. However, when the Football World Cup starts, the Brazilian squad, which is considered the best team in the world, provokes an amazing feeling of pride in their country. Most people seem to forget all their problems and even the criminal activity decreases. They paint roads with the national colors, wear the Brazilian team shirts and buy national flags. Moreover, the competition brings families and neighbors together and even rival gangs watch the games and celebrate peacefully.In conclusion, popular sporting events play an important role in decreasing international tensions and liberating patriotic feelings as history has shown.'"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ielts_dataset.essay.iloc[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8RbB4v3GE8P",
        "outputId": "9b2821fa-c45c-4e9e-af6b-3fe38b7b0ca9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "8.0"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ielts_dataset.score[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMHVY8bvmBPj",
        "outputId": "129ebb5e-0fa5-4666-bce2-0c56c61da980"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.88804144]], dtype=float32)"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "og_model.predict(lhs_ielts_dataset[1].numpy().reshape(1,128,768))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KvwnBlts0OOa",
        "outputId": "4bc4f28c-cf9e-46ce-e7a9-057d811403af"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.90515244]], dtype=float32)"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nsp_model.predict(lhs_ielts_dataset[1].numpy().reshape(1,128,768))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gHY7qyWz0VKp"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "O3dGIG9BE7Pg",
        "Jehlg6loEps4",
        "rzqETgwsFBbN",
        "f9IgDlfaFK2_",
        "kxZIz1NBxAlJ",
        "KCicVVh7m4zP",
        "QOZYLJMq5rc8",
        "tWX6MTxUEZXf",
        "x4D_SaMRbP-W",
        "UZU3HUdweSKg",
        "8ZQ4Y6QFemWq",
        "L3cKL8_6u51y",
        "3xCTUD8Jf13Z",
        "rX6iiq7kTWjA",
        "lyBJ_6a1T81w",
        "xwS6ftQnS3Ms",
        "WfBiTey3AmHX"
      ],
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0171469191484006a9354720c27c5a0c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d2373f446df40bfb808af517dbc5f9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6d81e7badfa9490dac1415746931d5cf",
              "IPY_MODEL_358c6230a3c44959909ad4649f6ab882",
              "IPY_MODEL_ca4252a9263b46d4bab8df81f147ad67"
            ],
            "layout": "IPY_MODEL_90cd40a619314bd4a7ce0901b1d02d43"
          }
        },
        "0f2f6a15053f4cd1baeadcf541d1a40b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e889f1fe8a84d098a73cf2077f25862": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2474d7fa1d4d4f588c74c108f400edf0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a62ef463c4b436d9327831cb15e2dc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f3b4bbb737841afa330e9459170433c",
            "placeholder": "​",
            "style": "IPY_MODEL_b6edddb02efb425b903076f0cf87c976",
            "value": "Downloading: 100%"
          }
        },
        "2b9989b684e04a32bb759c1ccba68f32": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1618c02b957453db8785e47f008f239",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fbdcf8e40cb748448a269b235dd59f2d",
            "value": 570
          }
        },
        "2ce86e3546634bb197c0e9ea950e9c56": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8828c7e012ea49baa4f24c55e6895468",
            "placeholder": "​",
            "style": "IPY_MODEL_53e18eef9f564a80a85e98439645b61a",
            "value": " 455k/455k [00:00&lt;00:00, 619kB/s]"
          }
        },
        "317829c743344e40b90d1ee5355653da": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5004b386c81c41429b2a9c6fa523c12f",
              "IPY_MODEL_bf1fafd44b634c2396dc5e18d67a260d",
              "IPY_MODEL_2ce86e3546634bb197c0e9ea950e9c56"
            ],
            "layout": "IPY_MODEL_61e5bc5bb4614816a0a4678efd3a219f"
          }
        },
        "358c6230a3c44959909ad4649f6ab882": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d5e5871f40a4f28b1117940a4cf27b3",
            "max": 440473133,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e01a6f5f808e4a70bd1a2ba20b655d00",
            "value": 440473133
          }
        },
        "3a74bf3f25fe417a90f9dabe99209cf4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_73792d96239e48909273911f0cb7db7b",
              "IPY_MODEL_7194f17fea074ef8ace4c1fb7cbe3d13",
              "IPY_MODEL_f3d2b2a2aaf54a6eac17fdf31af5242b"
            ],
            "layout": "IPY_MODEL_e1df78df65cb4ffa889e0c6f87bf3546"
          }
        },
        "3d6da0d3a7b745308daeda0b221e19a6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "461624643109418193f213d1e6b244ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4bff61a41ab2416fb8058d46147b9c1a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f3b4bbb737841afa330e9459170433c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5004b386c81c41429b2a9c6fa523c12f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f2f6a15053f4cd1baeadcf541d1a40b",
            "placeholder": "​",
            "style": "IPY_MODEL_63a9a234010742f6bd279368e849b04b",
            "value": "Downloading: 100%"
          }
        },
        "53e18eef9f564a80a85e98439645b61a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6197d372a233499890664cf3f1e40fda": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_81b9c468215e45e49c2b8f9583be4245",
              "IPY_MODEL_2b9989b684e04a32bb759c1ccba68f32",
              "IPY_MODEL_cdf1b07671bd440b86c2687b11316673"
            ],
            "layout": "IPY_MODEL_4bff61a41ab2416fb8058d46147b9c1a"
          }
        },
        "61e5bc5bb4614816a0a4678efd3a219f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "620345fed03b4b8f80b4ec250898b359": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "63a9a234010742f6bd279368e849b04b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6d81e7badfa9490dac1415746931d5cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e4b63c6d1d094c948a5abceeafb872d3",
            "placeholder": "​",
            "style": "IPY_MODEL_ad40979c03ef466b8a86c20bcef4b585",
            "value": "Downloading: 100%"
          }
        },
        "70606f4940f04977bf4cc8d63d725ac8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7194f17fea074ef8ace4c1fb7cbe3d13": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a617166331334ef38aa5ab60576416dc",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c4af460e3b3c4d2685808f564c17d915",
            "value": 231508
          }
        },
        "73792d96239e48909273911f0cb7db7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e15990c94df746818577f6d4987ac689",
            "placeholder": "​",
            "style": "IPY_MODEL_8ce19927c9af4cc7ad8b4af9a94fbd42",
            "value": "Downloading: 100%"
          }
        },
        "73e88557b7b549cba8c48a39df765d1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7d5e5871f40a4f28b1117940a4cf27b3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81b9c468215e45e49c2b8f9583be4245": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_70606f4940f04977bf4cc8d63d725ac8",
            "placeholder": "​",
            "style": "IPY_MODEL_e3e4a249923d4a0fbb06ec3a7319ba1b",
            "value": "Downloading: 100%"
          }
        },
        "8828c7e012ea49baa4f24c55e6895468": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c7b8eeb26ab432f8eb6805533dbae27": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8ce19927c9af4cc7ad8b4af9a94fbd42": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "90cd40a619314bd4a7ce0901b1d02d43": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90e84be76bdc45629fb748db00aae92f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9884f1119288448384be09dd75f7b590",
            "placeholder": "​",
            "style": "IPY_MODEL_461624643109418193f213d1e6b244ea",
            "value": " 28.0/28.0 [00:00&lt;00:00, 1.05kB/s]"
          }
        },
        "96f1e836186d4c768a280f860c4324da": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9884f1119288448384be09dd75f7b590": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2a246dc90564c6398e79803d06c2c55": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0171469191484006a9354720c27c5a0c",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8c7b8eeb26ab432f8eb6805533dbae27",
            "value": 28
          }
        },
        "a617166331334ef38aa5ab60576416dc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad40979c03ef466b8a86c20bcef4b585": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b11106c5a21948d3a0d50d5e39c31a1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b6edddb02efb425b903076f0cf87c976": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bf1fafd44b634c2396dc5e18d67a260d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dfa7eccb0de44080808818706385adcc",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_620345fed03b4b8f80b4ec250898b359",
            "value": 466062
          }
        },
        "c1618c02b957453db8785e47f008f239": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4af460e3b3c4d2685808f564c17d915": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c635355a8f054ec1b15f71862a838a98": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2a62ef463c4b436d9327831cb15e2dc3",
              "IPY_MODEL_a2a246dc90564c6398e79803d06c2c55",
              "IPY_MODEL_90e84be76bdc45629fb748db00aae92f"
            ],
            "layout": "IPY_MODEL_e84b0e22768043cf89e7ccc7e538096d"
          }
        },
        "ca4252a9263b46d4bab8df81f147ad67": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2474d7fa1d4d4f588c74c108f400edf0",
            "placeholder": "​",
            "style": "IPY_MODEL_73e88557b7b549cba8c48a39df765d1d",
            "value": " 420M/420M [00:07&lt;00:00, 61.2MB/s]"
          }
        },
        "cdf1b07671bd440b86c2687b11316673": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e889f1fe8a84d098a73cf2077f25862",
            "placeholder": "​",
            "style": "IPY_MODEL_b11106c5a21948d3a0d50d5e39c31a1e",
            "value": " 570/570 [00:00&lt;00:00, 23.4kB/s]"
          }
        },
        "dfa7eccb0de44080808818706385adcc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e01a6f5f808e4a70bd1a2ba20b655d00": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e15990c94df746818577f6d4987ac689": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1df78df65cb4ffa889e0c6f87bf3546": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3e4a249923d4a0fbb06ec3a7319ba1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e4b63c6d1d094c948a5abceeafb872d3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e84b0e22768043cf89e7ccc7e538096d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3d2b2a2aaf54a6eac17fdf31af5242b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d6da0d3a7b745308daeda0b221e19a6",
            "placeholder": "​",
            "style": "IPY_MODEL_96f1e836186d4c768a280f860c4324da",
            "value": " 226k/226k [00:00&lt;00:00, 313kB/s]"
          }
        },
        "fbdcf8e40cb748448a269b235dd59f2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}